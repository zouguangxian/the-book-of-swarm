
\green{}

Swarm项目旨在为未来独立的数字社会建立无许可存储和通信基础设施。从开发者的角度来看，Swarm是一个公共基础设施，为\gloss{Web 2.0}时代的实时交互式web应用程序提供动力。它为原语提供了一个低级的API，原语作为复杂应用程序的构建块，以及基于swarm的\gloss{Web 3.0}开发堆栈的工具和库的基础。API和工具的设计初衷是允许从任何传统浏览器访问Swarm网络，因此Swarm可以立即提供一个私有和分散的替代今天的\gloss{World Wide Web} (\gloss{WWW})。

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{fig/swarm-layered-design.pdf}
  \caption[Swarm的分层设计\statusgreen]{群的分层设计}
\label{fig:Swarm-layered-design}
\end{figure}

本部分详细介绍了系统的设计和体系结构。按照\ref{sec:design-principles}中提出的原则，我们强调模块化设计，并将Swarm设想为具有清晰可分离的层，每个层都依赖于前一个层(见图\ref{fig:Swarm-layered-design}):

\begin{itemize}
\item (1) \emph{作为底层传输的点对点网络协议，}
\item (2) \emph{一个覆盖网络，它的协议支持\glossplural{chunk}(固定大小的数据块)的分布式不可变存储，}
\item (3) \emph{提供高级数据访问和为基础层特性定义api的组件}
\item (4) \emph{定义标准的应用层，并为更精细的用例概述最佳实践。}
\end{itemize}

我们将(2)和(3)作为Swarm的核心。由于网络层依赖于它，我们也将制定(1)的要求，但我们考虑(1)和(4)的详细处理超出了本书的范围。


以设计为中心，在\ref{sec:network}章节讨论了群覆盖网络(图\ref{fig:Swarm-layered-design}中的第二层)的架构，并在\ref{sec:incentivisation}章节进行了补充，描述了使群能够自我维持的经济激励系统。\ref{sec:high-level-functionality}章,我们介绍了算法和约定允许群概念地图数据块层启用高级功能为存储和通信,特别是数据结构,如文件系统和数据库,\gloss{access control}索引\gloss{feeds}和直接通讯,占群的第三层。
在\ref{sec:persistence}章节中，我们提出了防止垃圾收集块从网络中消失的方法，包括:\glossplural{erasure code}、\gloss{pinning}和保险，并提供了使用丢失块通知和保险挑战来监控、恢复和重新上传它们的方法。
最后，在\ref{sec:ux}章节中，我们将从用户体验的角度来研究功能。

\chapter{网络}\label{sec:network}

本章讲述了群集覆盖网络如何建立在\gloss{peer-to-peer}网络协议之上，形成允许在节点之间路由消息的拓扑结构(\ref{sec:topology-routing})。在\ref{sec:kademlia-storage}中，我们描述了这样一个网络如何作为数据块(\ref{sec:chunks})的可扩展\gloss{distributed storage}解决方案，并给出了支持检索/下载和同步/上传协议(\ref{sec:push-and-pull})的逻辑。

\section{拓扑和路由\statusgreen}\label{sec:topology-routing}

本节通过明确关于底层网络(第1层)的假设，为Swarm的\gloss{overlay network}(第2层)设置场景(\ref{sec:underlay-transport})。\ref{sec:overlay-addressing}介绍了\gloss{overlay address space}并解释了节点如何分配地址。在\ref{sec:kademlia-routing}中，我们提出了\gloss{Kademlia} \gloss{overlay topology}(连接模式)，并解释了它如何解决节点之间的路由。在\ref{sec:bootstrapping}中，我们展示了运行Swarm客户端的节点如何发现彼此，引导并维护覆盖拓扑。

\subsection{底层网络的要求\statusyellow}\label{sec:underlay-transport} 

\yellow{}

Swarm是一个由用户运营的网络。网络中的每个节点都应该运行一个符合协议规范的客户机。在最低层，网络中的节点使用点对点网络协议作为它们的传输层进行连接。这个叫做\gloss{underlay network}。
在它的总体设计中，Swarm是不知道特定的底层传输所使用的，只要它满足以下要求。

\begin{enumerate}
    \item \emph{寻址}—节点通过其\gloss{underlay address}进行识别。
    \item \emph{拨号}—节点可以发起一个直接连接到一个peer通过拨号他们的底层地址。
    \item \emph{听}——节点可以侦听其他节点拨号，并可以接受传入连接。不接受传入连接的节点称为\glossplural{light node}。
    \item \emph{现场连接}——节点连接建立一个通信通道，该通道在显式断开连接之前保持活动，因此连接的存在意味着远程对等端在线并接受消息。
    \item \emph{通道安全}——
该信道提供身份验证，实现加密认证传输，抵御中间人攻击。
    \item \emph{协议多路复用}——
底层网络服务可以容纳在同一连接上运行的多个协议。对等体用它们实现的名称和版本通信协议，底层服务识别兼容协议，并在每个匹配的协议上启动对等体连接。 
    \item \emph{交付担保}——
协议消息具有\gloss{guaranteed delivery}，即由于网络问题导致的传递失败导致直接错误响应。
保证每个协议中消息的传递顺序。
理想情况下，底层协议提供优先级。
如果协议多路复用在同一个传输通道上，这很可能意味着帧，这样长消息就不会阻塞高优先级消息。
    \item \emph{连载}——
协议消息构造支持任意数据结构序列化约定。
    
\end{enumerate}

\gloss{libp2p}库可以提供所有需要的功能，并且是规范中给出的底层连接驱动程序，请参阅\ref{spec:protocol:intro}.%
%
\footnote{Swarm目前的golang实现使用以太坊的\gloss{devp2p}/rlpx，它满足上述标准，并使用TCP/IP和自定义加密技术来保证安全性。devp2p使用的底层网络地址使用\gloss{enode URL scheme}表示。Devp2p根据协议的消息ID进行消息调度。它使用了RLP序列化，该序列化是用更高级别的数据类型表示约定扩展的。为了提供对以太坊1的支持。我们可以提供一个瘦的devp2p节点，它将查询代理到一个基于libp2p的Swarm客户端，或者仅仅使用它的API。否则，我们希望devp2p网络支持停止。}

\subsection{覆盖addressing\statusgreen}\label{sec:overlay-addressing} 
\green{}

当客户端使用\gloss{underlay address}来建立与对等点的连接时，每个运行Swarm的节点都被额外标识为\gloss{overlay address}。正是这个地址决定了节点将连接到哪些对等点，并指导消息的转发方式。覆盖地址被认为是稳定的，因为它定义了节点跨会话的身份，并最终影响哪些内容最值得存储在节点的本地存储中。

该节点的\gloss{overlay address}来自以太坊账户，通过使用256位kecak算法(参见\ref{spec:format:bzzaddress})，将相应的椭圆曲线公钥与\gloss{BZZ network ID}哈希。包含BZZ网络ID的原因是可能存在许多群网络(例如\ test net, main net, or private Swarms). Including the BZZ network ID makes it impossible to use the same address across networks. Assuming any sample of base accounts independently selected, the resulting overlay addresses are expected to have a uniform distribution in the address space of 256-bit integers. This is important to deriving the address from a public key as it allows the nodes to issue commitments associated with an overlay location using cryptographic signatures which are verifiable by 3rd parties. 

Using the long-lived communication channels of the\gloss{underlay network}，群节点通过\emph{长年缠身}对等连接形成网络)。由此产生的连通性图可以实现在地址空间上定义的特定拓扑。所选的\gloss{overlay topology}称为\gloss{Kademlia}:它提供了一种策略，仅使用底层对等连接来中继消息，从而实现群网络中任意两个任意节点之间的通信。\ref{spec:protocol:hive}中描述了节点如何彼此共享关于自己和其他对等体的信息，称为“Hive”。在\ref{sec:bootstrapping}中讨论了节点如何使用该协议引导\gloss{overlay topology}。\gloss{Kademlia topology}的理论基础在\ref{sec:kademlia-connectivity}中得到了严格的形式化。

关键的是，覆盖地址空间都是256位整数。群的核心是\gloss{proximity order} (\gloss{PO})的概念，它在离散尺度上量化两个地址的相关性。%
%
\footnote{接近顺序是离散对数尺度的接近，反过来，是标准化的异或距离的倒数。参见\ref{sec:proximity}的正式定义。}
%
给定两个地址$x$和$y$, $\mathit{PO}(x,y)$计算它们二进制表示的匹配位，从最有效位开始，直到第一个不同的位。因此，最高的接近顺序为256，表示最大的相关性，即$x=y$。

\subsection{Kademlia路由\statusgreen}\label{sec:kademlia-routing}
\yellow{与附录一起返工}

\glossupper{Kademlia topology}可以使用覆盖寻址在网络中的节点之间路由消息。它有很好的可扩展性，因为它允许通用路由，这样(1)跳数和(2)对等连接数总是对网络大小的对数。

在接下来的内容中，我们将展示两种常见的路由方式:\emph{迭代/缩放}和\emph{递归/转发}。蜂群的设计关键在于选择后者，即前进的味道。然而，这是不寻常的，而且，由于迭代风格在许多点对点文献中占主导地位，而且大多数其他实现都使用迭代路由(参见\cite{maymounkov2002kademlia,baumgart2007s,lua2005survey})，我们认为让读者了解这两种方法是很有用的，以便揭示它们的特性。

\subsubsection{迭代和转发Kademlia}

设$R$是网络中节点上的任意二进制关系。与$R$与特定节点$x$相关的节点称为$x$的\glossplural{peer}。$x$的对等体可以通过相对于$x$的\gloss{proximity order} (\gloss{PO})进行索引(参见\ref{sec:proximity})。
对等体的等价类称为\glossplural{proximity order bin}，或者简称为bins。一旦被安排在bins中，这些对等点组就形成了节点$x$的\gloss{Kademlia table}(参见图\ref{fig:kademlia-table})。 



\begin{figure}[htbp]
   \centering
    % \includegraphics[width=0.7\textwidth]{fig/kademlia.pdf}
    % \includegraphics[width=0.7\textwidth]{fig/kademlia-2.pdf}
    % \includegraphics[width=0.8\textwidth]{fig/kademlia-3.pdf}
    \includegraphics[width=.88\textwidth]{fig/kademlia-35.pdf}
   \caption[从覆盖地址空间到Kademlia表\statusgreen]{从覆盖地址空间到Kademlia表。\textbf{Top}:覆盖地址空间用二叉树表示，有颜色的叶子是实际的节点。主节点(+)的路径用较粗的线表示。枢轴节点的节点通过从枢轴测量的异或距离的位来显示。这里0表示与主元匹配的位，1表示不同的位。叶节点按照与主节点(最左边的节点)的xor距离排序。枢轴的Kademlia表:从左侧的枢轴路径分支出来的子树显示为表的行，以递增的顺序表示邻近顺序容器。}
   \label{fig:kademlia-table}
\end{figure}

如果有一个称为\gloss{neighbourhood depth}的$0\leq d_x\leq \mathit{maxPO}$，则节点$x$具有一个\gloss{saturated Kademlia table}，这样:(1)节点在\gloss{proximity order} bin $d_x$和(2)至少与$d_x$(称为\gloss{nearest neighbours})接近的所有节点都是$x$的节点。如果网络中的每个节点都有一个饱和的Kademlia表，则我们说网络有\gloss{Kademlia topology}。

\begin{figure}[htbp]
   \centering
    \includegraphics[width=\textwidth]{fig/kademlia-3.pdf}
   \caption[最近的邻居\statusgreen]{使用$d = 2$的4位网络中的最近邻居 }
   \label{fig:bin-density}
\end{figure}

设$R$为“已知”关系:$y$为“$x$”，如果$x$同时具有$y$的覆盖和底层寻址信息。
在迭代的Kademlia路由中，\gloss{requestor node}迭代地扩展了已知的节点图。使用它们的\gloss{underlay address}，请求者节点将联系它们知道的距离较远的对等点的目标地址最近的对等点(通常使用UDP)，在每次后续迭代中，对等点至少变得离目标更近一个顺序(参见图\ref{fig:iterative-forwarding-kademlia})。由于Kademlia标准，请求者最终将发现目标节点的底层地址，然后可以与它建立直接通信。这种迭代策略%
%
\footnote{迭代协议等价于\cite{maymounkov2002kademlia}中描述的原始Kademlia路由。
}
%
关键取决于节点查找当前在线节点的能力。为了找到这样的对等点，节点需要为每个bin收集多个候选节点。可用性的最佳预测器是对等点最近一次响应的时间，因此容器中的对等点应该根据这个顺序进行优先级排序。

\begin{figure}[htbp]
   \centering
   \vspace{-2cm} 
   \includegraphics[width=.8\textwidth]{fig/iterative-kademlia.pdf} \\\vspace{-1.3cm}
   \includegraphics[width=.8\textwidth]{fig/forwarding-kademlia-3.pdf}
   \caption[迭代和转发Kademlia路由\statusgreen]{迭代和转发Kademlia路由:请求者节点显示在地址$...0000...$十字圆想路线的目的地址$...1111...$最接近的对等网络的蓝色圈$...1110...$这些初始椭圆表示前缀由请求者和目的地址共享$n$位长。在迭代的风格中，请求者联系他们知道最接近目标地址的对等点(步骤1，点黑色箭头)。在线的节点(黄色)响应更近的节点的信息(绿色箭头，步骤2)，因此请求者现在可以使用这些更近的节点重复查询(绿色，步骤3)。(绿色和蓝色)是距离目标地址最近的至少一个PO，直到请求者最终与最接近目标地址的节点直接接触为止。在转发方式中，请求者将消息转发给他们知道的离目的地最近的已连接对等体(黄色)。接收对等体做同样的事情。应用此策略可递归地通过对等点链(黄、绿、蓝)传递消息，每个对等点至少有一个靠近目的地的PO。}
   \label{fig:iterative-forwarding-kademlia}
\end{figure}


Swarm使用了Kademlia路由的另一种风格，这在\cite{heep2010r}中首次描述，然后在\cite{tronetal2019-network}中进行了扩展和研究。这里使用了递归方法，迭代的后续步骤被“外包”给\gloss{downstream peer}。
每个节点递归地将消息传递给一个直接对等点，该对等点至少离目的地更近一个\gloss{proximity order}。\glossupper{routing}在这里的意思是简单地通过越来越接近目的地的对等点链来转发消息，如图\ref{fig:iterative-forwarding-kademlia}所示。


通过这种方式，Swarm的底层传输提供了准稳定的TCP对等连接，通信通道保持活跃。然后可以将这些打开的连接用作$R$来定义\gloss{peer}的另一个概念。群的两个标准的健康\gloss{Kademlia connectivity}翻译为:为每个节点$x$,存在一个\gloss{neighbourhood depth} $d_x$这样(1)节点$x$开放与至少一个节点为每个\gloss{proximity order bin}但不包括$d_x$和(2)连接到所有的网络节点至少像$d_x$附近。如果网络中的每个节点都有一个饱和的节点卡德米亚表，那么该网络就被称为具有\gloss{Kademlia topology}。由于已连接的对等点保证是在线的，因此递归步骤只包括将消息转发到严格接近目的地的已连接的对等点。我们可以称之为\gloss{forwarding Kademlia}。


在\gloss{forwarding Kademlia}网络中，如果存在一条从发送方到目的地的路径，消息就被称为\emph{可路由的}。在使用\gloss{Kademlia topology}的成熟子网中，每条消息都是可路由的。

如果所有对等连接都稳定在线，则\gloss{thin Kademlia table}(即$d$之前的每个bin的\ a single\gloss{peer})就足以保证节点之间的路由。然而在现实中，网络受到\gloss{churn}，即\ nodes may be expected to go offline regularly. In order to ensure\gloss{routability}的影响，在面临搅乱时，网络需要维护\gloss{Kademlia topology}。这意味着每个单独的节点在任何时候都需要有一个\gloss{saturated Kademlia table}。通过在每个\gloss{proximity order bin}中保持几个连接的对等点，节点可以确保节点退出不会破坏其Kademlia表的饱和。给定一个节点退出模型，我们可以计算每个bin所需的最小对等点数量，以保证节点以任意接近1的概率饱和。节点在特定的接近顺序bin中保留的对等点越多，消息目标地址和对等点拥有更长的匹配前缀的可能性就越大。作为将消息转发到该对等体的结果，\gloss{proximity order}增加得更快，并且消息最终更接近目的地，而每个容器中的对等体更少(参见图\ref{fig:bindensity})。



在保证\gloss{Kademlia}饱和的情况下，节点将始终能够转发消息并确保\gloss{routability}。如果节点遵守转发原则(\gloss{aligned incentives}保证了这一点，参见\ref{spec:strategy:forwarding})，中继可能崩溃的唯一情况是节点在收到消息后退出网络，但没有机会转发它。%
%
\footnote{健康的节点可以承诺能够在一个(非常短的)常数时间内转发，我们可以调用\gloss{forwarding lag}。如果\gloss{downstream peer}在转发延迟过去之前断开了连接，那么\gloss{upstream peer}可以将消息重新转发给另一个对等体，从而保持消息不间断地传递。详情请参阅\ref{sec:retrieval}。
} 

转发Kademlia的一个重要优势是，这种路由方法比迭代算法需要更少的带宽。在迭代版本中，已知的对等点不能保证是在线的，所以找到一个在线的对等点会增加额外的不可预测性。

\subsubsection{发送方匿名}
\glossupper{sender anonymity}是集群的一个重要特征。重要的是，由于请求是从点对点转发的，请求级联中更低的那些点永远不可能知道请求的发起者是谁。

上述严格的Kademlia路由公式表明，如果一个节点从一个对等点接收到消息，并且该消息和对等点的接近顺序为$0$，那么接收方将能够得出它接收到消息的对等点一定是发送方。如果我们允许\gloss{light node}群客户端，因为他们运行在一个低资源环境中，不保持完全的Kademlia饱和，而是只有一个本地邻居，即使是来自bin $0$的peer的消息仍然是模糊的来源。 

\subsubsection{仓密度和多阶跃} \label{sec:bindensity}

由于对数距离和均匀节点分布的结果，一个特定节点的较远的节点数量呈指数增加。
只要连接的节点的数量小于近一步箱中的节点数量的两倍，那么较浅的箱总是允许节点有更多的选择。特别是，节点有机会以对等地址使密度最大化的方式增加每个bin的连接数(在接近顺序bin $b$中，对等地址的后续位构成\gloss{balanced binary tree})。这样的安排是最优的，因为对于$d$的一个bin深度，节点能够中继所有的消息，因此在一跳中，目的地址的邻近顺序将增加$d$(见图\ref{fig:bindensity})。 


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/bindensity.pdf}
   \caption[本密度\statusgreen]{仓密度:对于以位$0$开始的覆盖地址的节点，PO仓$0$的饱和类型。\textbf{Top left}:具有单个对等点的“瘦”bin对搅拌没有弹性，只在一跳中增加$1$的PO。\textbf{Top right:}至少需要两个对等体来维护Kademlia拓扑;两个对等体不平衡时不能保证多阶跃。\textbf{Bottom left:}两个对等体均衡，保证一跳增加2个PO-s。\textbf{Bottom right:}均衡时四个对等体可以保证单跳增加$3$ PO-s。}
   \label{fig:bindensity}
\end{figure}

\subsubsection{考虑到底层的接近程度}
预计随着Swarm客户端不断进化和发展，节点在选择节点进行连接时可能会考虑吞吐量因素。在所有条件相同的情况下，地理位置接近的节点往往具有更高的吞吐量，因此从长远来看将是首选。这就是转发Kademlia如何隐式地感知底层拓扑\cite{heep2010r}。有关连通性策略的更详细讨论，请参阅\ref{spec:strategy:connection}。


\subsection{引导和维护Kademlia拓扑\statusgreen}\label{sec:bootstrapping}
 
\orange{基于新的蜂巢协议的返工}
 
本节讨论稳定的Kademlia拓扑是如何出现的。具体来说，每个节点必须遵循准确的引导协议才能达到饱和的Kademlia连接并维护它。加入\gloss{decentralised network}的节点最初应该是无知的，可能只通过一个已知的、没有先验知识的peer发起连接。由于这个原因，引导过程需要包含一个发现组件，在该组件的帮助下，节点之间可以交换关于彼此的信息。该协议被称为\gloss{hive protocol}，并在\ref{spec:protocol:hive}中正式指定。

\subsubsection{Bootnodes}

Swarm对引导节点没有不同的节点类型或操作模式。这意味着普通节点应该能够连接到网络上的任何节点，并引导它们所需的连接。为了不覆盖任何单个节点，应该避免指定一个特定的节点作为初始连接，并且引导节点相对于新幼稚节点的角色应该在参与节点之间实现理想的平衡。这是通过一个邀请系统或一个集中化的引导节点服务来实现的，该服务运行一个公共网关，通过在线对等点中随机选择的节点的bzz地址来响应一个API调用。

一旦连接到网络中的一个节点，hive协议将开始生效，而幼稚节点将了解其他节点的bzz地址，并可以开始引导其连接。

\subsubsection{建立连接}

最初，每个节点以0作为其\gloss{saturation depth}开始。随着饱和度的变化，节点不断向连接的节点通告其饱和度深度。当一个节点$A$收到企图建立一个新的连接从一个节点$B$,她通知每个节点的其他同行$B$连接到她唯一的顺序,每个对等的距离相对于连接节点$A$并不低于同行的广告饱和深度。通知总是被发送到与新连接共享邻近订单箱的对等端。正式地说，当$x$与同行$y$连接时，$x$会通知每一个同行是$\mathit{PO}(x, p) = \mathit{PO}(x, y)$还是$d_p\leq \mathit{PO}(y, p)$。特别是，通知包括完整的\gloss{overlay address}和\gloss{underlay address}信息(见\ref{spec:format:bzzaddress})。%
%
\footnote{不包括不希望转发消息和不希望构建健康的Kademlia的轻节点，请参阅\ref{sec:light}部分。 }

    

% \begin{figure}[htbp]
%   \centering
%   \caption[Hive protocol: bootstrapping and maintaining Kademlia topology \statusred]{Hive protocol: bootstrapping and maintaining Kademlia topology}
%   \label{fig:bootstrapping-kademlia}
% \end{figure}

\subsubsection{成熟的连接}

当节点连接的数量足够多时，一个bin就会饱和，节点的邻域深度就会开始增大。如果当前深度发生变化，节点就会向其他节点宣传当前深度，使其保持最新。随着深度的增加，节点得到的通知将越来越少。一旦节点找到了所有最近的邻居，并且已经饱和了所有的bin，就不需要新的节点了。因此，如果一个节点在一段时间内没有接收到新的peer，那么它就可以得出一个饱和的kdemlia状态。%
%
\footnote{虽然节点不需要知道网络中节点的数量。实际上，当节点停止接收到新的对等体地址一段时间后，节点可以有效地估计网络的大小:网络深度为$\log_2(n+1)+ d$，其中$n$为最近邻居的远程对等体数量，$d$为该邻居的深度。由此可知，只需将其取2的指数，即可估计出网络中的节点总数。}
%
我们可以根据接收到的最后一个新对等体的年龄来量化饱和的确定性，而不是硬性的截止日期和二元饱和状态。假设连接稳定，最终每个在线节点将了解其最近的邻居，并与他们连接，同时保持每个bin不超过$d$为空。因此，每个节点都收敛于饱和状态。如果没有新节点连接，即使对等连接发生变化，运行状况(Kademlia拓扑)也会保持。例如，一个节点不应该回到一个较低的饱和状态。这是通过在每个邻近订单箱中需要几个对等点来实现的。 

\section{群storage\statusgreen}\label{sec:kademlia-storage}

在本节中，我们首先展示了在Kademlia拓扑中具有准永久连接的网络如何支持\ref{sec:disc}中固定大小的数据库的\gloss{load balancing}、\gloss{distributed storage}。在\ref{sec:chunks}中，我们详细描述了块的一般要求，并介绍了实际的块类型。最后，在\ref{sec:redundancy-by-local-replication}中，我们采用邻域复制的\gloss{redundancy}作为搅拌阻力的基本措施。

\subsection{用于的分布式不可变存储chunks\statusgreen}\label{sec:disc}
 
在本节中，我们将讨论使用Kademlia覆盖路由的网络如何成为使用\glossplural{distributed hash table} (\glossplural{DHT})实现无服务器存储解决方案的合适基础。然后我们介绍\gloss{DISC}%
%
\footnote{盘是\gloss{distributed immutable store for chunks}。在早期的工作中，我们将这个组件称为“分布式原映像归档”(DPA)，然而，这个短语变得容易误导人，因为我们现在也允许不是其地址的原映像的块。}
% 
这是Swarm对DHT存储的狭义解释。这个模型 
对数据块施加了一些要求，并要求使用“上传”协议。 

按照Swarm的惯例，我们提供了这个首字母缩略词的一些解决方案，它们总结了最重要的特征:


\begin{itemize}
\item \emph{分散的存储和通信基础设施}, 
\item \emph{块的分布式不可变存储}, 
\item \emph{通过签名或内容地址实现数据完整性},
% \item \emph{可下载的奖励安全通信}
\item \emph{受智能合约激励的驱使}。 

\end{itemize}
 
\subsubsection{从DHT到DISC}
Swarm的\gloss{DISC}与我们更熟悉的\glossplural{distributed hash table}有许多相似之处。最重要的区别是，Swarm并不保留一个将要找到的\emph{在哪里}文件列表，而是直接使用最接近的节点\emph{存储文件本身的片段}。
在接下来的内容中，我们将回顾dht，并更详细地探讨与DISC的相似和不同之处。 
 
\glossupperplural{distributed hash table}使用覆盖网络实现分布在节点上的键值容器(参见图\ref{fig:DHT})。其基本思想是，将键空间映射到覆盖地址空间，并且容器中的键的值将通过其地址接近该键的节点找到。在最简单的情况下，假设这是与存储该值的键最近的单个节点。在一个具有Kademlia连接的网络中，任何节点都可以路由到其地址最接近密钥的节点，因此是一个\emph{查找}(即\ looking up the value belonging to a key) is reduced simply to routing a request.\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.7\textwidth]{fig/dht.pdf}
   \caption[分布式哈希表(dht) \statusgreen]{用于存储的分布式哈希表(DHTs):节点$D$(下载器)在步长$1$中使用Kademlia路由查询块地址附近的节点，在步长$2$中检索种子器信息。播种器信息用于直接联系节点$S$(播种器)，以请求块并在步骤$3$和$4$中交付它。}
   \label{fig:DHT}
\end{figure})

用于\gloss{distributed storage}的dht通常将内容标识符(作为键/地址)与可以提供内容\cite{ipfs2014, crosby2007analysis}的不断更改的种子列表(作为值)关联起来。但是，可以直接使用相同的结构:在Swarm中，存储在最接近地址的Swarm节点上的不是内容的位置信息，而是内容本身(参见图\ref{fig:disc})。 


\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.7\textwidth]{fig/disc.pdf}
   \caption[Swarm DISC:分布式不可变存储块\statusgreen]{Swarm DISC:用于块的分布式不可变存储。在步骤$1$中，下载节点$D$使用转发Kademlia路由从块地址附近的存储节点$S$请求块。在$2$步骤中，数据块使用向后的转发步骤沿着相同的路由发送。   }
   \label{fig:disc}
\end{figure}

\subsubsection{约束}
\gloss{DISC}存储模型对哪个节点存储什么内容有自己的看法，这意味着以下限制: 

\begin{enumerate}
    \item \emph{固定大小的块}——节点之间需要内容的负载均衡，通过将内容分割成大小相等的称为\glossplural{chunk}的单元(参见\ref{sec:chunks})来实现。
    \item \emph{同步}——无论哪个节点上传块，块都必须到达它们应该存储的位置(参见\ref{sec:push-syncing})。
    \item \emph{似是而非的推诿}—由于节点对其存储的内容没有发言权，因此应该采用一些措施作为法律保护的基础，让节点操作符貌似合理地否认知道(甚至能够知道)任何关于块内容的内容(参见\ref{sec:chunk-encryption})。
    \item \emph{垃圾收集}——由于节点提交存储任何接近它们的内容，因此需要有一种策略来选择在存在存储空间约束的情况下哪些块被保留，哪些块被丢弃(参见\ref{spec:strategy:garbage-collection})。 
\end{enumerate}

\subsubsection{块}\label{sec:chunks}

\glossupperplural{chunk}是Swarm网络层使用的基本存储单元。它们是地址与内容的关联。由于在Swarm (\ref{sec:retrieval})中检索假定块存储在其地址附近的节点中，因此块的地址也应该均匀分布在地址空间中，并且对其内容进行限制，大小大致一致，以达到公平平等的\gloss{load balancing}。

当检索块时，下载器必须能够验证给定地址的内容的正确性。这种完整性意味着保证与地址相关联的内容的唯一性。为了防止不必要的网络流量，第三方\glossplural{forwarding node}应该能够仅使用节点可用的本地信息来验证块的完整性。

寻址的确定性和无冲突性质意味着块作为键值关联是唯一的:如果存在一个带有地址的块，那么其他有效块不能有相同的地址;这个假设是至关重要的，因为它使块存储\gloss{immutable}，即\ there is no replace/update operation on chunks. Immutability is beneficial in the context of relaying chunks as nodes can negotiate information about the possession of chunks simply by checking their addresses. This plays an important role in the stream protocol (see\ref{sec:pull-syncing})，并证明DISC分辨率为\emph{块的分布式不可变存储}。

综上所述，块寻址需要满足以下要求:

\begin{enumerate}
    \item \emph{确定的}—启用本地验证。
    \item \emph{碰撞自由}——提供完整性保证。
    \item \emph{均匀分布}——提供负载均衡。
\end{enumerate}

在当前的Swarm版本中，我们支持两种类型的chunk: \glossplural{content addressed chunk}和\glossplural{single owner chunk}。 

\subsection{内容解决chunks\statusgreen}\label{sec:content-addressed-chunks}

\gloss{content addressed chunk}并不是一个有意义的存储单元，也就是说，它们可以只是拆分一个更大的数据块(文件)而产生的任意数据块。文件在上传时被分解成块，然后在下载时从块中重新组装的方法在\ref{sec:datastructures}中有详细说明。内容寻址群块的数据大小被限制为4千字节。使用这种小块大小的理想结果之一是，即使对于相对较小的文件，也可以进行并发检索，从而减少下载延迟。 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/content-addressed-chunk-3.pdf}
   \caption[内容解决chunk\statusgreen]{内容块。最多4KB的负载加上一个64位小端序编码的span构成块内容。然后，连接到跨度的有效负载的BMT散列将生成内容地址。}
   \label{fig:content-addressed-chunk}
\end{figure}

\subsubsection{二进制默克尔树哈希}

Swarm中的规范内容处理块称为\gloss{binary Merkle tree chunk} (\gloss{BMT chunk})。
BMT块的地址使用\ref{spec:format:bmt}中描述的\gloss{binary Merkle tree hash}算法(\gloss{BMT hash})计算。\gloss{BMT}中使用的基哈希是kecak256，其均匀性、不可逆性和抗碰撞性等属性都保留到\gloss{BMT hash}算法中。由于均匀性，一组随机的分块内容将生成均匀分布在地址空间中的地址，即\ imposing storage requirements balanced among nodes.dbdaa

BMT块地址是8字节跨度的散列和构建在底层数据的32字节段上的\gloss{binary Merkle tree} (\gloss{BMT})的根散列(参见图\ref{fig:BMT})。如果块内容小于4k，则计算散列，就像用最大4096字节的所有零填充了块一样。

这种结构允许具有32字节分辨率的紧凑\gloss{inclusion proofs}。包含证明是一个字符串是另一个字符串的子字符串的证明，例如，一个字符串包含在一个块中。包含证明是在特定索引的数据段上定义的，见图\ref{fig:chunk-inclusion}。当存储节点提供它们拥有块的证据时(参见\ref{sec:postage-lottery})，这样的Merkle证明也被用作监护权的证明。连同Swarm文件哈希(参见\ref{sec:files}和afaed)，它允许文件的对数包含证明，即\ proof that a string is found to be part of a file.\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/inclusion-proof.pdf}
\caption[块的紧凑段包含证明\statusgreen]{块的紧凑段包含证明。假设我们需要证明块的第26段(黄色)。BMT的橙色哈希是从数据段到根的路径上的姐妹节点，构成了证明所需的部分。当这些参数与根哈希值和段索引一起提供时，就可以验证证明。需要应用$i$证明项的那一边取决于索引的二进制表示的$i$-th位(从最低有效位开始)。最后，将span添加到前面，并且得到的散列应该与块根散列匹配。}
\label{fig:chunk-inclusion}
\end{figure}


\subsection{尔格chunks\statusgreen}\label{sec:single-owner-chunks}

使用\glossplural{single owner chunk}，用户可以将任意数据分配到一个地址，并使用其数字签名验证块的完整性。地址被计算为\gloss{identifier}和\gloss{owner}的哈希值。块内容显示在一个结构中，该结构由标识符、\gloss{payload}和验证标识符和有效负载关联的签名组成(参见图\ref{fig:single-owner-chunks})。

\begin{itemize}
    \item \emph{内容}:
\begin{itemize}
    \item \emph{标识符}—32字节任意标识符， 
    \item \emph{签名}—一个EC签名的65字节$\langle r,s,v \rangle$表示(32+32+1字节)，
    \item \emph{跨度}—8字节小端二进制的uint64块跨度，
    \item 最大4096字节的规则块数据。
\end{itemize}
    \item \emph{地址}——标识符+所有者帐户的kecak256哈希值。
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/single-owner-chunk.pdf}
   \caption[尔格chunk\statusgreen]{尔格块。数据块内容由头和最多4KB的有效负载组成。最后一个报头字段是前缀的8字节跨度，就像在内容寻址块中一样。头两个报头字段提供完整性的单一所有者验证:一个标识符和一个签名，对标识符和span和payload的BMT散列进行签名。地址是id和签名者帐户的散列。}
   \label{fig:single-owner-chunks}
\end{figure}

\gloss{single owner chunk}的有效性是通过以下流程检查的:

\begin{enumerate}
    \item 将块内容反序列化为标识符、签名和有效载荷字段。
    \item 构造由标识符和有效负载的\gloss{BMT hash}组成的预期纯文本。
    \item 使用纯文本从签名中恢复所有者的地址。
    \item 根据块地址检查标识符和所有者(期望地址)的哈希值。
\end{enumerate}

单所有者块提供了一个虚拟分区，将部分地址空间划分为与单所有者关联的子空间。检查它们的有效性实际上是验证所有者对具有正确标识符的地址具有写访问权。

正如有效负载的跨度和长度所建议的，单个所有者块可以封装常规内容寻址块。任何人都可以简单地将常规块重新分配到由标识符指定的子空间中的地址(参见\ref{sec:notification-requests})。


需要注意的是，对于单个所有者块来说，完整性的概念比内容处理块的完整性要弱一些:毕竟，原则上可以将任何有效负载分配给标识符并进行签名。尽管如此，鉴于块只能由单个所有者(签名所需的私钥的所有者)创建这一事实，期望唯一性保证是合理的，因为我们希望节点希望遵守应用程序协议以获得所需的结果。然而，如果私钥所有者用相同的标识符签署两个不同的有效负载，并将两个块上传到Swarm，网络的行为是不可预测的。可以在第(3)层采取措施来缓解这一问题，稍后将在\ref{sec:feed-integrity}中详细讨论。

对于两种类型的块，完整性被链接到无冲突的散列摘要，这些散列摘要要么来自单个所有者，要么来自由签名验证的任意标识符，或者直接来自内容。这证明了DISC首字母缩写为\emph{通过签名或内容地址实现数据完整性}的决议是合理的。

\subsection{块encryption\statusgreen}\label{sec:chunk-encryption}

块在默认情况下应该加密。除了客户端对机密性的需求之外，加密还有两个更重要的作用。(1)加密对块内容的混淆提供了一定程度的\gloss{plausible deniability};全面使用它会让防守变得更强。(2)选择任意加密密钥的能力以及均匀分布的特性提供了\gloss{mining chunks}的可预测方法，即\ generating an encrypted variant of the same content so that the resulting chunk address satisfies certain constraints, e.g. is closer to or farther away from a particular address. This is an important property used in (1) price arbitrage (see\ref{sec:pricing})和(2)有效使用邮票(见\ref{sec:postage-stamps})。


\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{fig/chunk-encryption.pdf}
    \caption[群中的块加密\statusgreen]{群算法中的块加密。采用改进的反模式分组密码的对称加密。明文输入是用随机字节填充到4千字节的内容。span字节也被加密，就像它们是有效负载的延续一样。}
    \label{fig:chunk-encryption}
\end{figure}


块加密(参见图\ref{fig:chunk-encryption})在\ref{spec:format:encryption}中正式指定。小于4千字节的块用随机字节填充(从块加密种子生成)。使用基于xor的块密码对完整块明文进行加密和解密，并使用相应的对称密钥进行加密和解密。为了不通过引入额外的加密原语来增加攻击面，分组密码选择在计数器模式下使用kecak256，即对每个32字节的连续段将密钥与计数器散列在一起。为了允许有选择地公开作为加密文件一部分的各个段，而不泄露关于文件其余部分的信息，我们添加了一个额外的哈希步骤来派生块中的某个段的加密密钥。该方案易于在\gloss{EVM}中实现，且成本低廉，可用于约束明文加密的Swarm内容的智能合约。

块跨度的附加元数据编码也被加密，就好像它是块的延续，即使用计数器128。加密的块内容使用\gloss{BMT hash}摘要哈希，就像未加密的块内容一样。从\gloss{span value}中可以猜到一个块被加密了，但除此之外，在网络层中，加密的块的行为与未加密的块完全相同。

\glossupperplural{single owner chunk}也可以被加密，这仅仅意味着它们封装了一个加密的常规块。因此，它们的payload和span反映了上面描述的chunk内容加密，用标识符签名的哈希值就是加密的span和payload的\gloss{BMT hash}，即与包装的chunk相同。

\subsection{replication冗余\statusgreen}\label{sec:redundancy-by-local-replication}

有一种弹性的方式来请求数据是很重要的。为了实现这一目标，Swarm采用了纵深防御的方法。在由于转发问题导致请求失败的情况下，可以与另一个对等节点重试，或者为了防止这些情况发生，节点可以立即启动并发\glossplural{retrieve request}。但是，如果存储数据块的所有最后一个节点都从网络退出，那么这种回退选项就不可用了。因此，冗余对于保证数据的可用性至关重要。如果最近的节点是请求数据的唯一存储节点，并且它退出了网络，那么就没有办法检索内容。这个基本场景的处理方法是确保每组\gloss{nearest neighbours}都持有最接近其中任何一个块的每个块的副本，复制块的存储，从而提供数据冗余。 

\subsubsection{最近社区的大小}

如果在存储节点上定义了Kademlia连接，那么在具有Kademlia拓扑的网络中存在一个深度$d$，这样(1)每个小于$d$的\gloss{proximity order bin}包含至少$k$存储节点，(2)所有具有\gloss{proximity order} $d$或更高的\glossplural{storer node}都是实际连接的节点。为了保证数据冗余，我们可以在这个定义中增加一个标准，即(3)$d$定义的最近邻必须包含至少$r$对等体。

让我们将\gloss{neighbourhood size} $\mathit{NHS}_x(d)$定义为节点$x$的深度$d$定义的邻域基数。
然后,节点与冗余因素Kademlia连接$r$如果存在一个深度$d$(1)每个邻近秩序本不到$d$包含至少$k$仓库保管员同行($k$本密度参数见\ref{sec:bindensity}),和(2)所有仓库保管员节点与邻近秩序$d$或更高版本实际上是连接同行,和(3)$\mathit{NHS}_x(d)\geq r$。

然后我们可以采用最高深度$d'$，使(1)和(2)得到满足。这样的$d$保证存在，并且\glossupper{hive protocol}总是能够引导它。当我们减小$d'$时，不同邻域的数量成比例增长，因此对于任何不大于网络规模$r\leq N=\mathit{NHS}_x(0)$的冗余参数，都会有一个最高的$0<d_r\leq d'$，使$\mathit{NHS}_x(d_r)\geq r$。因此，\gloss{redundant Kademlia connectivity}总是可以实现的。



对于特定的冗余，完全连通邻域的面积定义了\gloss{area of responsibility}。职责区域的接近顺序边界为节点定义了一个\gloss{radius of responsibility}。如果块地址在节点的责任范围内，则存储节点被称为\emph{负责任的}(存储)块。

在这一点上，展示社区及其结构已经具有指导意义，见图\ref{fig:nearest-neighbours}。 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/nearest-neighbours-2.pdf} \\\includegraphics[width=\textwidth]{fig/asymmetric-nodes2.pdf}
   \caption[最近的邻居\statusgreen]{最近的邻居。\textbf{Top}:每个PO定义一个邻域，节点的邻域深度(黑圈)定义为最高的PO，使得邻域至少有R=4个peer(冗余参数)，并且所有浅bins都是非空的。\textbf{Bottom}:不对称的邻域。橙色节点的最近邻居包括黑色节点，但不包括黑色节点。}
   \label{fig:nearest-neighbours}
\end{figure}


\subsubsection{多余的可回收性}

如果块是可检索的，则称其具有$r$度的\gloss{redundant retrievability}，并且即使负责该块的任何$r$节点离开网络后，该块仍将保持这种状态。到目前为止，所提出的幼稚方法需要最接近的单个节点来保存内容，这种方法可以解释为零度可检索性。如果在其职责范围内的节点完全复制了它们的内容(参见\ref{sec:pull-syncing})，那么Swarm DISC中的每个块都可以通过$r$度冗余检索。让我们取最接近块$c$的节点$x$。由于它具有与冗余$r$的Kademlia连接，因此有$r+1$节点负责邻里中的块完全连接并复制内容。$r$负责的节点退出后，只剩下一个节点仍然拥有块。但是，如果在$r$节点离开时保持了Kademlia连通性，则网络中的任何其他节点都可以继续访问该节点，因此块仍然是可检索的。现在，对于网络来说，为了确保所有的数据块都将以$r$度保持冗余检索，由网络重组形成的新邻居组成的节点必须通过重新同步它们的内容来满足协议的复制标准。这被称为\gloss{eventual consistency}的保证。

\subsubsection{资源约束}

假设(1)转发策略沿\glossplural{stable node}转发请求;(2)存储策略，即$r$存储节点中最邻近的每个节点存储其地址在其负责半径内的所有块。只要这些假设有效，即使$r$存储节点同时脱机，每个块都是可检索的。对于(2)，我们仍然需要假设最近邻集中的每个节点都可以存储每个chunk。然而，实际上，所有节点都有资源限制。随着时间的推移，上传到Swarm上的不同区块的总量将会无限增加。除非总存储容量稳步增加，否则我们应该预期Swarm中的节点只能存储块的一个子集。一些节点将达到存储容量的限制，因此将面临一个决定，是通过同步停止接受新块，还是通过删除一些现有块来腾出空间。

从本地存储中清除块的过程称为decfe。决定选择哪些块进行垃圾收集的过程称为\gloss{garbage collection strategy}(参见\ref{spec:strategy:garbage-collection})。对于利润最大化的节点，它认为最好对预测未来利润最低的块进行垃圾收集，为了实现利润最大化，节点需要正确地进行预测(参见\ref{sec:postage-stamps})。因此，为了考虑到这些容量约束，我们将引入\gloss{chunk value}的概念，并使用最小值约束修改我们的定义:

在Swarm的DISC中，始终存在一个块值$v$，使得每个值大于$v$的块都是可检索的，并且最终(在同步后)以$r$度冗余可检索。

这个值理想地对应于保存上传者需要指示的块的相对重要性。为了让存储节点尊重它，该值也应该与块的盈利能力一致，因此在上传的定价中表示(参见\ref{sec:capacity-pressure})。

% \subsection{}\label{sec:}

\section{推拉:块检索和syncing\statusgreen}\label{sec:push-and-pull}
\green{}
在本节中，我们将演示区块是如何在网络中移动的:当它们被上传时，如何将它们推送到它们所属的邻居中的存储节点，以及当它们被下载时，如何将它们从存储节点中拉出。

\subsection{Retrieval\statusgreen}\label{sec:retrieval}

在分布式块存储中，如果消息在请求者和最接近块的节点之间是可路由的，则称块为\gloss{accessible chunk}。向块地址发送检索请求消息将到达该节点。由于\gloss{eventual consistency}，离块地址最近的节点将存储块。因此，在具有健康Kademlia拓扑的\gloss{DISC}分布式块存储中，每个节点都可以访问所有块。

\subsubsection{块交付}

对于检索，需要用一个流程来补充可访问性，以便将内容发送回请求节点，最好只使用块地址。至少有三种替代方法可以实现这一点(见图\ref{fig:chunk-delivery}):

\begin{enumerate}
    \item \gloss{direct delivery}—区块交付通过直接底层连接发送。 
    \item \gloss{routed delivery}——块传递使用路由作为消息发送。
    \item \gloss{backwarding}——块传递响应只是遵循请求被转发的路径，只是向后一直到发起者。
\end{enumerate}


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/chunk-delivery.pdf}
   \caption[交付块的可选方法:直接、路由和向后\statusgreen]{交付块的可选方法。\textbf{Top:} \emph{直接交付}:通过直接底层连接。bfed \emph{路由交付}: chunk使用Kademlia路由发送。\textbf{Bottom:} \gloss{backwarding}重用请求路由路径上的精确对等点来中继传递响应。}
   \label{fig:chunk-delivery}
\end{figure}

首先，采用明显的直接传递，通过较低层次的网络协议一步完成数据块的传递。这就需要一个特别的连接，以提高延迟来换取隐私安全性的恶化。%
%
\footnote{Beeline传输有一些优点，例如节省带宽和更好的延迟，所以我们不完全排除实现它的可能性。 
}
其次，使用路由传递，块在发送时使用从存储者的角度确定的特别路由返回给它的请求者。无论是直接传递还是路由传递，允许独立于请求路由进行路由传递都假定存储节点和路由节点(至少部分)知道请求者的地址，因此，这些方法会泄漏标识请求者的信息。然而，对于转发——向后的Kademlia，这就没有必要了:存储节点用交付响应请求对等体，而中间的\glossplural{forwarding node}则记住哪个对等体请求了哪个块。当数据块被交付时，它们将其传递回直接请求者，以此类推，直到它最终到达最初请求它的节点。换句话说，块交付响应只是遵循请求路由返回到发起者(参见图\ref{fig:request-response})。因为它是转发的反向，所以我们可以戏称它为\gloss{backwarding}。Swarm使用了这个选项，这使得它可以不以任何形式透露请求者的身份，因此Swarm完全实现了\gloss{anonymous retrieval}。 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/request-response-forwarding.pdf}
   \caption[反向:转发Kademlia 时匿名请求-响应往返的模式\statusgreen]{反向:转发Kademlia时匿名请求-响应往返的模式。前面的省略号表示请求者和目标共享的前缀，长度为$n$位。末尾的省略号表示与路由无关的部分地址，因为在该深度节点已经是唯一的。请求使用通常的Kademlia转发，但途中的中继节点记住请求来自的对等点，以便当响应到达时，它们可以\emph{落后的}它(即\ pass it back) along the same route.}
   \label{fig:request-response}
\end{figure}

在检索协议中默认的请求者匿名是Swarm坚持的一个关键特性，以确保用户隐私和抗审查访问。

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/retrieval.pdf}
   \caption[检索\statusgreen]{检索。节点$D$ (Downloader)向块的地址发送一个检索请求。检索使用转发Kademlia，请求通过转发节点$F_0$，…， $F_n$，一直到节点$S$，最接近块地址的存储节点。然后，通过沿着相同的路径将数据块传递回下载器。}
   \label{fig:retrieval}
\end{figure}

如图\ref{fig:retrieval}所示，通过后退实现检索的通用解决方案在垃圾邮件保护、扩展和激励方面有进一步的好处，这些现在将在本节的其余部分讨论。

\subsubsection{对未请求的块的保护}

为了记住请求，\gloss{forwarding node}需要创建一个它承担一些成本的资源(它占用内存中的空间)。没有进行相应交付的请求最终应该被垃圾收集，因此需要定义一个时间周期，在此期间这些请求是活动的。下游对等点也需要被告知此请求的超时时间。这是有意义的，因为请求的发起者希望将生存时间附加到请求，以指示它将等待响应多长时间。

发送未经请求的数据块是一种犯罪行为，因为它可能导致\gloss{denial of service (DoS)}。通过记住一个请求，节点能够识别未经请求的块发送，并惩罚发送它们的节点。请求过期后交付的块将被视为未请求的。由于节点之间在评估过期时间时可能存在一些差异，因此需要对未经请求的块交付有一定的容忍，但如果它们超过了转发请求的特定(但仍然很小)百分比，违规的对等端将被断开连接并列入黑名单。这种地方制裁是鼓励遵守协议的最简单和最简单的方法(参见\ref{sec:sanctions})。 

\subsubsection{Rerequesting}

有很大一部分群集节点可能无法始终稳定在线。如此高的生产情况是有问题的,如果我们使用的天真的策略将请求转发给任何一个接近节点:如果路径上的节点离线交付之前完成,然后请求-响应往返坏了,有效地呈现请求的块无法复原。如果与被请求的对等端连接被中断，承诺为一个块支付将被认为是无效的，因此从另一个节点重新请求该块没有害处(参见\ref{spec:strategy:forwarding})。


\subsubsection{超时vs未找到}

注意，在Swarm中没有明确的对未被发现的块的负面反应。原则上，最接近检索到的地址的节点可以告诉该地址没有块，并可以发出“not found”响应，但这不是我们所希望的，原因如下。虽然最近的节点块可以验证这一块确实不是在网络中的位置应该是,远离所有节点块不能令人信服地认为这是他们不能验证它直接和积极的证据对块的可回收性获得以后回顾可否认的可信。

总之，只要交付有可能为存储商创造收益，最好的策略是保持等待请求打开，直到它超时，并做好准备，以防chunk出现。有几种方法可以使数据块在请求后到达:(1)从现有的对等点同步(2)出现一个新节点或(3)如果请求先于上传，例如请求者已经“订阅”了一个单一的所有者地址(参见\ref{sec:messaging})以减少检索延迟。这在概念上不同于通常的基于服务器-客户端架构，在这种架构中，期望资源在主机服务器上或不在主机服务器上是有意义的。 
 

\subsubsection{投机取巧的缓存}

使用块传递响应的回退来检索请求也启用了\gloss{opportunistic caching}, \gloss{forwarding node}接收一个块，然后保存块，以防再次请求。这种机制对于确保Swarm自动扩展流行内容的存储和分发至关重要(参见\ref{sec:caching})。

\subsubsection{激励}

到目前为止，我们已经证明，通过使用检索协议并保持Kademlia连通性，网络中的节点能够检索块。然而，由于转发正在消耗一种稀缺资源(带宽)，而没有提供考虑这种带宽使用的能力，网络的可靠性将取决于搭便车和利他主义的比例。为了解决这个问题，在\ref{sec:incentivisation}部分，我们将概述一个与网络中节点的期望行为相一致的经济激励系统。当节点运营商采用这些利润最大化策略时，它们会产生有利于整个网络用户的紧急行为。
 
\subsection{推动syncing\statusgreen}\label{sec:push-syncing}
 
在前几节中，我们介绍了如何将维护Kademlia覆盖拓扑的节点网络用作分布式块存储，以及如何使用转发Kademlia路由来定义检索块的协议。
在讨论检索时，我们假设块位于与其地址最接近的节点上。本节描述负责实现这个假设的协议:确保在将数据块上传到任意节点后，将其交付到指定的存储器。

这个网络协议称为\gloss{push syncing}，类似于块检索:首先，块通过与检索请求相同的路由被转发到最接近块地址的节点，然后作为响应，\gloss{statement of custody receipt}沿着相同的路径传递回来(参见图\ref{fig:push-syncing})。存储器向\gloss{uploader}发回的托管声明表明，块已到达可普遍检索的邻近区域。通过跟踪上传的每个组成块的这些响应，上传者可以在共享或发布上传地址之前，确保他们的上传被网络中的任何节点完全检索。保持这些块的计数和接收作为\emph{进度条}的后端，\emph{进度条}可以显示给上传者，对它们的数据在网络上的成功传播给出积极反馈(参见\ref{sec:upload}和\ref{spec:api:tags})。


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/push-sync.pdf}
   \caption[推动同步\statusgreen]{推动同步。节点$U$(上传器)将块推同步到块的地址。Push-sync使用转发，所以数据块通过转发节点$F_0$，…， $F_n$，一直到节点$S$，节点$S$是最接近数据块地址的存储节点(箭头表示通过直接的点对点连接传输数据块)。然后，由$S$签名的托管收据声明将沿着相同的路径返回，作为向上传者的确认。}
   \label{fig:push-syncing}
\end{figure}

托管声明由声称最接近该地址的节点签署。
与检索协议中的下载者类似，上传者的身份也可以保持隐藏，因此转发Kademlia可以实现\gloss{anonymous uploads}。

另一个相似之处是，为了允许返回响应，节点应该记住哪个peer发送了特定的块。当期望托管响应的声明时，此记录应该持续一小段时间。当这个周期结束时，记录将被删除。与记录不匹配的托管语句被认为是不请求的，并且只允许与对等端进行的所有推同步流量的一小部分。超过这个容忍阈值将被禁止断开连接并列入黑名单(参见\ref{sec:sanctions})。

在本节中，我们描述了如何使用带有响应反向的Forwarding Kademlia路由的网络协议组织块上传的物流。然而，这个解决方案是不完整的，除非它有一致的激励:遵循这个协议的策略应该是激励的，DoS滥用应该是抑制的。稍后将在\ref{sec:postage-stamps}和\ref{sec:push-sync-incentives}中详细讨论这些问题。

\subsection{拉syncing\statusgreen}\label{sec:pull-syncing}

\glossupper{pull syncing}协议负责以下两个属性: 

\begin{itemize}
    \item \emph{最终一致性}——当拓扑因节点变动或新节点加入而发生变化时，同步相邻节点。
    \item \emph{最大的资源利用率}—节点可以从它们的对等节点中提取块来填充它们的剩余存储。%
％
\footnote{从节点的盈利能力来看，最大的存储利用率可能不是最佳的。换句话说，存储节点具有最优存储容量，这取决于从它们请求内容的频率。这意味着，在实践中，为了最大化利用存储容量，需要操作人员运行多个节点实例。}
\end{itemize}

拉同步是以节点为中心的，而不是以块为中心的，例如，它确保一个节点的存储被填满，以及在邻近区域内同步块。当两个节点连接时，它们将开始双向同步，以便在每个对等连接上都有双向块流量。两个方向的同步由不同和独立的\emph{流}(参见\ref{spec:protocol:pull-sync})管理。在流的上下文中，流的消费者被称为\gloss{downstream peer}或客户端，而提供者被称为\gloss{upstream peer}或服务器。

当两个节点连接并参与\gloss{chunk synchronisation}时，上游对等端提供它在每个邻近顺序bin的数据流中本地存储的所有块。为了接收更接近下游对等体而不是上游对等体的块，下游对等体可以订阅上游对等体在其Kademlia表中所属的邻近顺序bin的块流。如果对端连接在最近邻居深度$d$内，客户端将订阅接近顺序为bin $d$或更大的所有流。结果，同事们最终复制了属于他们职责范围的所有部分。

拉同步服务器的行为被称为流协议中的\gloss{stream provider}(参见\ref{spec:protocol:pull-sync})。节点通过使用不断增加的存储计数(称为\gloss{bin ID})对本地存储块进行索引来跟踪它们的存储时间。对于每个邻近指令箱，上游对等端按照存储时间戳的降序顺序提供流块。作为在每个对等体连接上同步流的结果，一个块可以从多个上游对等体同步到下游对等体。为了节省带宽不发送数据块已经同行,流协议实现了往返:发送块之前,上游同行提供一批块确定的地址,而下游反应与声明块批提供他们真正需要的(参见图\ref{fig:pull-syncing})。注意，下游对等端根据块地址决定是否拥有块。因此，该方法非常依赖于在\ref{sec:chunks}中讨论的块完整性假设。


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/pull-sync.pdf}
   \caption[把同步\statusgreen]{把同步。节点不断地同步它们最近的邻居。如果它们有空闲容量，它们也会从邻域深度以外的对等体中拉出属于较浅bins的同步块。}
   \label{fig:pull-syncing}
\end{figure}

在对等连接的上下文中，如果客户机已经同步了上游对等的所有块，那么它就被称为\emph{同步}。注意，由于磁盘容量的限制，节点必须设置一个值截断，因此“所有块”读取为“所有值大于$v$的块”的简写($v$是一个常数排序函数，其起源将在\ref{sec:capacity-pressure}中稍后讨论)。为了让一个节点保证存储所有大于$v$值的块，它的所有邻居必须存储所有大于$v$值的块。换句话说，同步的节点从它们的存储节点中继承这个值的最大值。

如果块是按照存储的顺序同步的，这可能不会导致节点总是拥有最有利可图(最常被请求的)块。因此，根据上游对等体从最流行的块开始同步块，并在达到存储容量时完成同步，可能是明智的。通过这种方式，节点有限的存储空间将得到优化。同步和垃圾收集将在\ref{sec:postage-stamps}和\ref{sec:capacity-pressure}中进一步讨论，并在\ref{spec:strategy:pull-sync}中指定统一的客户端策略。

为了结束本节，我们展示了如何在一个健康的Swarm中满足\gloss{eventual consistency}的标准。在任何节点的本地存储中找到的块在被同步到它们的存储器后将成为可检索的。这是因为只要网络中的对等体把数据块拉得离它们更近，而不是离上游对等体更近，每个数据块就会传播一条在推同步协议中也被视为有效转发路径的路由。如果添加新节点，旧节点退出，邻域就会发生变化，但只要本地冗余足够高，使得流失量不会导致之前可检索的块不可检索，邻域最终会复制它们的内容，冗余就会恢复。考虑一个不太可能发生的事件，即一个全新的邻居形成了，而原本持有属于这个邻居的内容的节点最终被排除在外，因此这些块暂时不可用。即使在这种情况下，只要有一个节点链在相关容器上运行拉同步流，冗余可检索性最终就会恢复。

\subsection{光nodes\statusgreen}
\label{sec:light}

\gloss{light node}的概念是指低带宽环境所必需的一种特殊操作模式，例如低吞吐量网络上的移动设备或只允许瞬态或低容量存储的设备。

一个节点被认为是轻的，因为它没有完全参与在前面章节中详细描述的常规协议，即检索、推同步或拉同步。

如果一个节点的带宽环境受到限制，或者以任何方式维持底层连接的能力有限，那么它就不能转发符合Kademlia路由规则的消息。它需要与它的对等体进行通信，这样它们就不会将消息转发给它。

由于Swarm中的所有协议都是模块化的，一个节点可以独立地开启或关闭任何协议(取决于容量和收益需求)。举个例子，当一个节点没有可用存储空间，但有空闲带宽时，可以只作为转发节点参与。当然,在关闭协议技术上是可行的,一个节点必须随时考虑到这一事实他/她的同事期待一定程度的服务如果这是广告,不得接受一些服务是关闭和选择不与该节点进行交互。

由于转发可以获得收入，这些节点仍然可能受到激励接受检索请求。但是，如果轻节点在邻近顺序bin $p$之上有Kademlia连接(即它们连接到$d$深度的$r$节点的最近邻内的所有存储节点，并且从$p$到$d$的每个邻近顺序bin中至少有一个节点)，他们可以为此做广告，从而参与转发。

当他们想要检索或推块时，如果块地址落在没有对等点的接近顺序bin中，他们可以在另一个bin中选择一个饱和的对等点。尽管这可能会导致一个虚假的跳(消息目的地到最新对等点的距离不会因为中继而增加)，Kademlia的假设仍然是有效的，即路由可以在对数步骤中完成。

被宣传为存储器/缓存节点的节点被期望存储特定值以上的所有块。为了保持一致性，他们需要同步他们职责范围内的内容，这就需要他们运行pull-sync协议。这对于有抱负的存储节点也是如此，这些存储节点将在线提供可用的存储，并开放pull-sync流来填充它们的存储容量。在此过程的早期阶段，节点与其他完整存储节点同步是没有意义的。但是，对于它们来说，与其他类似的新节点同步仍然很有用，特别是当存储节点的带宽达到最大时。

这里的关键是，对于冗余和跳数的工作，轻节点不完整，不饱和的Kademlia表不应该被其他节点计算到饱和。


\chapter{激励}\label{sec:incentivisation}
群网络由许多独立的节点组成，运行着实现群协议的软件(参见\ref{spec:protocol}章节)。重要的是要认识到，即使节点运行相同的协议，网络的应急行为不是由协议单独保证的;由于节点是自治的，它们基本上可以“自由”地以任何方式对对等节点的传入消息作出反应。
然而，让一个节点以一种有利于网络期望的紧急行为的方式作出反应是有利可图的，而以一种有害的方式作出反应则是昂贵的，这是可能的。广义地说，在Swarm中，这是通过使价值从使用网络资源的节点(\glossplural{net user})转移到提供网络资源的节点(\glossplural{net provider})来实现的。 


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/incentive-design-3.pdf}
\caption[激励设计\statusgreen]{激励设计}
\label{fig:incentives}
\end{figure}

% The rest of this chapter is concerned with describing the desired emergent behaviour of the network (\ref{sec:emergent_behavior}), after which we describe the actions which incur costs and those that provide value (\ref{sec:cost_benefit}). Finally, we proceed by describing the incentive mechanisms which ensures that costs are borne as directly as possible by the initiator of the action, with benefits flowing to the nodes who provided the initiator with the expected outcome, ultimately facilitating the desired emergent behavior (see \ref{sec:incentive_mechanisms}).

% \section{Incentive design \statusred}
% \wip{foundational requirement + analysis} 
% \subsection{WIP Desired emergent behavior \statusred}\label{sec:emergent_behavior}
% \subsection{WIP Analysis on expected costs and benefits of actions \statusred}\label{sec:cost_benefit}
% \subsection{WIP Proposed incentive mechanisms \statusred}\label{sec:incentive_mechanisms}
% This section will constitute most of the sections which are already described below.


\section{分享bandwidth\statusgreen}

\green{}

\subsection{服务和中继的激励机制\statusgreen}\label{sec:incentives-relaying}

\green{}

\subsubsection{转发卡德米利亚和反复交易}

块的检索最终是由访问内容的人发起的，因此，与检索相关的所有成本都应该由他们承担。虽然在今天的网络是“免费”的时候，付费检索可能听起来不像一个流行的想法，但当前网络的许多问题源于消费者无法直接与内容发布者分享托管和分销的成本。原则上，块的检索可以被视为一个功能单元，其中存储者充当服务提供者，请求者充当消费者。由于服务是由提供者提供给使用者的，因此使用者应该向提供者提供补偿。这种直接交易通常要求交易者彼此都知道，因此，如果我们要保持下载的匿名要求，我们必须以一种新颖的方式将补偿概念化。

当我们使用Forwarding Kademlia时，块检索包含了由转发节点执行的一系列转发操作。由于这些是独立的行动者，已经有必要鼓励每一个独立的接力行为。重要的是，如果只有继电器的实例是重要的，那么，不管会计和补偿的细节(参见\ref{sec:accounting})，事务器都被限制到连接的节点。鉴于曾经连接的对等点集是跨会话的准永久集，这允许我们在重复交易的上下文中构建交互。这样的环境总是会给相关各方带来额外的动机，促使他们友好相处。优先选择显示未受污染的历史记录的同行是合理的。此外，由于这种准永久集对网络大小是对数的，因此与对等点重复交互可能需要的任何簿记或区块链契约都是可管理的，从而提供了一个可伸缩的解决方案。反过来说，我们可以说，保持与可管理的对等点数量的平衡，以及请求起源的模糊性是节点连接有限的原因，也就是说，它们选择更精简的Kademlia bins。

\subsubsection{反向响应收费}

如果接受一个检索请求已经构成了转发节点的收入，即在响应交付之前触发了一个计入下游peer的计费事件，那么它就产生了一个不转发请求的错误动机。将请求收益满足条件设置为成功检索是很自然的解决方案:只有当请求的块被返回给它的请求者时才触发会计事件，参见图\ref{fig:retrieval-payment}。


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/retrieval-payment.pdf}
   \caption[开始鼓励检索\statusgreen]{开始鼓励检索。节点$D$ (Downloader)向块的地址发送一个检索请求。检索使用转发，因此请求通过转发节点$F_0$，…， $F_n$，一直到节点$S$，最接近块地址的存储节点。数据块是通过沿着相同的路径返回给下载器的。接收到块响应将触发一个记帐事件。}
   \label{fig:retrieval-payment}
\end{figure}

然而，如果请求没有代价，那么就可以为不存在的块(随机地址)发送许多非法请求。通过对发送过多请求而请求不存在的块(参见\ref{sec:sanctions})的对等端施加制裁，很容易缓解这一问题。

一旦节点发起(启动或转发)请求，如果块在定义的\gloss{time to live} (\gloss{TTL})内交付，它将承诺为该块支付费用，因此当块被传递回来时，不会阻止及时交付。这种承诺也阻止了节点轻率地向太多的对等点要求一个区块，因为如果多个对等点响应交付，每个节点都必须付费。


\subsection{块检索的定价协议\statusgreen}\label{sec:pricing}

\green{}

接下来，我们描述了在群网络中，节点用来传递块的价格的协议。在此协议的基础上，希望在服务质量和价格方面与其他节点竞争的节点可以实现策略(参见\ref{spec:strategy:pricing})。 

\subsubsection{价格发现}\label{sec:retrieval-price-discovery}

该协议的主要优点是，它允许价格发现机制仅基于本地决策，这是必要的原因如下:允许节点通过价格表达其成本结构，将使价格和质量上的竞争，最终使终端用户受益。(2)带宽资源的需求由于使用或连接的波动而不断变化。(3)能够直接对变化作出反应就创造了一个自我调节系统。

实际上，如果没有这种可能性，节点运营商可能会在成本上升时决定关闭其节点，或者相反，当成本或需求下降时，终端用户可能会在很长一段时间内多付费用，而节点没有竞争压力来相应地降低价格。

带宽是一种“即时满足”的服务，因此立即确认并核算其成本是合理的。由于很难设想在带宽的总体需求和供应中存在任何外部性或非线性，一种定价机制既能提供(1)高效和即时的信令，又能提供(2)以最小的交换和发现成本进行竞争性选择，最有可能容纳导致全局最优资源配置的策略。

为了实现这一点，我们引入了一个协议消息，可以将这些价格传递给上游对等点(参见\ref{spec:protocol:retrieval})。我们可以将此消息概念化为对请求的替代响应。节点为每个邻近距离维护与每个对等点相关的价格，因此当它们发出检索请求时，它们已经知道如果下游对等点在生存周期内成功交付有效块，它们将支付的价格。然而，限制价格信号只是为了响应是没有意义的:无论对等方决定改变价格的原因是什么，交换这一信息都符合双方的利益，即使存在需要响应的请求。为了防止用价格变化消息淹没上游对等体的DoS攻击，价格消息的速率是有限的。行为良好且定价具有竞争力的节点受到同行的青睐;如果一个节点的价格设置得太高，或者其价格比网络中其他节点的波动性大得多，那么对等节点就不太愿意向它们请求数据块。%
%
\footnote{虽然这表明不合理的定价是由市场力量处理的，但为了防止由于价格剧烈波动而导致的灾难性连接变化，可能需要在协议级别强制限制变化速率。 }

为了简化推理，我们假设默认价格为零，对应于免费服务(利他策略，参见\ref{spec:strategy:pricing})。 

\subsubsection{近似的差别定价}\label{sec:diff-pricing-prox}

如果一个区块的价格在所有邻近区域都是相同的，那么节点除了缓存区块并通过转售获得收入之外，就没有转发请求的真正动机。对于新块，这个选项很难证明是正确的，特别是当它们处于节点的浅接近顺序时，它们不太可能被请求。更重要的是，如果区块的定价在邻近指令中是统一的，那么串通的节点就可以生成区块流量，并准确地接收它们发送的数据，这实际上是一种免费的DoS攻击(参见图\ref{fig:ddos-uniform-price})。

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/ddos-uniform-price.pdf}
   \caption[统一的区块价格将允许DoS \statusgreen]{在邻近地区统一块价格将允许DoS攻击。攻击者可以向只有$S$可以服务的$S$发送检索请求，从而在$D$和$S$两个节点之间创建流量。如果在邻近地区的价格相同，这样的攻击对攻击者来说不会造成任何损失。}
   \label{fig:ddos-uniform-price}
\end{figure}

为了减少这种攻击，请求者为块支付的代价必须严格大于存储节点在请求从请求者路由到存储节点时作为补偿接收的代价。我们需要有一个奖励转发节点的定价方案，因此，这就需要根据节点邻近程度进行差异定价。如果一个节点离块越远，交付的价格越低，那么请求总是可以以这种方式发送，因为转发器会将差价收入囊中，从而获利。这意味着有效的差分方案将收敛于一个定价模型，其中，如果对等方离块地址更远，则交付成本更高，即块交付的回报是邻近度的递减函数。

由于沿着交付路径和邻近的竞争压力，我们期望一个节点对下游价格施加的微分收敛到转发实例的边际成本。
下游价格由节点的bin密度决定。假设具有基数$2^n$的平衡容器，节点可以保证在一跳内增加$n$的接近顺序。同时，这也意味着他们可以将成本分摊到$n$接近箱上，从而降低整体价格。


\subsubsection{同业间价格的一致性}

以一个节点$A$为例，该节点需要转发一个块请求，该块属于$A$的PO bin $n$。注意，所有在accbd容器中的$A$的其他对等体，就像$A$在它们的PO $n$中也有块。如果这些对等点中的任何一个，比如$B$，接近订单$n$的价格比defee便宜，defee可以降低其PO bin $n$的价格，将所有增加的流量转发给$B$，并仍将差额收入囊中，见图\ref{fig:price-arbitrage}。注意，这对网络不是理想的，因为它在路由中引入了\gloss{spurious hop}，即在不增加接近度的中继中。 


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/price-arbitrage-3.pdf}
    \caption[价格套利\statusgreen]{价格套利。节点为每个对等点的每个邻近订单保持一个可定价的价格。该图表显示节点$0101$试图转发$0000$的检索请求。箭头来自最近的节点，指向其他节点(尽管离块更远)提供更便宜转发的单元。选择更便宜的对等体将引导流量离开定价过高的对等体，并导致双方都有调整的压力。}
   \label{fig:price-arbitrage}
\end{figure}
 


类似地，在较浅的bins中，defee的peer在各自的bins中比defee的价格更低，例如$n-1$ bin中的$B$比$n$ bin中的defee更便宜，那么defee总是可以将任何请求转发给$B$，并将差额装入囊中。

现在让我们假设所有同行的价格表都是随着PO的减少而单调下降的。还假设较浅的桶的价格高于$n$，而高于$n$的桶的所有较深的桶的价格与$n$相同。设$B$、$C$、$D$和$E$为$n$ bin中稠密均衡的对等体。$A$希望将数据块转发给对等端，以便其目标地址的PO增加3。如果$B$和$C$试图串通反对defee，提高转发区块到$n+3$ bin的价格，它们仍然被$D$和$E$在$n+2$ PO bin上的价格绑定。特别是如果它们低于$n+3$的$B$和$C$。

这种价格差异为节点提供了套利机会;转发到最便宜的对等点的策略将把流量从昂贵的对等点引走，并增加较便宜的对等点的流量。因此，价格将会调整。

在其他条件相同的情况下，这种价格套利策略将实现(1)在网络上相同的接近顺序下价格一致，(2)价格作为接近顺序的函数线性下降(3)节点可以增加连通性并保持价格较低。通过这种方式，激励机制的设计使得对单个节点有益的策略也能够整齐地对齐，从而有利于整个系统的健康。


\subsubsection{本密度}

根据下游同行的收费接近块的重要后果,净收入从单一的非本地交付到一个请求者是一个单调递增函数块之间的差异的邻近节点本身与同行的请求被转发到。换句话说，我们在一个转发请求中能走的距离越远，我们挣的就越多。

这种激励与下载者的兴趣一致，即在服务请求时节省跃点，从而降低延迟传递和带宽开销。该方案鼓励节点在其Kademlia bins中保持尽可能深的无间隙均衡地址集(见图\ref{fig:bindensity})，也就是说，节点保留密集的Kademlia bins比保留稀疏的Kademlia bins更好。


能够维护更密集容器的节点实际上与更薄容器的节点成本相同，但节省跳数将提高延迟并使对等节点更高效。这将导致该对等体比其他具有相同价格的对等体更受青睐。流量的增加也会导致带宽的争夺，最终导致价格的提高。

注意，这种套利在\glossplural{shallow bin}容器中更有效，因为要选择的对等点的数量较高。这是对\glossplural{deep bin}在责任领域的重大反对。如果一个节点不复制它的邻居块，这些块中的一些将需要由离该节点更近但离该节点更远的节点请求。这只有在亏损的情况下才有可能实现。\ref{sec:postage-lottery}还讨论了另一个激励邻国复制其职责范围的因素。但是存储了责任区域后，节点可以选择任意设置它们的价格。 


\subsubsection{缓存和伸缩}\label{sec:caching}

节点每次服务一个区块都会获得奖励，因此区块的盈利能力与它的受欢迎程度成正比:请求区块的频率越高，相对于每个时间单元的固定存储成本，奖励就越高。当节点达到存储容量限制，并决定删除哪些块时，理性利润最大化代理的最优策略是删除盈利能力最低的块。一个合理的%
%
\footnote{将继续确定和开发比最后请求年龄更能预测大块盈利能力的指标(另见\ref{spec:strategy:garbage-collection})}。
最好的预测器是最后一次请求的时间。为了使可供选择的区块集最大化，节点会利用机会缓存它们所传递的数据以及它们同步的区块。这将导致流行的块被更广泛地分布和更快地服务，使整个群成为一个自动伸缩和自动平衡的\emph{内容分发网络}。


\subsubsection{缓存节点}

任何能给\glossplural{relaying node}带来利润的方案都能积极鼓励只转发非缓存节点进入网络。这样的节点对网络本身并没有好处，因为它们会造成不必要的带宽开销。一方面，它们的存在原则上可以减轻存储节点中继流量的负担，因此在浅容器中使用它们可能不会有害。另一方面，在邻近深度更近的地方，它们的同伴会倾向于缓存/存储节点，因为至少对于它们假定的责任区域中的块来说，它们的缺点是这样的。非缓存节点也有助于增加匿名性(参见\ref{sec:retrieval})。

\subsection{开始鼓励push-syncing\statusgreen}\label{sec:push-sync-incentives}

\green{}

Push-syncing(参见\ref{sec:push-syncing})是一种协议，它确保上传到网络中的数据块到达正确的地址。接下来，我们将解释如何激励转发。
%
%
\footnote{为了补充我们的带宽补偿解决方案，还需要采取进一步的措施来保护垃圾邮件和激励存储，稍后将分别在\ref{sec:postage-stamps}和\ref{sec:postage-lottery}中讨论。}



推同步协议与检索协议类似，它们各自的消息交换序列通过相同的路径。
在推送同步协议中，块的交付类似于检索请求，相反，推送同步中的托管接收声明类似于检索中的块交付响应。

推同步在原则上没有明确的转发动机。由于检索协议，由于节点期望在其地址的邻近区域找到块，群中的参与者通过参与协议来帮助上传的块到达目的地的动机至少是弱的。然而，我们需要提供数据块通过比请求者更远的节点(轻节点或重试)上传的可能性。因此，如果推同步是免费的，节点可能会产生大量浪费的带宽。

仅对下游对等点的推同步交付要求付款，将使转发器处于与存储节点就区块的交付讨价还价的位置。块的拥有对于未来的存储节点来说是有价值的，因为还有一个存储奖励系统(参见\ref{sec:postage-lottery})。考虑到这一点，转发节点在理论上可以持有数据块，除非存储节点支付的价格略高于拥有该数据块的价值，因为存储激励因素考虑了潜在的利润。特别的是，由于上传者的路径上的转发者并不多，任何来自存储奖励机制的利润都可能被转发节点捕获。

相反，在推同步中，通过将托管收据声明变成付费消息，角色交换。现在，货代节点不具备讨价还价的条件。为了了解其中的原因，请考虑如果转发节点试图持有一个块以获得将该块推给存储节点的价格，会发生什么情况。在这种情况下，上传者将不会在适当的时间得到托管收据声明，假设尝试已经失败，并通过不同的路径重新上传块。现在，原来的转发节点突然被迫与另一个转发节点竞争，以获得带宽成本的补偿。由于所有转发节点都知道这一点，紧急行为将产生一系列愿意将块转发给存储节点的对等节点，只需要很小的补偿和产生的带宽成本。现在原来的转发节点不需要一开始就尝试和存储节点讨价还价:相反，他们可以在返回托管收据的对账单时立即获得小额利润。 


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/push-payment.pdf}
\caption[推同步协议的激励机制\statusgreen]{推同步协议的激励机制。节点$U$(上传器)通过转发节点$F_0, \ldots F_n$将chunk发送到其地址，与之最近的节点是节点$S$(存储器)。存储节点以托管收据语句响应，该语句通过相同的转发节点$F_n, \ldots F_0$传递回上传者。收到托管收据报表会触发一个会计事件。}
\label{fig:syncing-swap}
\end{figure}

这个方案清楚地说明了为什么两种协议的激励依赖于相同的前提:同一商品(托管收据声明)有许多卖家(转发器)和只有一个买家(上传者)。这使得服务的价格(将数据块交付给存储商)等于该路径上每个节点转发的所有边际成本之和，同时允许存储商节点从存储补偿方案中获取所有利润。

通过这种方式，我们可以确保(1)存储器实际使用收据进行响应，(2)有一种方法来检测超时或未经请求的收据响应，以防止DoS，参见图\ref{fig:syncing-swap}。

就像在检索协议中一样，定价对于不同的邻近性是不同的(参见\ref{sec:diff-pricing-prox})，而且由于网络中节点的成本是变化的(取决于节点的容量利用率和效率)，定价也将随时间而变化。以来的会计赔偿是由于一个块和一个短消息(检索请求和保管收据),我们可以有把握地得出这样的结论:价格结构转发的两个协议都是相同的,因此可以使用一个通用货运定价方案为(见\ref{sec:retrieval-price-discovery})
不同之处在于，与检索协议不同，在检索协议中，数据块被送回并可以验证其完整性，而pushsync中的会计事件是一个可以被欺骗的托管声明。有了转发激励，节点就会有不转发的动机，并模仿存储节点发出托管声明。这使得通过替代路由查询(检索)块是可取的。如果这样的检索失败，可能需要尝试通过其他路由推同步块。 
 

\section{Swap:会计和结算}\label{sec:accounting-and-settlement}

\green{}

本节涵盖与带宽共享相关的激励方面。
在\ref{sec:accounting}中，我们引入了一种机制来跟踪对等体之间的数据流量，并提供对等体对对等体的消息中继计费。
随后，在\ref{sec:cheques}中，我们描述了补偿不平衡服务的条件，并说明如何实现解决。
特别介绍了\glossplural{cheque}和\gloss{chequebook contract}的概念。在\ref{sec:waiver}中，我们讨论了豁免，这是一种进一步优化，允许更多地节省交易成本。在\ref{sec:zero-cash-entry}中，我们讨论了发送现金交易的激励服务如何使零现金进入Swarm。最后，在\ref{sec:sanctions}中，我们将讨论一套基本的制裁措施，作为节点良好运行和遵守协议的基本激励。

\subsection{对等accounting\statusgreen}\label{sec:accounting}


\cite{ethersphere2016sw3}引入了一个点对点计费协议，称为\gloss{swap}。Swap是一种以牙还牙的会计方案，可以衡量微交易(参见\ref{spec:protocol:swap})。该方案允许直接连接的对等方交换支付或支付承诺。系统的主要特性被以不同的字母缩略词SWAP的助记符分辨率捕获:

\begin{itemize}
    \item \emph{需要和提供的服务}的eddcd——用于服务交换的帐户服务。
    \item \emph{自动付款结算}——超过\gloss{payment threshold}时发送\gloss{cheque}。
    \item 债务可以以未兑现支票的价值被免除。 
    \item \emph{白手起家}和\emph{用对等体发送}——通过单向互换支持零现金入账。
\end{itemize}

\subsubsection{服务服务}

\gloss{swap}允许在连接的对等点之间进行服务交换。在消费相等且随时间变化方差低的情况下，双向服务可以不支付任何费用。数据中继就是这种服务的一个例子，使Swap非常适合在内容传输或网状网络中实现带宽激励。

\begin{figure}[htbp]
\input{fig/swap-balance-thresholds.tex}
\caption[交换差额和交换阈值\statusgreen]{交换差额和交换阈值。
中间的零余额表示消费和供应相等。
当前的渠道平衡表示未补偿服务提供的差异:
如果在0的右边，天平倾向于A, B处于负债状态，而在左边
天平向B倾斜，A负债。
橙色的间隔表示损失容忍度。如果余额超过了支付阈值，一方就会
debt向它的对等端发送一个\gloss{cheque}，如果它到达afdef，欠债的对等端将断开连接。}
\label{fig:swap}
\end{figure}

\subsubsection{结算与支付}

在服务消费存在高度差异或不平等的情况下，平衡最终将显著地向一个对等体倾斜。在这种情况下，负债方向债权人支付款项以将名义余额归零。这个过程是自动的，并将交换定义为becfe(参见图\ref{fig:swap})。这些支付可以只是承诺。


\subsubsection{付款的阈值}

为了量化所谓的“显著倾斜”，交换协议要求对等点发布一个\gloss{payment threshold}作为握手(\ref{spec:protocol:swap})的一部分:当他们对对等点的相对债务超过这个阈值时，他们发送一条消息，其中包含向对等点支付的款项。任何节点都可以在这个级别发送消息，因为这里也存在断开连接的阈值。断开阈值由任何对等点自由设置，但一个合理的值是支付阈值和断开阈值之间的差异说明了两个对等点会计余额的正常方差。(见\ref{spec:strategy:swap})。 


\subsubsection{原子性}

发送\gloss{cheque}并在接收端更新余额不可能是一个原子操作，否则会增加大量的复杂性。例如，客户端可能会在接收和处理消息之间崩溃，因此即使发送方没有返回错误，发送方也不能确定收到了付款，这可能会导致双方的账目不符。由两个阈值之间的差异($\mathit{DisconnectThreshold}-\mathit{PaymentThreshold}$)表示的容差可以防止这种情况发生，也就是说，如果此类崩溃的发生率不高，并且两个对等点发生的概率大致相同，则产生的微小差异将被过滤掉。这样，节点就不会受到制裁。

\begin{center}
\begin{figure}[htbp]
\input{fig/chequeswap.tex}
\caption[支票交换\statusgreen]{B点的互换余额(相对于A)达到支付阈值(左)，
B向peer a发送一张支票，B保留这张支票并将掉期余额恢复为零。}
\label{fig:chequeswap}
\end{figure}
\end{center}

\subsection{作为支付的链下承诺的支票\statusgreen}\label{sec:cheques}

区块链网络中直接\gloss{on-chain payment}的一个主要问题是，每一笔交易都必须由参与网络的每个节点来处理，导致交易成本很高。但是，可以在不呈现链上支付的情况下创建支付。这种支付被称为\gloss{second-layer payment}策略。其中一种策略是推迟付款并批量处理。为了降低成本，受益人必须愿意承担更高的结算失败风险。我们认为这在Swarm的带宽激励中是完全可以接受的，在此同行将参与重复的交易。


\subsubsection{支票本合同}

\cite{ethersphere2016sw3}引入了一个非常简单的智能合约，允许受益人选择何时处理付款。这个\gloss{chequebook contract}是一个可以处理其所有者发出的\glossplural{cheque}的钱包。这些支票与传统金融交易中使用的支票类似:发行方签署\emph{支票}，指定\emph{受益人}、\emph{日期}和\emph{量}，并将其作为在稍后日期支付的承诺令牌交给接收方。智能合约扮演着银行的角色。当接收者希望得到报酬时，他们通过将支票提交给智能合约来“兑现支票”。在确认支票上的签名、日期和金额后，合同将金额转移到受益人的账户(见\ref{fig:swap-chequebook}图)。类似于拿着支票去银行兑现的人，任何人都可以在交易中将数字支票发送到所有者的支票簿账户，从而触发转账。

交换协议规定，当超过\emph{付款阈值}时，债权人对等端将发送一张支票。这样的支票可以立即被兑现，通过发送到发行人的支票簿合同。或者，支票也可以持有。持有支票实际上是一种信用贷款，可以使交易双方节省交易成本。

存入支票本(\gloss{global balance})的金额作为支票的抵押品。它集中在所有未偿付支票的受益人身上。在这种最简单的形式下，支票簿具有与真实支票相同的担保:无担保。由于资金可以在任何时候自由地从支票簿钱包中取出，兑现时的偿付能力永远无法得到保证:如果支票簿上的余额少于提交给它的支票批准的金额，支票就会被退回。这是交易成本和结算失败风险之间的权衡。

尽管严格来说，没有对偿付能力的保证，在破产的情况下也没有明确的惩罚措施，但空头支票将影响发行人的声誉，因为支票簿合同记录了它。在支票是在重复交易的背景下交换的前提下，同行将避免签发超出其余额的支票。换句话说，一个节点在同行中保持良好声誉的兴趣，足以作为维持其偿付能力的动力。


\begin{figure}[htbp]
\centering
\input{fig/swap.tex}
\caption[交换支票簿的基本交互序列\statusgreen]{交换支票簿的基本交互顺序}
\label{fig:swap-chequebook}
\end{figure}


\subsubsection{双兑现}

由于这些数字支票是文件，因此可以复制，因此必须小心，同一支票不能被兑现两次。为了防止这种“双重兑现”，可以为每张发给特定受益人的支票指定一个序列号，在支票兑现时合同将储存该序列号。然后，支票簿合同可以依靠序列号来确保支票按顺序兑现，因此只需为每个受益人存储一个序列号。

当向同一受益人重复支付款项时，防止重复兑现的另一种策略是，支票中包含曾经贷给受益人的联邦、商业和商业补助金总额。已兑现的全部金额存储在每个受益人的合同中。当提交新的支票时，合同忽略金额等于或少于存储总额的支票，但如果收到总额高于存储总额的支票，合同将转移差额。


这个简单的技巧也使得批量兑现支票成为可能，因为只需要处理当前的“最后一张支票”。这就实现了上面提到的交易成本的降低。

\subsubsection{兑现没有醚}\label{sec:zero_eth}
并不是Swarm中的所有同行都有支付交易费用的以太坊来兑现支票。支票本允许第三方兑现支票。交易的发送方会因为所执行的服务而获得奖励。

\subsection{Waivers\statusgreen}\label{sec:waiver}

如果互换渠道的不平衡是高方差的结果，而不是不平等的消费，在积累支票一段时间后，渠道平衡开始向另一个方向倾斜。通常情况下，现在由另一方向其对等方签发支票，导致未兑现支票在双方累积。
为了进一步节省交易成本，能够“把支票彼此对赌”可能是可取的。

这样的过程是可能的，但它需要在支票簿合同中进行某些重要的更改。特别是，兑现支票不再是立即的，必须引起安全延迟，这是其他支付通道实现中常见的概念。

让我们设想一个类似于支票返还给发行方的系统。假设同业$A$向$B$发行支票，余额为零。后来天平向$A$倾斜，但从$A$到$B$的支票没有兑现。在传统金融世界中，用户B可以简单地将最后一张支票归还给$A$，也可以将其销毁。在我们的情况下，事情没有这么简单;我们需要一些其他的机制，$B$ \emph{承诺不兑现}这个特殊的支票。这种承诺可以采取几种形式;它可以实现通过$B$签署消息允许$A$发行一个新的“去年支票”,累计总额低于之前,或者$B$可以发行某种“消极”的支票的支票簿,好像一个支票相同数量的影响已经支付。

所有这些实现的共同之处在于支票簿不再允许支票的即时兑现。在收到支票兑现请求时，合同必须等待，以便允许有问题的另一方提交有关已注销支票或减少的总额的潜在遗漏信息。为配合使用单一支票簿的(半)双向付款，我们作出以下修改:

\begin{enumerate}
    \item 用户A发给用户B的所有支票必须包含一个序列号。
    \item A签发给B的每张新支票必须增加编号。
    \item A的支票簿合同记录了B兑现的最后一张支票的序列号。
    \item 在兑现延误期间，高编号的有效支票将取代先前提交的任何支票，不论其面值如何。
    \item 任何已提交的支票如减少先前已提交支票的支付额，只有经受益人签署才有效。
\end{enumerate}


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/waivers-diagram-2.pdf}
\caption[混合支票和弃权交换的示例序列\statusgreen]{混合支票和弃权交换的例子序列}
\label{fig:waivers-diagram}
\end{figure}

有了这些规则，就很容易看到支票注销将如何工作。假设用户defee向用户$B$签发了支票$c_0 \ldots c_n$，其累计总额为$t_0 \ldots t_n$。假设$B$兑现的最后一张支票是bccfcbb。支票本合同记载$B$已经收到$t_i$的付款，最后一张兑现的支票编号为$i$。

让我们进一步假设天平开始向$A$倾斜一些$x$。如果$B$已经兑现了$c_n$支票，那么$B$现在必须使用$B$的支票簿作为来源，并指定defee为受益人，签发一张她自己的支票。然而，由于支票$c_{i+1} \ldots c_n$是未兑现的，$B$可以向defee发送一张支票，以defee的支票簿为来源，$B$为受益人，编号为$n+1$，累计总金额为$t_{n+1} = t_n - x$。根据上述规则，A将接受$B$支付的相当于$x$金额的款项。在这种情况下，$B$放弃了早先的部分权利，而不是向defee发送支票。这证明SWAP是\emph{发送弃权书作为付款}。

这个过程可以重复多次，直到累积的总数被带回$t_i$。此时，所有未偿债务已被有效地注销，任何进一步的支付必须以从$B$的支票簿到defee的适当支票的形式进行(见图\ref{fig:waivers-diagram})。

\subsection{尽最大努力解决策略}

亚伯文本

\subsection{零现金entry\statusgreen}\label{sec:zero-cash-entry}


互换会计也只能在一个方向上工作。如果一方以零流动资本(\gloss{newcomer})进入系统，但以资金(\gloss{insider})与另一方连接，则新来者可以开始提供服务(而且不使用任何服务)，以赚取正的掉期余额。

如果内部人士有支票簿，他们可以直接用支票支付给新来的人。然而，这有一个警告:新来者将能够从提供的服务中赚取支票，但没有办法兑现它们。兑现支票需要向区块链发送交易，因此需要gas，除非节点能够说服它的一个对等节点为它们发送交易。为了实现这一点，节点可以在它们想要发送的结构上签字，然后使用预处理步骤扩展Swap合同，从而触发支付给新来者的费用，包括交易的天然气成本和交易发送方的服务费。新来者的支票可以由任何内部人员兑现(见图\ref{fig:zero-cash-entry})。这个特性证明SWAP是defed。

\begin{figure}[htbp]
\centering
\input{fig/zero-cash-entry.tex}
\caption[零现金条目\statusorange]{引导或如何作为具有交换能力的节点启动，使用并提供
服务和赚钱。}
\label{fig:zero-cash-entry}
\end{figure}

无需启动资金就能赚取少量资金的可能性至关重要，因为这为新用户提供了无需购买代币就能访问Swarm的途径。这一好处一般延伸到以太坊生态系统:使用Swarm，任何人都可以赚取少量的钱，开始支付天然气，以燃料他们的dapp，而不需要经历一个痛苦的过程获得代币之前。 


\subsection{套现和破产风险}



\subsection{制裁和黑名单\statusgreen}\label{sec:sanctions}
\red{}

本节为SWAP计划提供了额外的激励措施和防止违规行为的保护措施。 

\subsubsection{协议违反}

在对等不信任的设置中，很难对不受欢迎的对等行为进行微妙的制裁，然而，当基本的交互规则被违反时，检测到它的节点可以简单地与该对等断开连接。为了避免由于试图重新连接而导致的死锁，对越界节点施加的制裁还包括将对等节点的地址记录到黑名单中。这个简单的措施足以为寻求利用该协议的节点提供明确的抑制因素。 

\subsubsection{过度的轻浮}

检索和推同步协议都有一个激励结构，其中只有响应产生收入来源。虽然这形成了强烈的打球动机，但也可能有必要采取措施，以确保节点不能向网络发送无意义的请求，而没有相关成本。在推同步的情况下，尤其重要的是不允许块在没有成本的情况下删除其他块。这将构成后面介绍邮票一节的主题(请参阅\ref{sec:postage-stamps})。

在pull-sync检索的情况下，攻击包括请求不存在的块，并导致下游对等点发起大量网络流量，以及一些内存消耗，因为请求在生存期间被持久化。
当然，可能会发生请求不存在的块，而且请求的块可能在网络中被垃圾收集，在这种情况下，请求者可能是出于善意。

为了减少这种情况，每个节点都会记录来自每个节点的检索请求的数量，然后更新失败请求的相对频率，例如，即使有问题的节点已经转发了请求，但请求已经超时。如果这些失败请求相对于成功请求的比例过高，就会对对等请求施加制裁:它将被断开连接并列入黑名单。

% 
% \footnote{Note that policing frivolous requestors is much easier than policing forwarders, since the latter requires positive evidence from other nodes while the former only requires forwarding.}
%

通过记住它们转发的请求，节点可以将合法的响应与潜在的DoS攻击区分开来:对于检索，如果交付的块没有满足开放请求，它就被认为是未经请求的;对于推同步，如果托管响应的语句与转发块的现有条目不匹配，则认为它是未经请求的。

超时在这里至关重要。在请求的生存期结束后，开放请求的记录可以被删除，因此，任何后续响应都将被视为未经请求的响应，因为它与从未请求过的消息没有区别。

为了允许在时间度量差异上有一定的容忍度，在断开连接并将其列入黑名单之前，仍然允许来自对等体的一小部分非法消息。

\subsubsection{的服务质量}

除了主动发送消息的速度外，节点还会在其他方面引起不满，比如价格高、网络吞吐量低或响应延迟长。与过分琐碎的请求类似，没有必要区分恶意攻击或善意提供的次优(质量差，价格过高)服务。因此，缓解服务质量问题将在转发(参见\ref{spec:strategy:forwarding})和连接(参见\ref{spec:strategy:connection})中的对等选择策略上下文中进行讨论。

\subsubsection{黑名单}

黑名单是一种策略，是对断开连接的一种措施。它应该扩展我们的判断，表达在分离的行为，peer是不适合的业务。
特别是在接受传入连接以及连接驱动程序的对等建议策略时，应该参考黑名单。一方面，加入黑名单可以避免节点在恶意节点试图重新连接的循环中陷入死锁。另一方面，必须注意不要将善意的同行列入黑名单，以免损害网络连接。



\section{存储激励\statusyellow}\label{sec:storage-incentives}

\wip{the lottery is not completely finalised}

在\ref{sec:postage-stamps}中，我们引入了\glossplural{postage stamp}，主要是作为一种垃圾邮件保护措施。
然后，在\ref{sec:postage-lottery}中，我们转向\gloss{postage lottery}，解释如何修改用于垃圾邮件保护的邮票，以创建积极的激励机制，使存储节点存储文件，并使上传文件的节点表明文件的重要性。在\ref{sec:capacity-pressure}中，我们描述了如何使用定价机制来表示网络的容量压力，以及如何采取激励措施来纠正这种情况。最后，\ref{sec:chunk-insurance}展示了邮资彩票提供的积极奖励可以通过引入参股保险公司加以补充。如果参股保险公司失去了自己投保的部分，它们将失去存款。我们认为，这种惩罚性措施对于缓解\gloss{tragedy of commons}问题至关重要，\gloss{tragedy of commons}问题只会影响实施正向存储激励的系统。 

\subsection{带有邮票的垃圾邮件保护}\label{sec:postage-stamps}
\green{}

同步包括将块从上传者转移到存储者，即从它们进入网络的地方，转移到块位于节点职责范围内的邻近区域。存储节点的角色是通过响应使用块数据的检索请求来提供内容。在其他所有条件都相同的情况下，给定Kademlia路由，节点离块地址越近，对该块的请求最终得到它们的可能性就越大。这为存储节点同步内容创造了一个微弱的动机。然而，它的前提条件是，这块土地承诺有一定的利润。如果对手可以向网络发送从来没有请求过的块(可能是随机生成的)，那么这种假设就不成立。从网络的角度来看，这意味着无用的块将简单地取代有用的块。通过附加上传区块的成本，Swarm可以减轻此类攻击。


\subsubsection{邮票}

受国际邮件投递的启发，整个投递路径(以及存储)都可以预先支付。这种支付证明称为\gloss{postage stamp}，发送方必须将其附加到有效载荷上。

上传者不一定要承担这个成本，但他们需要确保每个块都附加了邮票，否则上传就不会成功。相反，这种首付不一定要作为收入支付给任何人，也就是说，它可以被烧毁或以其他方式重新分配。上传大量的实际成本可以作为一个信号的相对重要性(有点类似地优先邮件),仓库保管员节点可以使用排列块在选择哪些该保留,服务,以及哪些垃圾收集(见\ref{spec:strategy:garbage-collection})事件的能力不足。

邮票被建模为使用\gloss{witness}与数据块关联的支付证明。证人是由支付人指定的第三者实体发出的数码签署。


\begin{figure}[htbp]
\centering
  \includegraphics[width=\textwidth]{fig/postage-stamp.pdf}
\caption[邮票\statusgreen]{邮票}
\label{fig:postage-stamps}
\end{figure}

\subsubsection{付款证明}

支付证明可以用于许多不同的实现。最明显的选择是向区块链上的中央邮票发行者智能合约付款。%
%
\footnote{然而，使用支票似乎是一种选择，因为支票是针对累积债务签署的，并假定单一受益人能够在先前发出的支票上重建增加值。换句话说，支票不是向非同侪传递价值的合适方式。}
%
然而，由于交易成本高，要求对每个区块进行链上支付将是非常昂贵的。相反，我们需要一个解决方案，允许上传者在\gloss{postage batch}中购买邮票，然后在许多块中重用它。 


当交易被发送到其创建端点时，中央邮费智能合约会创建这些批，同时还会创建一定量的BZZ令牌和以下交易数据:

\begin{itemize}
\item \emph{主人地址}—有权使用为标记块创建的批的所有者。
\item \emph{的批次数量}—由此付款创建的批数。
\item \emph{批处理深度}——可以在创建的每个批处理中盖章的块数量的对数。
\end{itemize}

支付邮费后，会记录以下信息:

\begin{itemize}
\item \emph{付款参考ID}——生成的作为此支付参考的随机ID。
\item \emph{每个块平衡}—由该付款创建的批次所涵盖的每个批次平均分配的总金额。
\item \emph{主人地址}—有权使用为标记块创建的批的所有者。
\item \emph{的批次数量}—由该付款创建的批数。
\item \emph{批处理深度}——可以在创建的每个批处理中盖章的块数量的对数。
\end{itemize}


所有者是交易数据中指定的地址，并被记录为被授权使用创建的批的人;如果未指定，则默认假定为事务发送方。

生成一个随机标识符以提供对支付的引用。
付款交易将创建多个批次，这些批次的数量在交易中指定。最终将分别记录每批的批深。每次付款都可以创建新的批次。
该支付覆盖的块的数量可以计算为批大小的总和。初始批深度用于支付事务创建的所有批。然后，随着交易发送的BZZ令牌的数量被平均分配到支付覆盖的所有块，即令牌的总数量除以覆盖的块的数量，分配给支付ID，以代表批的每块余额。然后，任何人都可以选择在以后的日期充值这个余额。 


\begin{figure}[htbp]
  \centering
    \includegraphics[width=\textwidth]{fig/postage-stamp-structure.pdf}
  \caption[邮票\statusgreen]{邮资邮票是一种数据结构，由邮资合同批号、块地址和证明两者关联的见证人签名组成。上传者和转发者必须为上传的每个块附上有效的邮票。 }
  \label{fig:postage-stamp}
\end{figure}


附在数据块上的邮票是一个包含以下字段的数据结构(参见图\ref{fig:postage-stamp}和abddac中的规范):

\begin{itemize}
    \item \emph{块地址}—贴邮票的地址。 
    \item \emph{批处理标识符}——由支付标识符和批索引组成，可以用邮资智能合约检查批索引的有效性。
    \item \emph{见证}——所有者的签名，将批标识符和所有者的地址连接起来。
\end{itemize}

邮票的\emph{价值}是与批关联的每块余额。
与用于邮政邮件的邮票类似，一块邮票上可以有多个邮票。在这种情况下，将多个有效邮票赋予该块的价值加起来构成总邮票价值。 

\subsubsection{邮票有效期}

检验邮票是否有效，须符合下列准则:

\begin{itemize}
\item \emph{真实的}——批标识符有效，即支付ID存在并已注册，批索引小于与支付ID关联的批数。
\item fdeef—证人由指定的地址作为批的所有者签署。
\item \emph{资助} -引用批次尚未耗尽其余额，并有足够的资金以覆盖至少一个存储周期的最新价格。
\end{itemize}

所有这些都可以被智能合约本身轻松地检查。验证其中包含的数据块小于批处理允许戳记的数据块总数是至关重要的。如果不采取进一步措施，就有可能发生超支攻击，即上传者在超过批大小的块上重用戳记，从而欺骗不知情的存储者，让他们承担报酬过低的额外工作。

对这种\emph{overissuance}的保护并非无关紧要:在没有使用特定批处理签名的所有块的全局可见性的情况下，节点无法直接验证大小，因为它们无法访问没有通过它们转发的附加在块上的戳记。因此，各节点需要有一种方法来防止集体过度发行，而每个节点必须仅根据当地可获得的信息决定如何采取行动。

\subsubsection{通过限制前缀冲突来限制批大小}

一个解决方案是对批施加一个显式的fbadb:使用相同批标识符签名的块没有比深度更长的\gloss{prefix collision}约束。一个批次大小为$2^d$的邮票可以被认为是深度为$d$的平衡二叉树，其中叶子对应于批次的最大长度\glossplural{collision slot}。如果一个批处理的深度大于网络的深度(日志网络中节点的数量),那么所有的块匹配相同的碰撞位置是保证土地在同一街区,,因此,“违规”的统一性要求可以在本地检测到节点(参见图\ref{fig:prefix-collision})。 
% If storers respond to this violation by randomly keeping only one of the chunks for each collision slot, uploaders will not only lose one chunk if they try to store more then their allowed allocation, but also lose the  predictability of which one on top.
存储节点将纠正批处理记录的深度。
他们可以通过对比当前记录的批次深度更接近的批次报告所有者发行的两枚邮票来进行更正。
这样做的动机是，存储者可能获得比已支付的存储成本更高的额外存储成本。


\begin{figure}[htbp]
  \centering
  \input{fig/prefix-collision} \caption[限制邮票大小\statusgreen]{邮资批处理用二叉树表示，并将发行的邮票映射到批处理。叶节点位于从根开始的层次上，对应于支付时设置的邮资批次的深度。叶节点上的框可以被认为是前缀冲突槽。在这个图中，灰色盒子表示已经填满的槽，所以下一个块地址应该落入一个白色的。}
  \label{fig:prefix-collision}
\end{figure}


由于块地址不太可能完美地分布在批处理的碰撞槽上，上传者必须保留多个深度$d$来签名$2^d$块。一般来说，最有效地利用每张邮票是填满所有不同的\glossplural{collision slot}(见\ref{sec:upload})。换句话说，持续的不一致性将导致邮票未得到充分利用，因此上传和存储每个块的平均单价更高。这种解决方案有一个预期的副作用，即它为非均匀上传强加了一种预先成本:我们上传的内容越集中在一个社区，就有越多的邮票插槽没有被使用。通过这种方式，我们可以确保将太多的上传信息导向一个特定的社区是非常昂贵的。%
%
\footnote{有针对性的袭击袭击街区的成本随着深度呈指数增长。}
%
This will be significant for the later discussion of decentralised file insurance (see \ref{sec:insurance}). 

Another advantage of limiting batch size based on prefix collisions is that with prefix collisions, the absolute value of a postage stamp can be estimated. This comes in handy later when designing the postage lottery (see: \ref{sec:postage-lottery}). 


In order for these collisions to be detectable, the batch size needs to be higher than the estimated neighbourhood depth over the whole lifetime of the batch. In any case, it is not in the interest of users to have batches much deeper than that, since the longer the collision prefixes, the more difficult it becomes to achieve uniformity and fill the entire batch  (see \ref{sec:complexity-filling} of the appendix). 
% We will, for now, just assume that the depth of a batch is a fixed number set centrally in the contract and that follows the depth of Swarm. The effect of network growth on the already used stamps is discussed below.


\subsubsection{使用加密挖掘块}

完全填满\glossplural{postage batch}的一个整洁的解决方案依赖于\ref{sec:chunk-encryption}中暗示的洞察力:选择加密密钥允许我们将一个块\emph{我的}到一个特定的邮资批次。

寻找加密密钥以生成靠近地址的内容散列的过程类似于在区块链中挖掘块。块需要32字节的密钥加密,扮演的角色目前在一块,那就是:它提供了足够的熵来保证一个是能够找到一个加密密钥,这样产生的哈希摘要加密块产生一个地址属于一个特定的槽内开放的邮资批。开采的难度是由分批深度决定的。

考虑一下节俭的上传者，它只有足够多的邮资碰撞槽要发送的块。给定一个深度为$d$的邮资批，它们使用选定的密钥对数据块进行加密，这样加密后的数据块地址就会填满一个开放邮资批的自由碰撞槽。如附录(\ref{sec:complexity-filling})的分析所示，这种填充批次的策略需要每个块平均进行$0.69d+1$试验，即1000、100万和100亿节点分别需要8、15、22次$0.69d+1$试验。这被发现具有合理的复杂性。


\subsection{邮资抽奖:对存储的积极激励\statusyellow}\label{sec:postage-lottery}

\yellow{}

如\ref{sec:accounting}中所讨论的，Swarm中的主要激励机制是为检索提供补偿，即节点为块成功服务得到奖励。这种奖励机制还有一个额外的好处，那就是鼓励机会主义缓存。利润最大化的存储节点为经常被请求的块提供服务，因此，确保流行内容在网络上广泛分布，从而也减少了检索延迟。

只使用这种激励的另一面,是块很少检索可能最终失去了:如果不被访问一块很长一段时间,然后由于存储容量有限,最终它将垃圾收集,为新来者。为了让群体能够保证数据的长期可用性，奖励系统需要确保那些原本会被删除的数据块能够产生额外收入。换句话说，不能从检索中产生足够利润的不受欢迎的块应该补偿存储它们的节点失去的机会。本节介绍的\gloss{postage lottery}通过在存储节点之间公平地重新分配来自邮票的收入来提供这种补偿。



邮资彩票计划的核心是认识到概率支付可以用来为存储节点创造收入。
使用抽奖可以让我们校准收益，使其在长期内获得与实际支付相同的收益，同时节省交易成本，并提供必要的随机性，作为抽查。


\subsubsection{比赛:抽奖、申请、索取和赚取}

邮资抽奖在\gloss{EVM}区块链上进行，并由一个智能合约管理。抽奖过程由以下协议定义(正式参见abdcid)。

每个$N$-th %
%
\footnote{选择$N$是为了使两轮之间的时间能够轻松地适应抽签过程的所有阶段。}
%
区块链上的区块标志着新一轮全球彩票的开始。
后续的$N$块由三个阶段组成，在这三个阶段中，抽奖参与者被期望发送交易来与抽奖智能合约进行交互: 

\begin{enumerate}
\item \emph{pre-committal}——节点通过发送价格报价来预先承诺抽奖挑战。作为有效的预提交事务的结果，定义了一组申请人。这一阶段的结束标志着证人批次的选择。
\item \emph{提交}—节点发送由证人批指定的块列表和它们的监护权证明。作为有效索赔交易的结果，定义了一组索赔人。这一时期的结束以挑战的选择为标志。
\item \emph{驳斥}—节点发送对挑战的反驳。由于有效的反驳，一组最终获奖的索赔人被确定。这一时期的结束标志着奖金的赢家。
\end{enumerate}

最后一节结束后，新一轮抽奖活动开始。抽奖和它的阶段也可以用缩写词\gloss{race}来描述，当然，还有一个描述阶段的助记方法:\gloss{raffle--apply--claim--earn}。事件的时间轴如图\ref{fig:raffle-timeline}所示。


\subsubsection{自动抽奖活动轮}

RACE过程在抽奖阶段初始化。首先，将起始块的哈希值与从$0$到$n-1$的整数一起哈希，以获得$n$ \emph{中奖彩票} ($r_0, \ldots r_{n-1}$)，每个$n$ \emph{中奖彩票} ($r_0, \ldots r_{n-1}$)表示一个独立的\gloss{raffle draw}.%
%
\footnote{每轮需要多次抽奖，以校准节点赢得抽奖的预期频率。随着网络的增长，通过增加$n$，存储服务补偿所需的预期时间可以保持不变。}。 
%
一旦这些中奖彩票被生产出来，其地址接近彩票$r_i$的节点就能够申请参加适用的抽奖活动。


从网络的角度来看，这些抽奖是对存储节点的抽奖，而从存储节点的角度来看，抽奖代表了集群内提供网络存储获得补偿的手段。 


\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/postage_race.pdf}
  \caption[事件的时间轴在抽奖轮\statusgreen]{抽奖活动的时间轴。}
  \label{fig:raffle-timeline}
\end{figure}


\subsubsection{应用:预先承诺抽奖挑战}

在第一个交互阶段，为了申请奖金，中奖彩票附近的所有节点必须向彩票合同发送一个交易，包括为每个块存储一个块的报价。通过提交这样的价格，节点隐式地声明它拥有其职责范围内价值高于价格的所有批次的所有块。这个责任范围是节点自己声明的，是预承诺的一部分。 

% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=.7\textwidth]{fig/radius_of_responsibility.pdf}
%   \caption[Radius of responsibility for postage lottery claims \statusorange]{Radius of responsibility for postage lottery claims}
%   \label{fig:raffle-radius}
% \end{figure}

\subsubsection{主张:提交证明以获胜}

在此申请截止日期过后，通过为每个申请人指定\gloss{witness batch}，抽奖进入索赔阶段。这个见证批作为对申请人声称他们存储了他们负责的所有块的抽查。与中奖彩票类似，证人批是根据完成$h_1$轮申请的块的\gloss{blockhash}提供的随机性来选择的。抽查按以下程序执行。首先通过将blockhash $h_1$和申请人的地址散列在一起创建一个锚，然后选择id最接近锚且值高于申请中提交的价格的批。该批作为随机证人批，申请人将提交证据，证明他们仍在所有已分配的块的保管中。

如前所述，附加到块的戳记赋予该块一个值，该值由批处理的每个块余额定义。追求\gloss{value-consistent garbage collection strategy}(参见\ref{spec:strategy:garbage-collection})意味着块上接受的最小邮票值将与存储节点的垃圾收集截止值一致。忠实遵循此策略的节点知道，它们从未删除过邮资价值高于其最低所需邮资价值的数据块。这样，无论选择哪一批作为见证，他们都可以确信自己能够包含该值以上的所有相关块。

索赔阶段从应用程序中分离阶段是为了迫使申请人导向任何抽查,因为:如果证人当时已知的应用程序中,无聊的节点可以声称奖,即使他们只是偶然出现的块存储只见证批。为了阻止这种机会主义的行为，参与抽奖需要一笔押金与预先承诺。如果该节点未能在剩余的抽奖阶段幸存下来，则该金额将被添加到奖励池中，否则将退还给申请人。

为了获得抽奖，一个节点必须表明他们拥有每一个见证块，即在他们的责任范围内的每一个带有见证批的见证块。为了证明块数据的所有权，节点必须提交一个\gloss{batch proof of custody}，一个\glossplural{BMT proof}的标准有序列表(参见\ref{spec:format:bmt})，每个见证块都提交一个(参见图) 
\ref{fig:batch-proof-of-custody})。申请人有$N_2$模块提交他们的索赔，然后抽奖进入挑战阶段。申请但未提交索赔的申请人将被视为提交了无效索赔。   


\begin{figure}[htbp]
  \centering
   \includegraphics[width=\textwidth]{fig/batch-proof-of-custody.pdf}
  \caption[批保管证明\statusgreen]{批保管证明。保管证明是用块地址、段索引和邮票包裹的BMT包含证明。多个POCs与见证批id打包。}
  \label{fig:batch-proof-of-custody}
\end{figure}

\subsubsection{挣:挑战申请人}

% If the set of chunks presented to the blockchain is incomplete (i.e. it doesn't contain all chunks for which a statement of custody receipt was issued), the applicants can be challenged on the blockchain. The challenge contains a statement of custody receipt that was signed previously by the applicant (see \ref{sec:push-syncing} and \ref{sec:push-sync-incentives}). This receipt can then be submitted by any third party and is validated right away by the smart contract. If the challenge is valid, the applicant loses their registration immediately and more punitive measures may be enacted by his peers. Challengers have till the end of the raffle round to challenge applicants.

\subsubsection{选择获胜者}

在挑战阶段结束后($N$区块后开始抽奖轮)，从幸存的申请人中，每个抽奖，提供最低价格的人将赢得这一轮。价格本身是所有邻居的赢家所申请的最低价格。

彩票奖金的发放需要考虑中奖者的数量、区块的数量、节点存储的数量占集群存储总量的比例。
奖金发放的时间是平均分配给获奖者的。为了便于推理，可以将blocks = winners校准，这样我们就可以说，当一个节点获胜时，它将为一个块的所有块获得报酬。只要价格不低于最低要求，获胜者有权领取每一块的价格。所有获奖者的收入总额从每批的余额中减去。款项从合同中扣除后余额干涸的邮资批次。%
%
\footnote{在实践中，这种平衡调整是不必要的，参见\ref{spec:format:postage-stamps})。
}

虽然获胜的节点可以尝试从更高的价格中获得更大的胜利，但他们彼此竞争，试图赢得抽奖，所以他们被激励通过提供他们用于垃圾收集的实际截止值来确保自己的胜利。作为竞争性支付的结果，预计单位价格将收敛于存储多一块的边际成本。




\subsubsection{批深度和数量调整支付}

到目前为止，为了便于推理，我们假设每个批的深度已经给出。批处理深度的要求是，它要比邻域深度更深，以便存储节点总是能捕获前缀冲突，但不能太深，否则会使批处理难以完全填充(参见\ref{sec:complexity-filling})。如果深度$b$的一批已经被填满，则期望一个责任半径为$d$的存储节点存储属于该批的$2^{b-d}$块。
其中一半的订单与中奖者的地址接近。

为了激励$r$冗余块副本(每个副本存储在邻近的一个节点上)，获胜者需要存储相同的块。
此外，不应该部分存储批处理的块。
如果节点被激励为一个批处理提供尽可能多的块，那么这两个问题都会得到解决。
这种动机转化为局部存储比赛的本地块，导致奖金降低。如果每批检测到的深度和实际大小都作为预提交的一部分报告，这是实现的。错误地提交比节点存储的数据块更多的数据，会有对批处理(如果指定为见证人)进行不可辩驳的挑战的风险，导致在没有获得抽彩奖金的情况下失去一次性的价格抽奖券。所有这些都会使上传者和存储者在尝试使用完全填充的batc hes(冲突槽构成一个深度为$b$的平衡二叉树)时保持一致。
由于实际大小构成对实际块体积的估计是群的。

存储的最佳安排是
特别地，我们建议在申请时使用音量调整方案

这在需求中是隐含的
相反，根据中标公司提交给合同的每批区块的实际数量，我们可以将Swarm中的当前邻域深度估计为$d'\defeq b - \mathit{log}_2(C)$。这让彩票智能合约有机会成为深度预言者。oracle值也可以用作抽奖计算中任何邮资批次的最小深度。请注意，如果批的自声明深度可能低于典型的邻域深度，那么节点的存储中最多只能有一个批的块，因此无法报告过量发放的批。因此，活性批次具有最小的$2^{d+1}$尺寸。


实际上旧的、完全填满的邮资批次要么可以保留，要么可以对其内容进行再保险。在前一种情况下，当网络宽邻域深度增长并超过原批深度时，节点会希望保留批，在这种情况下，所有者可以合法地向其添加块。
为了在不发生冲突的情况下向批处理中添加新块，必须记住已经与批处理关联的块。%
%
\footnote{实际上，只要记住哪些碰撞槽被填满了，达到了不断增长的网络可能达到的深度就足够了。在实践中，作为一种优化，深度$b' >b$的潜在碰撞槽可以使用长度$2^{b'-1}$的位向量记录}
%

请注意，主人可以选择支付一定的邮费，即使蜂群增长1000倍，余额也只会在一段时间后干涸。这在\gloss{upload and disappear}环境中变得很重要。
这样的深度批处理需要相同的$O(\mathit{log}(n))$计算开销(参见\ref{sec:complexity-filling})。这实际上意味着需要大量购买/使用的折扣。





% \subsubsection{Statement of custody receipts}

% Statement of custody receipts are crucial in the lottery, as they enable nodes to challenge. The challenge constitutes of submitting a receipt signed by the applicant. It is either a chunk closest to the applicant or to one of its neighbours. If the challenge is valid, the applicant loses their registered status. 

% In order for syncing neighbours to be able to challenge, nodes need to attach a statement of custody receipt to all the chunks that they are closest to or that their neighbour peer is closest to. The peers can be sanctioned with disconnection and blacklisting in case of non-compliance. 

% As part of syncing, an aspiring storer node must sign statements of custody receipts for all the chunks that it is closest to. If the upstream peer did not require these, then they could not defend their territory as it were, i.e. they would have no grounds to challenge the new node when they apply for winning a raffle round after registering. Note that they do not need to keep all of the chunks, since one is enough to mount a challenge. Additionally, the upstream node is not incentivised to withhold chunks that belong to the new node as they cannot earn any lottery winnings from them once the new node enters the race. 

\subsubsection{彩票中隐含的激励}

这个过程激励节点遵守以下行为:

\begin{itemize}
\item afed，否则抽奖就没机会了。
\item 与他们的邻居保持完全同步。否则，索赔可能是不完整的，而体积调整会使节点拥有更少。
\item \emph{有一个完全索引的本地商店}——为了能够列出批处理中的所有块，节点需要保存邮票并保留一组相关的块地址。 
\item \emph{执行值一致的垃圾回收}——为了判断节点是否在本地存储了批处理中所有先前接收到的块，它们必须执行垃圾收集值一致，%
％
\footnote{或者存储已删除块的索引，这是低效的}
即接受的最小值与删除的最大值一致。
％
\item 为了提供BMT证明，节点必须拥有块内容中的数据。%
％
\footnote{在特殊情况下，邮寄地址已预付邮资的信封，在信封填好并寄出之前不能收取费用(见\ref{sec:addressed-envelopes})。}
\end{itemize}


\subsection{价格信号能力压力}\label{sec:capacity-pressure}

\yellow{}

\subsubsection{存储容量}
Kademlia拓扑结构和冗余参数决定了节点的邻域深度(见\ref{sec:redundancy-by-local-replication})。邻里深度划定了责任范围。作为邮资彩票的结果，节点被激励拥有一个统一的社区大小。上传到该区域的块的数量与上传到Swarm $C$的所有块的数量成正比，与Swarm $N$中的节点数量成反比。一个节点存储的块数量平均为$CR/N$，其中$R$是邻域复制因子，度量冗余程度。这表示任意邻近区域的块密度。在给定特定连接和固定存储量的情况下，$C/N$捕获\emph{存储容量的压力}。

如果我们假设块只被保存一段有限的时间，那么在一定的变化范围内，压力保持不变。换句话说，我们可以找到一个网络大小%
%
\footnote{在存储容量的意义上;或者假设每个节点的最小存储容量为节点数。}
%
这样用户想要保存的所有内容都会被保存。 

如果向Swarm上传新内容的速度高于过期时间(邮票余额低于当前价格)，那么固定网络将面临越来越大的压力。因此，在没有添加容量的情况下，一段时间后，本应保存的内容将被垃圾收集。 

如果通过激励新的存储节点加入网络来吸引新增存储，或者通过提高价格来抵制不断增长的需求，就可以解决这种容量短缺问题。相反，如果过期的速度比新上传的速度快，压力就会降低，很可能会有多余的容量。如果通过鼓励用户上传内容或一些节点因价格降低而退出，就可以弥补资源未得到充分利用的情况。从供给和需求的角度考虑，只要储存容量的压力以储存价格(即每一大块邮票的最小价值)来表示，我们就可以达到一个自我调节的市场。 

\subsubsection{垃圾收集策略和邮资价值}

如果我们确保垃圾收集队列按下降的邮费优先级排列，这种自我调节市场的出现就会发生(参见\ref{spec:strategy:garbage-collection})。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/garbage-collection-fixed.pdf}
  \caption[垃圾收集\statusgreen]{垃圾收集:块是根据来自邮费价值和预期的检索收入的盈利能力排序的。}
  \label{fig:garbage-collection}
\end{figure}


请注意，当抽奖轮支付时，从所有邮票余额中减去相同的金额。因此，无论发生了多少轮抽奖，价值排序都不会改变。然而，为了插入新创建的邮票，我们需要知道到目前为止支付的总金额，然后将其添加到新项目的价值中。

一张邮票必须承诺足够的收入与它的价值，以使它优于最低分位数的竞争对手。当一个节点将块追加到垃圾收集队列的底部时，邮资值将通过检查区块链上是否有充值来更新。%
%
\footnote{为了避免检查区块链上的更新以确定支付率的变化，节点可能只希望将更新速率作为对彩票合同上记录的支付事件的响应。}
%
If there was a change, the chunk will need to be reinserted in the queue. 

\subsubsection{结合检索流行度和邮资价值}

除了预期的彩票奖金之外，对盈利能力的估计还需要考虑到出售受欢迎的大宗商品带来的收益。如果我们记录每一个抽奖\gloss{epoch}提供的数据块的次数，那么就可以对这些数据点应用预测模型来预测未来一段时间的收益。幸运的是，我们只需要决定哪些是盈利最少的部分。 

% The distribution of popularity is a power law distribution with a long  tail. Unless Swarm's capacity is so constrained that only popular chunks can be stored, we expect that nearly  half of chunks will not be accessed at all.


当我们迭代具有最小邮资值的块时，我们必须决定每个块是否能够在下一个epoch幸存下来，或者它是否没有被请求的真正承诺。一旦与分位数的容量匹配的块数量被删除，垃圾收集过程将终止(参见图\ref{fig:garbage-collection})。

\subsubsection{统一的价格} 

当推同步块时，每个转发节点只接受其邮资值高于该节点发布的最小值的块。实际上，这意味着初始邮资值不能低于网络中该值的最大值，否则同步不成功。这意味着节点保持低邮资价格收购彩票不会获得更多的流量,他们只是更有获胜的机会,需要更多的存储容量比他们更昂贵的邻居能够存储额外的块,其价值达到低于他们的邻居的最低。

如果邻居们设法保持高价，它将吸引那些出价过低的新节点。如果由于实际容量不足导致的高价格是真实的，则新节点增加存储空间，纠正不均匀性。如果邻近地区因为卡特尔而保持高价格，那么新节点就能够打破这种局面。因此，在较长一段时间内，价格有望趋同。



% Whenever we serve a chunk we update the value of the chunk by adding the retrieval price. For the sake of simplicity, let us assume that there is the garbage collection cycle and the raffle round is at the same time. Knowing the earnings of the last epoch, we recalibrate the chunk profitability predictive model. 





\subsection{保险:负激励\statusorange}\label{sec:chunk-insurance}

\orange{大部分摘自较早的论文-重写更短，以反映最新的}

到目前为止，存储激励机制是指系统通过向存储者提供货币奖励来鼓励内容保存的能力。这是通过邮资彩票实现的，它使邮资支付公平地重新分配给商店。通过这个计划，我们在集体层面上提供了积极的激励。但是，这种系统对\gloss{tragedy of the commons}问题来说是可疑的，因为消失的内容不会对任何一个存储节点产生负面影响。由于缺乏个人问责制，作为防止数据丢失的安全措施，存储激励机制受到限制。另一方面，引入竞争性保险又增加了一层负面激励，迫使商店非常精确地承诺为用户提供可靠性。在激励系统的设计中需要特别注意，以确保如果不把承诺的每一点都储存起来，不仅对保险公司来说是无利可图的，而且是彻底的灾难。 

\subsubsection{惩罚措施}

不像带宽激励的情况下，检索是立即计算和解决的，长期存储保证是承诺的性质，它只能决定，如果承诺已在其有效性结束。在这些情况下，声誉的丧失不足以阻止恶意行为:由于必须允许新节点立即提供服务，骗子只能诉诸于新身份，继续兜售(空)存储承诺。

我们需要威胁采取惩罚性措施，以确保遵守存储承诺。这些将使用\emph{沉积体系}工作。希望出售约定存储收据的节点在做出承诺时应该验证并锁定股权。这意味着节点必须提前注册并签订合同，并提供\gloss{security deposit}。注册后，节点可以出售其资金锁定期间的存储承诺。当他们的注册是有效的，如果他们被发现丢失了他们承诺覆盖的一块，他们将失去他们的押金。

\subsubsection{需求}

让我们从一些合理的指导原则开始:

\begin{itemize}
\item 在交付仓库时，业主需要表明他们的风险偏好。
\item 当提交到存储时，存储器需要表达他们的风险偏好。
\item 要建立合理的市场机制，实现供需平衡。
\item 需要向所有者保证其内容是安全存储的。
\item 有必要建立一个诉讼制度，对不遵守承诺的商店收取费用。
\end{itemize}

业主的风险偏好包括所涵盖的时间段以及\emph{度的可靠性}的偏好。这些首选项应该在每个块的基础上指定，它们应该在协议级别上完全灵活。

满足商店的风险偏好意味着他们有办法表达他们保留他们储存的东西的确定性，并在定价时考虑到这一点。一些节点可能不希望提供太长时间的存储保证，而另一些节点则无法承担太大的押金。这区分了节点在提供服务方面的竞争。

\emph{市场机制}意味着有灵活的\emph{价格谈判}或发现或自动反馈循环，倾向于响应供需变化。

下面，我们将详细阐述一种激励机制，我们将其称为\gloss{swap}、\gloss{swear}和\gloss{swindle}，因为其基本组成部分:

\begin{itemize}
\item[\emph{交换}]
  节点与注册的节点保持准永久的长期联系。在这些连接中，对等点交换块和触发掉期会计的收据(见\ref{sec:accounting})。
  
\item[\emph{发誓}]
  在群集网络上注册的节点负责，如果在链上\gloss{litigation}过程中被发现违反了群集规则，将失去其押金。

\item[\emph{诈骗}]
  节点监视其他节点，根据诉讼程序提交挑战，以检查它们是否遵守了承诺。

\end{itemize}

\subsubsection{合同通过收据}

\gloss{litigation}程序要求各方之间有合同协议，最终将为确保未来内容的可用性而支付费用的所有者和为保存内容并使其在未来任何时间立即可访问而获得奖励的存储者联系起来。激励机制需要确保诉讼是最后的选择。

管理存储交易的最简单解决方案是使用所有者和存储者之间的直接契约。这可以通过确保存储者返回他们接受存储的数据块的签名收据，所有者直接或通过托管支付收据的费用来实现。在后一种情况下，只有当存储人员能够提供存储证明时，他们才能获得锁定资金。这个过程类似于邮票抽奖的过程。保险可以以特别标记的邮票的形式购买，托管收据的声明可以关闭循环，代表上传者和存储者之间的合同。以监护权证明为条件的支付可以像抽签一样执行。

如果未能提供存储的内容，即使消费者试图访问数据块但无法访问，也会受到惩罚，因为消费者不是协议的一方，无法存储和提供所请求的内容。因此，希望检索内容的第三方可以进行诉讼。

如果块和收据的配对是公开的和可访问的，那么内容的消费者/下载者(不仅仅是创建者/上传者)可以在发现块丢失的情况下提起诉讼(见\ref{sec:insurance})。 

\subsubsection{登记}

在节点可以出售长期存储承诺之前，它必须首先通过区块链上的一个合同注册，我们称之为\gloss{SWEAR}合同。SWEAR合约允许节点注册他们的公钥，成为Swarm中负责任的参与者。注册是通过将保证金发送到SWEAR合同中完成的，如果注册节点“发誓”遵守的条款被违反(即节点没有遵守其存储承诺)，该合同将作为抵押品。\emph{登记}仅在设定的期限内有效，在该期限结束时，群节点有权获得其保证金。只要被授予注册身份，Swarm的用户就应该能够依靠存款的损失来抑制违规行为。因此，订金在注册期满前不得退还。因此，保险期的期满应包括一个最后期限，在此期间节点不允许发出新的收据，但仍可受到质疑。

当一个已注册的保险节点收到一个存储最接近他们的数据块的请求时，它可以用签名的收据来确认它。正是这些签名收据用于对内容丢失实施惩罚。由于有锁定的抵押品支持，这些收据可以被视为存储和服务特定区块的有担保承诺。



\subsubsection{提交一个挑战}


如果一个节点没有遵守他们发誓遵守的Swarm规则，就需要执行惩罚性措施，这必须在诉讼程序之前进行。这个过程的实现称为\gloss{SWINDLE}。

当用户试图检索投保内容，但未能找到块时，他们可以通过提交\gloss{challenge}报告丢失。这个场景是启动\gloss{litigation}的典型上下文。这类似于一个法庭案件，收据的签发人是被告，在被证明无罪之前，他们是有罪的。与法院程序类似，当区块链规则被滥用时，尽管有威慑和积极的激励，公众诉讼应该是最后的手段。


该挑战采用发送到SWINDLE合同的交易形式，其中挑战者提供丢失数据块的收据。允许任何节点发送一个块的挑战，只要他们有有效的收据(尽管不一定是发给他们的)。同样的交易还会发送一笔保证金，支付上传一大块内容的费用。质疑和反驳的有效性都需要合同能够轻易地核实。
合同验证收据是否有效，即1)真实，2)有效，3)资金，通过检查以下条件:

\begin{itemize}
\item \emph{真实的}——收据是用注册节点的公钥签名的。
\item \emph{活跃的}—收据的有效期未过。
\item \emph{资助}——在被驳倒的情况下，将向其提供足够的资金，以补偿同行上传的部分内容。
\end{itemize}

上面的最后一点旨在抑制无谓的诉讼，即用虚假的挑战轰炸区块链，并可能导致DoS攻击。

契约附带一个访问器，用于检查给定节点是否受到质疑(可能会受到惩罚)，因此可以通知受到质疑的节点，它们必须以及时的方式呈现块。挑战会持续一段固定的时间，而这段时间的结束基本上就是反驳挑战的最后期限。 

\wip{still pondered - fingerpointing is not necessary}

\subsubsection{指指或证明储存}


所涉及的节点可以通过向区块链发送一个交易来反驳质疑，该交易可以是直接反驳(托管证明或区块本身取决于大小)，也可以是由另一个节点签名的相同区块的收据。此收据需要由更近的邻居(比节点本身更靠近块地址的注册对等点)发出。换句话说，如果一个节点被指控有收据，他们可以转移责任，并提供一个有效的收据从更近的邻居。%
%
\footnote{合同可以很容易地验证新被质疑的节点(作为反驳提交的收据的签名者)是否比最初被质疑的节点更接近块地址。}
%
因此，诉讼可以触发一系列挑战，从最初被挑战的节点一直指向一个不能进一步转移责任的节点，因此必须呈现区块或受到惩罚。这种反驳挑战的方式被称为\gloss{fingerpointing}。 

在验证反驳的格式时，合同通过检查块有效载荷的哈希值与被诉讼的哈希值或验证保管证明来检查其有效性。 

如果在质疑开始的时间内质疑被反驳，被指控节点的押金将保持不变。上传块的成本必须从挑战的押金中偿还给上传者，但为了防止DoS攻击，在任何情况下，这个押金实际上应该比这个高得多(例如，对应的天然气价格的一个小整数倍)。成功驳倒后，挑战被从区块链状态清除。

这个挑战方案是(1)让被告反驳挑战以及(2)让需要它的节点获得实际数据的最简单的方法。

\subsubsection{成功的挑战和执行}

如果在截止日期前对该质疑没有成功的反驳，则指控被视为已被证明，案件进入执行阶段。被证明丢失了块的节点将丢失其存储。由于存款被锁定在SWEAR合同中，因此保证了执行的成功。

如果在诉讼中，发现有一大块(由收据覆盖的)丢失了，保证金必须至少有一部分是\emph{燃烧}。请注意，这是必要的，因为如果罚金作为对丢失区块收据持有人的补偿，它将通过“丢失”串通用户存放的虚假区块，为注册节点提供提前退出的途径。由于Swarm用户对他们的信息被可靠地存储感兴趣，他们保留收据的主要动机是保持Swarm这样做的动机，而不是在他们不这样做的情况下获得补偿的潜力。如果保证金是大量的，我们可以通过支付提起诉讼的赔偿而逃脱惩罚，但是我们必须烧掉大部分(比如95%)的保证金，以确保这条容易退出的路线仍然关闭。

惩罚可以是\emph{悬架}，这意味着被发现有罪的节点不再被视为注册的集群节点。这样的节点只有在创建新身份并再次支付押金后才能恢复销售存储收据。注意，存储的块位于地址的附近，因此必须创建一个新标识也意味着要花费额外的带宽来补充存储。这是对违规节点造成的额外痛苦。


\subsubsection{存款}

另一个需要做出的重要决定是，一大块土地的最大存款额是否应随价格而变化。首先，很难想象这意味着什么。假设节点的存款变化并影响它们被选为存储者的概率:在两个发布相同价格的节点中，选择了一个存款更高的节点。在这种情况下，节点有动机提高赌注，并开始一场投标战。在正常运营的情况下，这种投标不会衡量对服务质量的信心，而只是反映潜在商店的财富。我们得出的结论是，价格应该是可变的，并且完全取决于节点，但更高的置信度或确定性也应该直接反映在它们所承担的保证金数额上:每个区块所承担的保证金应该是价格的常数倍。

假设$s$是一个系统范围的安全常数，规定了在发生损失时价格和保证金之间的比率，对于$p$的广告价格，最低保证金为$d=s\cdot p$。每块、每时代的价格可以自由配置，并由自由市场的供求决定。因此，节点可以自由遵循任何价格甲骨文或形成卡特尔商定的价格。

\subsubsection{开始鼓励约定的服务}

在没有锁定资金的情况下，延迟付款会让商店很容易被拖欠。另一方面，预付款(即在签订合同时付款，而不是在储存期结束后付款)会使买方容易受到欺骗。在不限制节点可以出售的收据总额的情况下，恶意节点可以收集超过其存款的款项并消失。即使他们违背了诺言，押金也被没收了，他们仍然拿着利润走了。考虑到网络规模和对保险存储的相对稳定需求，保证金可能被设置得足够高，因此这种攻击不再具有经济效益。

锁定全部金额，消除了存储方对被保险人可能无力偿债的不信任。在支付保险时，资金应涵盖整个存储期间的存储块的总价格。该金额被锁定，并根据节点提供托管证明的条件分批释放。另一方面，由于付款被延迟，在工作完成之前就不可能收集资金，这就完全消除了\gloss{collect-and-run attack}。

\section{总结}


在本书架构部分的前两章中，我们介绍了群的核心:\ref{sec:network}章中描述的点对点网络层实现了块的分布式不可变存储，这是由下一章中描述的激励系统补充的。由此产生的基础层系统提供:

\begin{enumerate}
    \item 未经允许的参与和访问，
    \item 节点操作符现金输入为零，
    \item 最大的资源利用率, 
    \item 数据的负载均衡分布，
    \item 可伸缩性、 
    \item 抵制审查制度，保护存储和检索的隐私，
    \item 伸缩受欢迎的内容,
    \item 基本可信的否认和保密
    \item 有节点退出的动态网络中的流失阻力和最终一致性，
    \item 由于内在的经济激励，无需干预的可持续性，
    \item 稳健的私有p2p会计， 
    \item 激励带宽共享,
    \item 带链上结算的链下微承诺
    \item 抵抗DoS和垃圾邮件保护，
    \item 积极的(即由奖励驱动的)存储激励，
    \item 针对数据丢失的负面激励(即，通过威胁采取惩罚性措施予以劝阻)。
\end{enumerate}


\chapter{高级功能}\label{sec:high-level-functionality}


本章建立在分布式块存储的基础上，并引入数据结构和流程，以支持更高级别的功能，提供丰富的数据处理经验。特别是，我们将展示如何组织块来表示文件(\ref{sec:files})，如何组织文件来表示集合(\ref{sec:collections})，介绍键值映射(\ref{sec:maps})，然后简要讨论任意函数数据结构的可能性。然后，我们转而提供提供机密性和访问控制(\ref{sec:access-control})的解决方案。

在\ref{sec:feeds}中，我们引入了Swarm feed，它适用于表示各种顺序数据，例如可变资源的版本更新或用于实时数据交换的索引消息:提供持久的pull消息传递系统。为了实现各种类型的推送通知，\ref{sec:pss}引入了\glossplural{Trojan chunk}的新概念，允许将消息伪装成块，并将其定向到群中所需的接收者。我们解释如何木马块和饲料可以一起使用，形成一个完全成熟的通信系统，具有非常强的隐私特征。                                                       

\section{数据structures\statusgreen}\label{sec:datastructures}

\green{}

在前两章中，我们假设数据是块的形式，即固定大小的数据块。我们现在提出的算法和结构，使它可以表示任意长度的数据。然后我们介绍了\glossplural{Swarm manifest}，它形成了表示集合、索引和路由表的基础，允许Swarm托管网站并提供基于url的寻址。

\subsection{文件和Swarm hash\statusgreen}\label{sec:files}

在本节中，我们将介绍\emph{群散列}，它是一种组合块以表示更大的结构化数据集(如文件)的方法。群散列算法背后的想法是,块等Merkle树可以安排连续的叶节点对应的块段的输入数据,而中间节点对应块的块引用的是由他们的孩子,包装在一起,形成另一个块(见\ref{fig:Swarm-hash})。 



\begin{figure}[htbp]
\centering
\resizebox{1\textwidth}{!}{
    \input{fig/Swarm-hash.tex}
}
\caption[群散列\statusgreen]{群哈希:数据输入被分割为4千字节的块(灰色)，这些块是BMT哈希。它们的哈希被打包成从$0$级别开始的中间块，一直到单个块保持在$n$级别。 }
\label{fig:Swarm-hash}
\end{figure}

\subsubsection{分支因素和参考尺寸}

树的分支因子计算为块大小除以参考大小。在未加密内容的情况下，块引用只是块的\gloss{BMT hash}(参见\ref{spec:format:bmt})，它是32字节，因此分支因子仅为4096/32 = 128。在中间节点下引用的一组块称为\gloss{batch}。如果内容被加密，则块引用将成为块哈希值和解密密钥的连接。两者都是32字节长，因此加密块引用将是64字节，因此分支因子是64。 


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/intermediate-chunk-3.pdf}
\caption[中间块\statusgreen]{中间的块。它封装了对其子节点的引用。}
\label{fig:intermediate-chunk}
\end{figure}

因此，单个块可以代表Swarm哈希树中的一个中间节点，在这种情况下，它的内容可以被分割为引用，允许检索它们的子节点，而这些子节点本身可能是中间块，参见图\ref{fig:intermediate-chunk}。通过递归地从根块中解压缩这些数据块，我们可以得到一个数据块序列。 

 \subsubsection{大块跨度和深度完整性}

包含在中间块下的数据长度称为\gloss{chunk span}。为了能够判断一个块是否是一个数据块，在64位小端二进制表示中，块跨度被添加到块数据之前。在计算块的BMT哈希值时，该span构成了元数据，需要将元数据加到BMT根前，并将其散列在一起以提供块地址。当组装一个文件从一个散列,一个可以告诉如果一个块是一个数据块或一个中间块仅仅通过观察跨度:如果跨度大于4 k,块是一个中间块及其内容需要被解释为一系列的散列的孩子;否则它就是一个数据块。

理论上，如果文件的长度已经知道，那么中间块的跨度就没有必要了，因为我们可以计算树所需的中间层的数量。但是，使用span不允许将中间层恢复为数据层。这样，我们就强加了\emph{深度完整性}。 

\subsubsection{追加和恢复已中止的上传}

Swarm哈希具有一个有趣的特性，即与中间块对应的任何数据跨度也是一个文件，因此可以像中间块是它的根哈希一样引用它。这很重要，因为它允许在保留对早期状态的历史引用的同时追加到文件，并且不复制块(除了在Merkle树的不完整的右边缘)。追加也与在上传大文件时崩溃时恢复上传有关。

\subsubsection{随机存取}

注意，文件中除了右边缘之外的所有块都被完全填满了。由于块的大小是固定的，对于任意的数据偏移，可以预先计算到达块的路径，包括在块内搜索的偏移量。因此，\emph{随机存取文件}立即得到了支持(参见图\ref{fig:random-access})。


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/random-access.pdf}
\caption[随机访问在任意偏移量与群哈希\statusgreen]{随机访问在任意偏移与群哈希。任意偏移量告诉我们如何遍历Swarm哈希树。}
\label{fig:random-access}
\end{figure}

\subsubsection{文件的紧凑包含证明}


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/file-inclusion.pdf}
\caption[压缩包含证明文件\statusgreen]{文件的紧凑包含证明。如果我们需要证明segment $i$包含，在除以32(段内位置)后，我们按7位分组，找到中间节点各自的段。}
\label{fig:file-inclusion}
\end{figure}


假设我们要证明在文件中以特定偏移量包含子字符串。我们看到，应用于数据的偏移量映射到遍历Swarm哈希的确定路径。由于子字符串包含证明简单地简化为一系列数据段路径的证明，块地址是BMT哈希的结果，其中基段为32字节长。这意味着在中间块中，BMT基段与子块的地址对齐。因此，证明中间块的子块在特定跨度偏移量上等价于在子哈希上给出段包含证明。因此，文件中的子字符串包含可以通过一系列BMT包含证明(参见\ref{spec:format:bmt})来证明，其中序列的长度对应于Swarm hash树的深度(参见图\ref{fig:file-inclusion})。


请注意，即使在加密数据的情况下，这种包含证明也是可能的，因为对于段位置的解密密钥可以有选择地公开，而不会暴露任何可能危及块中其他地方加密的信息。

在本节中，我们介绍了Swarm hash，这是一种基于块的数据结构，表示文件，它支持以下功能:

\begin{itemize}
    \item \emph{随机存取}——可以从任意偏移量读取文件，而不需要额外的成本。
    \item \emph{附加}——支持没有复制的追加。 
    \item \emph{长度保留编辑}——支持保留长度的编辑，而不重复未修改的部分。
    \item \emph{契约包含证明}—允许包含证明，分辨率为32字节，文件大小为对数。
\end{itemize}



\subsection{集合和manifests\statusgreen}\label{sec:collections}

\gloss{Swarm manifest}是一种结构，它定义了任意路径和文件之间的映射，以表示集合。它还包含与集合及其对象(文件)相关联的元数据。\gloss{manifest entry}包含对文件的引用，更准确地说，是对文件表示的Swarm根块的引用(参见\ref{sec:files})，还指定了文件的媒体mime类型，以便浏览器知道如何处理它。你可以把清单想象成(1)一个路由表，(2)一个目录树，或者(3)一个索引，这使得Swarm可以实现(1)网站，(2)文件系统目录，或者(3)键值存储(见\ref{sec:maps})。manifest提供了在Swarm中启用基于URL的寻址的主要机制(参见\ref{sec:urls})。

清单以压缩的try %表示
%
\footnote{看到\url{https://en.wikipedia.org/wiki/Trie}}
%
其中，单个的try节点被序列化为块(参见\ref{spec:format:manifests})。这些路径与至少指定\emph{参考}的\gloss{manifest entry}相关联。如果路径是集合中多个路径的公共前缀，则引用可以指向嵌入的清单，从而在try中实现分支，参见图\ref{fig:manifest-structure}。 


\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{fig/manifest-structure.pdf}
\caption[清单结构\statusgreen]{显化结构。节点代表一个通用的try节点:它包含描述共享前缀的延续的分叉。fork由键的下一个字节索引，其值包含子节点的Swarm引用以及最长前缀(压缩)。}
\label{fig:manifest-structure}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/manifest-entry.pdf}
\caption[清单条目\statusgreen]{Manifest条目是一种数据结构，它包含对文件的引用，该文件包含与汇编程序、访问控制和http头相关的文件或目录的元数据。}
\label{fig:manifest-entry}
\end{figure}

清单条目是一种数据结构，它封装了关于文件或目录的所有元数据。
该信息最低限度地包括对文件的群引用，并补充文件信息
作为(1)downloader组件的参数，它将块组装成一个字节流，或(2)作为浏览器处理的客户端渲染的参数，或(3)作为manifest到文件系统目录树的映射。(1)举例说明了访问控制信息和擦除编码参数，以及块恢复所需的发布者。(2)包括内容类型的头，或一般的HTTP头，本地集群客户端将挑选他们的API和设置在响应头时，文件被检索。
(3)下载时映射到文件系统的文件信息，如文件权限。

清单的高级API(参见\ref{spec:api:storage})提供了上传和下载文件和目录的功能。它还提供了一个接口，用于向路径上的集合中添加文档，以及从集合中删除文档。注意，此处删除仅意味着创建了一个新的清单，其中所涉及的路径丢失了。在Swarm中没有其他的删除概念，即在已删除清单条目中引用的值仍然保留在Swarm中。Swarm通过\emph{bzz URL方案}公开manifest API(参见\ref{spec:api:storage})。

\subsection{基于url的地址和名称resolution\statusgreen}\label{sec:urls}

之前我们介绍了Swarm的底层网络组件，它是一个分布式的不可变块存储(DISC，参见\ref{sec:disc})。在前两节中，我们介绍了文件(\ref{sec:files})和集合(\ref{sec:collections})可以在Swarm中表示并使用块引用引用的方法。清单提供了一种方法来索引集合中的单个文档，这允许它们被认为是群集中托管的网站的代表。根清单作为群集上虚拟托管站点的入口点，因此类似于托管服务器。在当前web中，域名解析为主机服务器的IP地址，(静态站点的)URL路径根据它们相对于主机的文档根集的路径映射到目录树中的条目。
类似地，在Swarm中，域名解析为对根清单的引用，URL路径根据其路径映射到清单条目。

当HTTP API提供URL时，执行以下步骤:

\begin{enumerate}
    \item \emph{域名解析}——Swarm将主机部分解析为对根清单的引用，
    \item \emph{显化遍历}——沿着与URL路径匹配的路径递归地遍历嵌入的清单，以到达清单条目，
    \item \emph{服务文件}——使用从清单条目的元数据中获取的头(特别是内容类型)在浏览器中检索并呈现清单条目中引用的文件。
\end{enumerate}

Swarm支持使用\gloss{Ethereum Name Service} (\gloss{ENS})进行域名解析。\gloss{ENS}是一个系统，类似于旧网络的DNS，它将人类可读的名称转换为系统特定的标识符，例如，在Swarm.%的情况下是一个参考
% TODO:  add references 
\footnote{RNS，也支持RSK上RIF OS的名称服务。}
%
为了使用ENS, Swarm节点需要连接到一个支持以太坊API (ETH主网，Ropsten, ETC等)的基于evm的区块链。 
ENS用户可以在区块链上注册域名，并设置域名解析为引用。该引用通常是公共(未加密)清单根的内容散列。在这种情况下，该清单表示一个包含网站资产的目录，哈希的默认路径可以设置为所需的根html页面。当ENS名称被导航到启用了Swarm的浏览器或网关时，Swarm将简单地呈现根html页面，Swarm将提供相对路径中提供的其余资产。通过这种方式，用户可以很容易地托管网站，Swarm提供了一个老旧浏览器的接口，并实现了对DNS的分散改进。


\subsection{映射和键值存储\statusgreen}\label{sec:maps}

本节描述在Swarm中实现一个简单的分布式键值存储的两种方法。两者都只依赖于已经引入的工具和api。

一种技术是使用清单:路径表示清单条目中的键和引用，其中包含指向值的特定路径点。这种方法得益于通过bzz manifest API支持插入、更新和删除的完整API(参见\ref{spec:api:storage})。由于清单的结构是紧凑的try，这个键值存储是可伸缩的。索引元数据需要键值对数量的对数存储。查找需要对数带宽。该数据结构允许遵循关键顺序的迭代。

单一所有者块还提供了一种定义键值存储的方法。

另一种技术只是假设将单个所有者块的索引构造为数据库名称和键的哈希值的连接。此结构只提供插入，不提供更新或删除。插入和查找都是常量空间和带宽。然而，查找对于假阴性是不安全的，也就是说，如果没有找到表示键值对的块，这并不意味着它从未被创建过(例如，它可能已经被垃圾收集了)。因此,基于单一所有者块键-值存储是最好的作为(1)有限缓存recomputable值,如翻译(2)之间的映射表示一群散列和Keccak256散列之间用于Ethereum区块链状态单词查找树节点,或(3)传统关系链接,如喜欢、在社交媒体上给帖子投赞和评论。 


\section{访问control\statusgreen}\label{sec:access-control}

\green{}

本节首先讨论使用加密的内容的保密性。一旦为用户提供了管理他人访问受限内容的方法，加密就变得特别有用。用例包括管理私有共享内容以及授权访问web应用程序的成员区域。通过这种方式，我们提供了一个健壮而简单的API来管理访问控制，传统上是通过集中式的门控来处理的，而这经常会导致灾难性的安全漏洞。

\subsection{Encryption\statusgreen}\label{sec:encryption}

介绍如何在分布式公共数据存储中实现机密性。通过这种方式，我们展示了如何满足许多用例存储私人信息的自然需求，并确保只有使用Swarm的特定授权方可以访问这些信息。

很明显，当前web应用中主要使用的基于服务器的访问控制提供的伪机密性是不够的。在Swarm中，节点被期望与其他节点共享数据块，事实上，数据块的存储者被激励为任何请求它们的人提供服务，因此，节点作为受信任的控制访问的把关者是不可行的。此外，由于每个节点都可能是存储器，因此机密性解决方案必须不泄漏任何内容，不允许第三方存储器将私有块与随机数据区分开。因此，防止未授权方访问私有块的唯一方法是使用加密。在Swarm中，如果请求者被授权访问一个块，他们必须拥有一个可以用来解密块的解密密钥，而未授权方则不能。顺便说一下，这也是\gloss{plausible deniability}的基础。

数据块级别的加密在\ref{sec:chunk-encryption}中描述，并在\ref{spec:format:encryption}中正式指定。它
具有理想的特性，即它实际上独立于块存储层，具有与未加密内容完全相同的存储和检索块的底层基础设施。
访问私有数据和公共数据之间的唯一区别是在块引用(参见afaed)中存在解密/加密密钥，以及相关的次要加密计算开销。

%, a constant or linear factor.

存储API的原始\lstinline{GET}端点允许加密和未加密的块引用。
如果块引用的大小是两倍，则会触发解密;由加密块的地址和解密密钥组成。使用该地址，可以检索、存储加密块，并使用提供的解密密钥对其进行解密。API以得到的明文进行响应。

存储API的\lstinline{POST}端点希望用户表明他们是否希望对上传进行加密。在这两种情况下，数据块都将被存储并推同步到网络，但如果需要加密，则需要首先创建加密的数据块。如果没有提供进一步的上下文，将生成一个随机加密密钥，该密钥用作种子来生成随机填充(如果需要的话)，将该块填充到完整的4096字节，最后使用该密钥对明文进行加密。在加密的情况下，API \lstinline{POST}调用返回Swarm引用，该引用由作为块地址的Swarm散列和加密密钥组成。

为了保证加密密钥的唯一性以及减轻操作系统熵池的负载，建议(但不是必需的)使用存储在内存中的(半)永久随机密钥作为明文的\gloss{MAC}生成密钥。
此密钥可以是永久的，并使用\lstinline{scrypt} \cite{percival2009stronger}生成
在启动时提供密码。清单条目的名称空间和路径可以用作上下文，而不是明文。
这种使用\gloss{key derivation function}块加密的结果将是决定性的,只要上下文是一样的:如果我们交换一个字节的文件和加密相同的上下文,所有数据块的文件除了一个修改最终将加密完全按照原(见\ref{spec:format:encryption})。因此，加密对重复数据删除是友好的。 


\subsection{管理access\statusgreen}\label{sec:managing-access}

本节描述客户端需要遵循的流程，以便获得加密内容的完整引用。该协议需要基本的元信息，这些元信息被简单地编码为明文元数据，并显式地包含在文档的根清单条目中。这种非特权访问被称为\gloss{root access}。

相反，\gloss{granted access}是一种选择性访问，需要根访问以及访问凭据:授权的私钥或密码短语。授予访问为共享相同根访问权限的多方访问内容提供了不同的权限。这允许在不更改访问凭据的情况下更新内容。授权访问是通过在引用上使用额外的加密层实现的。

引用的对称加密称为\gloss{encrypted reference}，这一层使用的对称密钥称为\gloss{access key}。

在授予访问的情况下，根访问元信息既包含加密的引用，也包含使用访问凭据获取访问密钥所需的附加信息。一旦获得了访问密钥，就可以通过使用访问密钥对加密的引用进行解密来获得对内容的引用，从而产生由地址根块和根块的解密密钥组成的完整引用。然后可以使用普通方法检索和解密请求的数据。

访问密钥可以从各种来源获得，我们将定义其中三个来源。

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/access-control-single-party.pdf}
\caption[Access key作为单方访问的会话密钥\statusyellow]{Access key作为单方接入的会话密钥。}
\label{fig:access-control-single-party}
\end{figure}

首先，\gloss{session key}是从提供的凭据派生出来的。在授予单个方访问权限的情况下，会话密钥直接用作访问密钥，参见图\ref{fig:access-control-single-party}。在多方参与的情况下，使用额外的机制将会话密钥转换为访问密钥。

\subsubsection{密码}
最简单的证书是\emph{密码}。会话密钥是通过使用\lstinline{scrypt}和在根访问元信息中指定的参数从密码短语派生出来的。crypt的输出是一个32字节的密钥，可以直接用于群加密和解密算法。

在典型的用例中，密码短语是通过带有足够安全措施的带外方式分发的，或者是亲自交换的。任何知道密钥来源的密码短语的用户都能够访问内容。

\subsubsection{不对称的推导}

更复杂的凭证是\emph{私钥}，与整个以太坊用于访问账户的凭证相同，即使用secp256k1的椭圆曲线。为了获得会话密钥，必须在内容发布者和被授权者之间执行一个\gloss{elliptic curve Diffie-Hellman} (\gloss{ECDH})密钥协议。由此产生的共享秘密被用盐搅碎在一起。\gloss{root access manifest}的元数据中包含内容发布者的公钥和salt。根据ECDH的标准假设，此会话密钥只能由发布者和受让人计算，而不能由其他任何人计算。
同样，如果将访问权授予单个公钥，则以这种方式派生的会话密钥可以直接用作访问密钥，从而允许对加密引用进行解密。
图\ref{fig:credentials-to-derive-session-key}总结了使用凭据来派生会话密钥。

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/credentials-to-derive-session-key.pdf}
\caption[派生会话密钥的凭据\statusyellow]{派生会话密钥的凭据。}
\label{fig:credentials-to-derive-session-key}
\end{figure}


\subsection{选择性访问多参与方\statusgreen}

为了管理多方对同一内容的访问，引入了一个额外的层来从会话密钥获取访问密钥。在此变体中，受让人可以使用任意类型的凭据进行身份验证，但是会话密钥派生为
上面描述的不能直接用作解密引用的访问密钥。相反，通过用两个不同的常量(分别为$0$和$1$)对其进行散列，可以得到两个键:一个\gloss{lookup key}和一个\gloss{access key decryption key}。

授予访问权限时，发布者需要生成全局访问密钥来加密完整引用，然后使用
每个被授权者的访问密钥解密密钥。然后，创建一个查找表，将每个授权查找密钥映射到它们加密的访问密钥。然后，对于每个查找密钥，使用相应的访问密钥解密密钥对访问密钥进行加密。

该查找表以Swarm清单格式实现为\gloss{access control trie} (\gloss{ACT})，其路径对应于查找密钥和清单条目，清单条目包含加密访问密钥的密文作为元数据属性值。ACT清单是一个由URL引用的独立资源，URL包含在根访问元数据中，以便用户知道是否使用ACT。它的确切格式在\ref{spec:format:access-control}中指定。

在访问内容时，用户检索根访问元数据，标识ACT资源，然后使用密码短语和密码参数或发布者公钥、私钥和salt计算会话密钥。通过使用$0$对会话键进行散列，他们可以从会话键获得查找键，然后从ACT检索清单条目。为此，他们需要知道ACT清单的根，然后使用查找键作为URL路径。如果条目存在，则用户以密文的形式获取访问密钥属性的值，该密文是用用常量$1$散列会话密钥得到的密钥解密的。然后可以使用生成的访问密钥解密包含在根访问清单中的加密引用，参见图\ref{fig:access-control-multiple-party}。一旦我们解锁了清单根，所有引用都包含解密密钥。

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/access-control-multiple-party.pdf}
\caption[对多个被授权的访问控制\statusyellow]{对多个被授权者的访问控制涉及到从会话密钥到访问密钥的额外层。每个用户必须查找专门为他们加密的全局访问密钥。要查找的密钥和要解密访问密钥的密钥都来自会话密钥，而会话密钥又需要它们的凭据。} 
\label{fig:access-control-multiple-party}
\end{figure}


这种访问控制方案有许多可取的特性:
\begin{itemize}
\item 检查和查找自己的访问权限是ACT考试规模的对数。
\item ACT的规模只是提供了一个被授予者数量的上限，但没有向第三方披露任何超出这个上限的关于被授予者集合的信息。即使那些被纳入ACT的学生也只能知道自己是受资助者，但除了人数上限之外，无法获得其他受资助者的信息。
\item 授予对额外密钥的访问权限需要通过单个条目扩展ACT，该条目是ACT大小的对数。 
\item 撤销访问需要更改访问密钥，因此需要重新构建ACT。注意，这还要求发布者在创建初始ACT之后保留受让人的公钥记录。
\end{itemize}

\subsection{访问hierarchy\statusgreen}

在最简单的情况下，访问密钥是对称密钥。然而，这只是更灵活的解决方案的一种特殊情况
访问键由一个对称键和一个键派生路径组成，该路径从根键派生。在这种情况下，除了加密引用之外，还可能包括派生路径。任何具有访问密钥(其派生是引用的派生路径的前缀)的方都可以通过使用自己的密钥和引用的其余派生路径派生其密钥来解密引用。

这允许使用树状的角色层次结构，可能反映组织结构。只要角色变更是“晋升”，即导致特权的增加，就足以为每次角色变更更改一个ACT条目。

在\ref{spec:format:access-control}中更详细地指定了清单的确切格式以及序列化约定



\section{集群饲料和可变资源更新\statusyellow}\label{sec:feeds}

\green{}

饲料是蜂群的一个独特特征。它们构成了单个所有者块的主要用例。提要可用于对可变资源的修订进行版本控制，为主题的连续更新建立索引，将部分发布到流，或在通信通道中发布连续消息。feed实现了持久的pull-messaging，也可以解释为发布-sub系统。
首先，在\ref{sec:feed-chunks}中，我们介绍了提要如何由带有索引方案的单个所有者块组成，我们将在\ref{sec:indexing-schemes}中讨论如何选择索引方案。在\ref{sec:feed-integrity}中，我们分析为什么饲料完整性是相关的，以及如何验证和执行。\ref{sec:epoch-based-feeds}描述了\gloss{epoch-based feeds}，它提供以接收零星更新为主题的提要，并提供一种搜索方式。最后，在\ref{sec:feed-as-channel}中，我们将展示如何将提要用作发件箱，以便在通信通道中发送和接收后续消息。


\subsection{饲料块\statusyellow}\label{sec:feed-chunks}

提要块是具有相关约束的单个所有者块，该约束的标识符由\gloss{feed topic}和\gloss{feed index}的散列组成。主题是一个32字节的任意字节数组，这通常是一个或多个人类可读字符串的kecak256散列，指定主题和提要的子主题(可选)，参见图\ref{fig:feed-chunk}。 


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/feed-chunk.pdf}
\caption[饲料块\statusgreen]{提要块是单个所有者块，其中标识符是主题的散列和索引。索引是根据索引方案计算的确定性序列。同一主题的后续索引表示提要更新的标识符。}
\label{fig:feed-chunk}
\end{figure}

索引可以采用各种形式来定义提要的一些潜在类型。本节讨论的是:(1)使用增量整数作为索引的简单提要(\ref{sec:indexing-schemes});(2)使用历元ID (\ref{sec:epoch-based-feeds})的\gloss{epoch-based feeds};和(3)使用\gloss{double ratchet}密钥链生成的nonces的专用信道feed。(\ref{sec:feed-as-channel})。
所有这些提要类型的统一属性是发布者(所有者)和使用者都必须知道\gloss{indexing scheme}。

发布者是feed块的唯一所有者，也是唯一能够在feed中发布更新的人。发布更新需要(1)根据主题和正确的索引构造标识符，并(2)将其与更新的任意内容的哈希值连接在一起进行签名。由于标识符在所有者的地址子空间中指定了一个地址，因此该签名有效地将有效负载分配给这个地址(参见\ref{sec:single-owner-chunks})。通过这种方式，可以证明发布在特定提要上的所有项仅由关联私钥的所有者创建。

相反，用户可以通过其地址检索块来使用提要。检索更新需要使用者从所有者的公钥和标识符构造地址。为了计算标识符，他们需要主题和适当的索引。为此，他们需要知道索引方案。

feed使Swarm用户能够表示一系列的内容更新。更新的内容是提要所有者根据标识符签署的有效负载。有效载荷可以是一个群引用，用户可以从中检索相关数据。

\subsection{索引方案\statusyellow}\label{sec:indexing-schemes}

不同类型的提要需要不同的\glossplural{indexing scheme}和不同的查找策略。在接下来的内容中，我们将介绍几个基本独立的维度，在这些维度中，提要可以被分类，并且在做出选择时显得相关。


在提要块的结构中，实际使用的索引方案，甚至是否有一个索引方案(例如，如果单个所有者块是一个提要块)都没有透露。由于转发节点验证块时不需要此信息，因此在结构中显式地使用子类型会泄漏不必要的信息。 

\subsubsection{更新的语义}

提要的更新可以有三种不同的语义，定义三种提要子类型。
修订或可变资源更新是\emph{代用的}，系列更新是\emph{替代}，分区更新是\emph{累计}。

表示同一语义实体的修订的提要称为\gloss{mutable
resource updates}。这些资源会发生变异，因为潜在的语义实体发生了变化，比如你的简历版本或资源描述变得更加复杂，比如维基百科上关于罗马皇帝的条目。用户通常会对这些资源的最新更新感兴趣，过去的版本只具有历史意义。

由一个共同的线程、主题或作者连接起来的一系列内容，比如社交媒体上的状态更新、个人的博客帖子或区块链的区块，也可以用称为\gloss{series}的提要表示。
系列中的更新被解释为可选的和独立的实例化或按时间顺序显示的情节。

最后，还有表示为提要的\gloss{partitions}，提要的更新将被累积或添加到较早的提要中，例如视频流的部分。它们主要不同于序列，因为提要更新本身是不可解释的，而时间序列可能表示对应于资源结构的某种序列化的处理顺序，而不是时间序列。当这样的提要被访问时，所有部分的积累可能是必要的，即使是为了表示的资源的完整性。

如果后续更新的提要包含数据结构的引用索引之前更新(例如一个键-值存储使用更新的时间戳或简单的根散列连接更新内容),然后在所有三个案例\gloss{lookup strategy}减少查找最新的更新。

\subsubsection{更新频率}

在随时间更新的提要中可能有几种类型，\gloss{sporadic feeds}具有不规则的异步性，即更新可能有不可预测的间隔，还有\gloss{periodic feeds}具有定期重复发布的更新。

我们还将讨论\gloss{real-time feeds}，其中更新频率可能不是定期的，但确实显示了实时人类交互时间跨度内的变化，即它们被秒到分钟的间隔所打断。

\subsubsection{订阅}

feed可以解释为\gloss{pub-sub systems}，具有持久性，支持异步拉取。在接下来的内容中，我们将分析作为pub/sub的订阅feed的实现是如何受到\gloss{indexing scheme}选择的影响的。

为了迎合订阅用户的需求，需要跟踪更新。如果我们知道最新的更新，则需要使用定期轮询来获取后续的更新。
如果提要是周期性的，那么可以在一个已知周期之后开始轮询。或者，如果提要更新足够频繁(最多是比所需轮询频率少1位整数数量级)，那么轮询也是可行的。
然而，如果提要是零星的，轮询可能不实用，我们最好求助于推送通知(见\ref{sec:trojan}和\ref{sec:notification-requests})。

如果我们由于离线而错过了一段时间的轮询，或者只是创建了订阅，我们也可以依靠推送通知或使用\gloss{lookup strategy}。

查找分区不是问题，因为我们需要获取和累积每个更新，所以在这种情况下，只迭代连续索引的策略无法得到改进。
对于周期性提要，我们只需计算给定时间的索引，因此异步访问是有效且简单的。
然而，查找偶尔更新的提要的最新版本需要进行一些搜索，因此
将受益于\gloss{epoch-based indexing}。



\subsubsection{聚集索引}

可以使用\gloss{feed aggregation}将一组零星的提要转换为定期提要。想象一个像Reddit这样的多用户论坛，每个注册的参与者会使用零星的feed在一个帖子上发表评论。在这种情况下，让每个用户监视每个其他用户的评论提要并搜索其零星的提要以检索线程上的所有评论是不现实的。对于所有用户来说，只做一次会更有效。索引员正是这样做的，并将每个人的评论聚合到一个索引中，这个数据结构的根现在可以作为定期提要发布，参见图bfdbbaf。可以选择时间段，以提供实时的feed体验;即使改变的速度不能证明它是合理的，即一些更新将是多余的，成本摊销在所有使用聚合饲料的用户，因此在经济上是可持续的。 

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/feed-aggregation-2.pdf}
\caption[提要聚合\statusyellow]{提要聚合用于合并来自多个源提要的信息，以避免使用者重复工作。参与群组通信的\textbf{Left:} 6节点(讨论帖子、进行实时聊天或异步邮件线程)。每个节点将其贡献发布为发件箱提要更新(小的彩色圆圈)。每个参与者都轮询对方的基于纪元的提要与查找工作的重复。\textbf{Right:}的6个节点现在注册为一个聚合器的源，该聚合器轮询节点的提要并创建索引，将源聚合为一个数据结构，然后每个参与者都可以提取该数据结构。}
\label{fig:feed-aggregation}
\end{figure}

这样的服务可以提供任意级别的安全，但无需诉诸于声誉而不值得信任。使用合意数据结构进行聚合，可以使用廉价和紧凑的包含证明(见\ref{sec:files})来证明不正确的索引，因此，与正确性相关的任何挑战都可以在链上进行评估。如果有人提出无可辩驳的质疑，就有可能失去他们的保证金，这对提供者保持良好的服务质量是一个强有力的激励。

\subsection{完整性\statusyellow}\label{sec:feed-integrity}

我们说一个feed有\emph{完整性}，如果它的每个更新都是完整的，即更新是明确的。在形式上，这意味着对于每个索引，各自的提要标识符只分配给单个有效负载。顺便说一下，这也意味着相应的提要块具有完整性。正如在\ref{sec:single-owner-chunks}中讨论的，这是一致检索的先决条件。
如果连续更新的有效负载被想象为区块链的块，那么完整性标准要求提要所有者不能分叉他们的链。

事实上，提要的完整性只能由所有者来保证。但它能被检查或执行吗?用户可以通过在区块链上下注保证金来保证feed的完整性，如果发现他们在更新中重复签名，他们将失去这笔保证金。尽管这可能会强烈抑制为长期利益而分叉提要，但就其本身而言，它仍然无法为提要的消费者提供足够的完整性保证。因此，我们必须设计索引方案来加强这种完整性。

\subsubsection{权威版本历史}

可变资源更新feed跟踪版本的方式与以太坊名称服务非常相似。
当所有者合并一个版本(比如一个网站)时，他们想要注册当前版本的内容地址。为了保证历史没有争议，有效负载需要合并前一个有效负载的散列。这就要求有效负载必须是一个复合结构。如果我们希望有效负载只是一个清单或清单条目，以便它可以根到匹配URL的路径，或直接显示，这是不可能的。此外，如果提要内容不是有效负载哈希，那么ENS注册一个有效负载哈希，但chunk可能在Swarm上不存在，因此违反了ENS的语义。

将前一个有效负载哈希合并到后续索引的索引方案的行为类似于区块链，因为它表达了所有者对特定历史的明确承诺，任何消费者读取和使用它都表示他们接受这样的历史。
只有通过检索上一次已知的更新之后的每个更新，才能查找此类提要。该地址是更新块的地址，因此注册更新地址既保证了历史完整性，又保留了ENS语义，因此注册地址只是一个chunk的Swarm引用。
这样的提要实现了\gloss{authoritative version history}，即对可变资源的修订的安全审计跟踪。 

\subsubsection{实时的完整性检查}

确定性索引提要支持\gloss{real-time integrity check}。在表示区块链(账本/侧链)的提要上下文中，完整性意味着非分叉和唯一的链承诺。实时执行此功能的能力允许快速和安全地定义事务结束性。

我们用一个链下p2p支付网络的例子来说明这一点，其中每个节点的锁定资金被分配给一组固定的债权人(详见\cite{ethersphere2019swap})。节点的债权人需要检查重新分配的正确性，即总增加被复签减少所覆盖。
如果债务人持续发布一份存款分配表，列出详尽的债权人名单，通过发行两种针对目标债权人的替代方案，债务人将能够安排双重支出。相反，这个分配表的唯一性的确定性允许债权人得出最终结论。

我们声称，使用群馈源，这种唯一性约束可以实时检查。

这里的观点是，有意义地控制对单个所有者块请求的响应是不可能的:即使攻击者控制了块地址的整个邻近区域，也没有系统的方法来用特定的版本响应特定的请求者
%
\footnote{如果块是使用相同的路由上传的，那么后面的块将作为已知的被拒绝。如果这两个块来自网络中的不同地址，它们可能最终都在各自的本地邻居中。这个场景将导致不一致的检索，这取决于请求最终指向哪个节点。}
%
这是由于转发Kademlia的性质，请求的发起者模棱两可的结果。让我们假设攻击者通过一些复杂的流量分析，有机会使用$1/n$(渐近上限)来识别发起者并给出微分响应。然而，从随机地址发送多个请求，可以测试完整性，并将一致的响应视为结束性的要求。攻击者使用$k$独立请求为债权人测试提供一致的差异响应的可能性是$1/n^k$。在$k$中使用线性带宽开销，我们可以获得关于更新唯一性的指数确定度。如果债权人找到了一致性，它可以得出结论，没有可供选择的分配表。


通过要求分配表作为提要更新进行传播，我们可以利用无权限、可用性和匿名性来强制提要完整性。如果提要是一个类似区块链的账本，则实时完整性检查将转换为分叉终结性。 


\subsection{Epoch-based
索引\statusyellow}\label{sec:epoch-based-feeds}

\yellow{}

为了使用单个所有者块实现具有灵活更新频率的提要，我们引入了\gloss{epoch-based feeds}，这是一种索引方案，其中单个所有者块的标识符包含与发布时间相关的锚。为了能够找到最新的更新，我们介绍一下
自适应查找算法。 

\subsubsection{时代的网格}

\gloss{epoch}表示从特定时间点开始的具体时间段，称为\gloss{epoch base time}，并具有特定的长度。
周期长度表示为以秒为单位的2的幂。最短的是$2^0 = 1$秒，最长的是$2^{31}$秒。

\gloss{epoch grid}是纪元的排列，其中行(称为级别)表示将时间划分为具有相同长度的不同不相交纪元的可选划分。级别的索引是根据epoch长度的对数，按照惯例，将级别0和1秒的epoch长度放在底部，见图\ref{fig:epoch-grid}。

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/epoch-grid.pdf}
\caption[Epoch网格与基于纪元的feed updates\statusorange]{Epoch网格显示了基于纪元的提要的前几个更新。所占据的时代用黄色标记，并编号以反映它们所代表的更新顺序。 }
\label{fig:epoch-grid}
\end{figure}

当在epoch网格中表示基于epoch的提要时，每个更新将根据它们的时间戳分配给网格中的不同epoch。特别地，一个更新被映射到包含时间戳的最长空闲时期。这种结构为一系列更新提供了一个连续的结构，从而便于搜索。连续性要求意味着，通过知道上一次更新的epoch，可以明确地将后续更新映射到epoch。


为了确定一个特定的纪元，我们需要知道纪元基准时间和级别。这一对被称为\gloss{epoch reference}。为了计算$t$在特定水平$l$上任何给定时刻的历元基时间，我们将丢弃$t$的$l$最低有效位。
这个级别需要一个字节，epoch基准时间(使用linux秒)需要4个字节，因此epoch引用可以序列化为5个字节。
任何基于纪元的提要的第一次更新的纪元引用总是相同的。

\subsubsection{将纪元映射到feed更新块}

然后，可以使用序列化的epoch引用作为\gloss{feed index}将提要更新映射到提要块。提要的主题与索引散列在一起会产生用于构造表示提要块的单一所有者块的提要标识符。

为了确定存储后续更新的纪元，发布者需要知道他们存储上一个更新的位置。如果发布者没有跟踪这一点，他们可以使用查找算法来找到他们的最新更新。



\subsubsection{查找算法}

当使用者检索提要时，他们通常要么想在特定时间查找提要的状态(历史查找)，要么想查找最新的更新。

如果需要基于\emph{目标}时间的历史查找，则更新可以包含一个将时间戳映射到状态的数据结构。在这种情况下，找到比目标晚的任何更新都可以用来确定地查找更早时间的状态。

如果没有这样的索引可用，那么历史查找需要找到时间戳早于目标的最短填充历元。

为了选择最好的开始纪元来遍历我们的网格，我们必须假设最坏的情况，也就是资源在我们最后一次看到它之后再也没有更新过。如果我们不知道资源最后一次更新的时间，我们假设0是它的“最后一次”更新。

我们可以猜测起始级别是$\mathit{lastUpdate}\xor \mathit{NOW}$从左边开始计数的第一个非零位的位置。两次(上次更新时间和现在)之间的差异越大，级别就越高。

在\ref{sec:epoch-based-feeds-appendix}中，我们向读者介绍一个示例。

\subsection{实时数据交换}\label{sec:feed-as-channel}

提要可用于表示通信通道，即角色的传出消息。这种被称为\gloss{outbox feed}的提要可以被创建来提供类似电子邮件的通信或即时消息，甚至两者的结合。对于类电子邮件的异步性，可以使用\gloss{epoch-based indexing}，而对于即时消息传递，最好使用确定性序列索引。
在群组聊天或群组电子邮件中，机密性是通过对数据结构的访问控制来处理的，对每一方对线程的贡献进行索引。通信客户机可以检索与线程相关的每个组成员的提要，并合并它们的时间线以进行呈现。

即使是论坛也可以采用这种发件箱机制，但是，超过一定数量的注册参与者，在客户端聚合所有发件箱可能变得不切实际，需要索引聚合器或其他方案来众包数据组合。

\subsubsection{双向私人频道}
 
私有的两方通信也可以使用发件箱馈送实现，参见图\ref{fig:feeds-as-channel}。这些提要的参数是作为初始密钥交换或注册协议(参见\ref{sec:pss-key-exchange})的一部分设置的，该协议确保各方同意索引方案以及使用的加密。 


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/feeds-as-channel.pdf}  
  \caption[Swarm feed作为outboxes \statusgreen]{群馈作为私人交流的发件箱。发件箱提要表示会话中来自某一方的连续消息。索引方案可以遵循一个密钥管理系统，该系统具有很强的私密性，使通信通道本身变得模糊，并使拦截攻击代价高昂。}
\label{fig:feeds-as-channel}
\end{figure}


用于即时消息传递的实时系列提要应该有一个索引方案，其中至少有几个更新需要确定性的延续。这使得可以提前为将来的更新发送检索请求，即在处理以前的消息期间甚至之前。当这种检索请求到达地址与请求的更新地址最近的节点时，显然无法找到chunk，因为对方还没有发送它们。然而，即使是这些存储节点也被鼓励保持检索请求的活动，直到它们过期(请参阅\ref{sec:retrieval}中的参数)。这意味着在它们的生存时间设置(30秒)结束之前，请求将表现为订阅:更新块的到来将触发对开放请求的传递响应，就像它是发送给订阅者的通知一样。这将预期的消息延迟降低到单程转发路径平均时间的两倍以下，参见图\ref{fig:outbox-feed-latency}。 


\begin{figure}[htbp]
\includegraphics[width=\textwidth]{fig/outbox-feed-latency.pdf}  
\centering
\caption[提前请求未来的更新\statusgreen]{提前请求未来的更新。该图显示了双方a和B之间使用发件箱提要进行即时消息传递期间一系列事件的时间。这些列指定提要更新地址的邻近位置。圆圈表示协议消息到达的时间:颜色表示数据的来源，空的圆圈表示检索请求，完整的圆圈表示到达各自的邻居的同步推送。请注意，发件箱地址是预先确定的消息，因此可以在更新到达之前发送检索请求。

重要的是，发送$m$消息的一方和接收它的另一方之间的延迟显示为$\delta(m)$。消息$A_3$和$A_4$在$A_2$之前到达，可以报告和修复。如果地址可预见性只适用于前面的1条消息，那么$B_2$和$B_3$都将有更长的延迟。

还需要注意的是，$B_2$和$B_3$的延迟是由预先请求帮助的:$B_4$和$B_5$的检索请求在收到feeds和$B_2$后发送，并在$B_2$和$B_3$分别到达它们的邻居的同时到达它们的邻居。如果地址可预测性只提前1条消息，这也会导致$B_2$和$B_3$有更长的延迟。}
\label{fig:outbox-feed-latency}
\end{figure}


\subsubsection{Post-compromise安全}

一个名为\gloss{double ratchet}的密钥管理解决方案实际上是用于即时消息加密的行业标准。
通常使用\gloss{extended triple Diffie--Hellmann key exchange} (\gloss{X3DH})来建立双棘轮钥匙链的初始参数(见\ref{sec:pss-key-exchange})。

双棘轮将基于连续密钥协议的棘轮与基于密钥派生函数\cite{perrin2016double}的棘轮组合在一起。该方案可以被一般化的\cite{alwen2019double}，并被理解为一个很好理解的原语的组合，并显示出提供(1)前向保密，(2)后向保密，%
%
\footnote{也被称为未来保密或妥协后安全。}
%
(3)即时解密和消息丢失恢复能力。


\begin{figure}[htbp]
\centering
\includegraphics[width=.6\textwidth]{fig/double-ratchet.png}
\caption[未来的保密更新地址\statusorange]{更新地址的未来保密}
\label{fig:double-ratchet-for-feeds}
\end{figure}

在端到端加密的保密性之上，Swarm提供了对攻击的进一步抵抗。由于转发了Kademlia，发件人是模棱两可和可否认的。由于正常的推同步和拉同步流量，消息也会混淆。为了使攻击者难以攻击，如果我们在双棘轮机制中添加更多的钥匙链，索引序列也可以提供\gloss{future secrecy}。除了根、发送和接收加密密钥链，我们还需要引入另外两个:outgoing和incoming \gloss{outbox index key chains}，见图\ref{fig:double-ratchet-for-feeds}。这样做的结果是，底层的通信通道被混淆了，即拦截一个发件箱更新块并知道它的索引，而不能揭示之前或后续的发件箱更新索引。这使得后续消息的监视或拦截变得非常困难和昂贵。

在\ref{sec:feed-integrity}中，我们将有效负载散列分解到索引方案中，以实现链的不可合并性(明确的历史记录)。受此启发，我们还建议在后续的提要更新索引中考虑有效负载散列。这就产生了称为\gloss{recover security}的附加属性，直观地确保一旦对手设法伪造了从a到B的消息，那么B将不会接受从a到B的消息。
如果A发送给B的消息的真实性影响到后续的\gloss{feed index}，则可以保证这一点。如果存在不匹配(其中一条消息是伪造的)，消息将被查找到错误的地址，因此通信通道将被放弃，并启动一个新的通道。这样的通信通道代表了一个完全保密的实时消息零泄漏解决方案。




\section{Pss:直接推送消息与邮件装箱\statusgreen}\label{sec:pss}

\green{}

本节介绍\emph{pss}, Swarm的直接节点对节点推送消息解决方案。
其存在的功能和动机被这个词的其他决议戏谑地捕捉到:

\begin{itemize}
\item \emph{群集邮政服务}——如果收件人在线，则发送消息;如果收件人不在网上，则存储以供下载。
\item \emph{PSS是BZZ低语}——除了与中国低语的关联，它肯定承载着以太坊低语的精神和抱负。%
％
\footnote{Whisper是一个基于流言的黑暗信息系统，现在已经没有开发了。由于缺乏可伸缩性，它从未被广泛采用。Whisper与Swarm和以太坊区块链一起，是三合一的通信组件，是以太坊web3最初愿景的基础。}
％
Pss依附于Swarm的\gloss{distributed storage}，并因此继承了它们对传递和持久性的充分激励。同时，它借鉴了Whisper的加密、信封结构和API。
\item \emph{pss !指令嘘/耳语}——唤起不向第三方披露信息的努力，这正是pss的口号:真正的零泄漏消息，除了匿名和机密性，消息的行为也是不可检测的。
\item  \emph{发布/订阅系统}——API允许发布和订阅主题。
\end{itemize}

首先，在\ref{sec:trojan}中，我们引入了特洛伊块(Trojan Chunks)，即向存储器发送伪装成块的消息，这些块的内容地址恰好落在目标接收者的附近。 
\ref{sec:pss-key-exchange}讨论了使用pss发送联系信息以打开实时通信通道。
在\ref{sec:addressed-envelopes}中，我们探索了feed标识符的挖掘，以定位具有单个所有者块地址的邻居，并给出了一个有地址信封的构造。最后，基于木马块和地址信封，\ref{sec:notification-requests}引入了更新通知请求。
pss提供的用户体验将在稍后的\ref{sec:pss-ux}中讨论。 

\subsection{木马chunks\statusgreen}\label{sec:trojan}

承诺提供私人消息的尖端系统往往难以提供真正的零泄漏通信\cite{kwon2016riffle}。虽然将发送方和接收方链接起来在加密上被证明是不可能的，但对流量分析的抵制更难实现。拥有足够大的匿名集需要在任何时候都有大量可用的数据。在没有大规模采用的情况下，要保证专用消息网络中的高消息率，就需要持续的虚假流量。有了Swarm，就有机会将信息伪装成块流量，从而混淆信息本身的行为。

我们将\gloss{Trojan chunk}定义为一个内容处理块，其内容具有固定的内部结构，参见图\ref{fig:trojan-chunk}:

\begin{enumerate}
    \item \emph{跨度}——8字节little endian uint64消息长度  
    \item \emph{现时标志}—32字节任意时刻 
    \item \emph{木马的信息}——4064字节非对称加密的消息密文，由底层明文组成
\begin{enumerate}
        \item \emph{长度}——以字节为单位的消息长度的2字节小端编码
        \item $32$字节混淆的主题id   
        \item \emph{有效载荷}——消息的$m$字节数 
        \item \emph{填充}——$4030-m$随机字节。
    \end{enumerate}
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/trojan-generic.pdf}
\caption[木马块或pss message\statusgreen]{pss消息是一个木马块，它用一个木马消息包装一个模糊的主题标识符，该木马消息反过来包装要由处理它的应用程序解释的实际消息有效负载。}
\label{fig:trojan-generic}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/trojan-chunk-3.pdf}
\caption[木马chunk\statusgreen]{木马块封装了不对称加密的木马消息。}
\label{fig:trojan-chunk}
\end{figure}

发送方知道接收方的公开密钥后，将消息封装在一个木马消息中(即在消息前加上长度前缀，然后填充到4030字节)，然后使用接收方的公开密钥对其进行加密，通过非对称加密获得木马块的密文有效载荷。然后发送方找到一个随机的nonce，当它被添加到有效负载前时，块散列到一个以\gloss{destination target}前缀开始的地址。目标目标是表示地址空间中特定邻域的位序列。如果目标是作为接收者覆盖地址的前缀派生的部分地址，匹配目标意味着块落在接收者的邻近区域。如果只知道公钥，则假定它是收件人的bzz帐户，即他们的覆盖地址可以从它%计算
%
\footnote{可选覆盖可以与公钥相关联，特定地址上的节点可以监听多个公钥。}
%
(参见\ref{sec:overlay-addressing}和\ref{spec:format:bzzaddress})。然后，寄件人将这一区块上传至Swarm，并将其选择的邮票与收件人地址所在的社区进行同步。如果接收节点在线，只要匹配目标的位长大于接收节点的邻域深度，它们就一定会接收chunk。在实际应用中，目标应该是$n+c$位长，其中$n$为群中估计的平均深度，$c$为一个小整数。 

\subsubsection{接收木马的信息}

只有当接收者成功地使用与他们作为常驻密钥发布的公钥(见\ref{sec:pss-key-exchange})相对应的私钥打开了木马消息并进行完整性检查/主题匹配时，他们才知道一个块是pss消息。希望接收此类木马消息的节点将不断尝试打开他们最接近的所有消息。转发节点(或除发送方和接收方以外的任何人)没有办法区分随机加密块和木马消息，这意味着通信完全混淆为通用块流量。

在收件人使用非对称解密打开信封之后，有一个完整性检查和主题匹配的组合步骤。知道有效负载的长度(从消息的前2个字节开始)，接收方获取有效负载片并计算它的kecak256哈希值。现在，对于客户端订阅的每个主题，它将有效负载散列与主题一起散列。如果带有主题的结果片段xor-ed与消息中混淆的主题id匹配，则消息确实表示为带有所述主题的消息，并使用有效负载作为参数调用已注册的处理程序。

\subsubsection{用于异步交付的邮件装箱}

如果收件人不在网上，该邮件块将会像其他邮件块一样胜出，这取决于它所拥有的邮票。每当接收节点联机时，它从邻近的最接近它的块拉同步，其中所有的木马块，以及他们自己尚未收到的消息。换句话说，通过木马消息，pss自动提供异步\emph{邮箱}功能，即。
发送方不需要采取任何进一步的行动，即使在通信方发送时它们处于离线状态，未发送的信息将被保存下来，并在它们在线时对接收方可用。邮筒的持续时间是由邮票控制的，其控制方式与块的存储方式完全相同，事实上，它是完全无法区分的。

\subsubsection{开采接近}

寻找靠近接收地址的散列的过程类似于在区块链上挖掘块。木马块中的nonce段也扮演着与块nonce完全相同的角色:它提供了足够的熵来保证一个解决方案。挖掘的难度与目标目标的长度相对应:确保接收者将接收消息所需的最小接近顺序需要高于接收者的邻域深度%
%
\footnote{在挖掘木马块时，使用邮资彩票批处理深度(请参阅\ref{sec:postage-lottery})作为目标接近顺序的启发式方法是有意义的。这可以作为对邮票智能合约的只读调用。}
%
当它上线时，它是网络中节点数的对数。在找到合适的内容地址之前，每个木马消息需要尝试的nonces的预期数量是困难的指数级，因此等于网络中的节点数量。由于寻找nonce所需的预期计算周期数等于网络大小，在实践中，挖掘一个特洛伊木马永远不会昂贵或缓慢，即使是对单个节点。第二个范围内的小延迟预计仅在一个有10亿个节点的网络中出现，即使这样也可以接受，因为木马消息只用于一次性实例，如信道的初始化。所有后续的实时交换将使用前面描述的使用单个所有者块的双向发件箱模型进行。


\subsubsection{匿名邮箱}

如果邮票还没有过期，则保证对pss消息的异步访问。接收方只需要创建一个节点，该节点的覆盖地址与发布为接收方常驻地址的目的目标相对应。

可以简单地创建一个匿名邮箱。匿名邮箱可以代表客户端接收pss消息，然后在单独的私有提要上发布这些消息，以便预期的收件人可以在它们恢复在线时读取它们。

\subsubsection{聚合索引寄存器}

正如在\ref{sec:indexing-schemes}中提到的，聚合索引服务帮助节点监视零星的提要。例如，论坛索引器聚合注册成员的贡献提要。对于公共论坛，下链注册也是可能的，只需向聚合器发送一个pss消息即可实现。 


\subsection{key exchange的初始联系人\statusgreen}\label{sec:pss-key-exchange}


加密通信需要一次握手，以对作为对称密钥生成方案输入的初始参数达成一致。\gloss{extended triple Diffie--Hellmann key exchange} (\gloss{X3DH})就是这样一种协议\cite{marlinspike2016x3dh}，用于建立握手后通信协议的初始参数，如前面在提要一节中讨论的\emph{double-ratchet方案}(请参阅\ref{sec:feed-as-channel})。
在接下来的内容中，我们将描述如何在无服务器设置中使用pss实现X3DH协议。

Swarm的X3DH使用与以太坊相同的原语，即secp256k椭圆曲线、kecak256哈希和EC公钥的64字节编码。

Swarm X3DH协议允许双方建立一个共享的秘密，以形成用于确定握手后双向消息传递中使用的加密密钥的输入。\emph{引发剂}是发起与\emph{应答器}的双向通信的一方。响应者应该发布必要的信息，使响应者先前不知道的各方能够发起联系。零泄漏通信可以通过首先执行X3DH来建立双棘轮协议用于数据加密的种子密钥，以及所使用的提要索引方法来实现。这将使响应者能够检索发件箱提要的更新。

X3DH使用如下密钥:%
%
\footnote{该协议为响应器指定了一次性的预键，但可以安全地忽略它们，因为它们只作为重放保护，而在本实现中，这是通过其他方式解决的。}

\begin{itemize}
\item 应答者长期公共身份密钥- $K^{\mathrm{ENS}}_r$，
\item 应答器常驻密钥(aka signed pre-key) - $K^{\mathrm{Res}}_r$，
\item 启动器长期身份密钥- $K^{\mathrm{ID}}_i$，
\item 会话的启动器临时密钥- $K^{\mathrm{EPH}}_i$。
\end{itemize}{}



\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/prekey-bundle-feed-update.pdf}
   \caption[X3DH预密钥包feed更新\statusgreen]{X3DH预密钥包提要更新包含常驻密钥和常驻地址，并可选地与ENS名称散列一起加密，以证明惟一性并提供身份验证。}
\label{fig:prekey-bundle-feed-update}
\end{figure}


\gloss{pre-key bundle}包含启动器需要知道的关于响应器的所有信息。然而，这些信息不是存储在(通常是第三方)服务器上，而是存储在Swarm中。为了人性化的身份管理，可以选择使用ENS提供熟悉的基于用户名的身份。ENS解析器的所有者代表该人物的长期公共身份密钥，并被认为已经过身份验证。长期标识地址可以用来构造一个基于时代的提要，该提要的主题id表明它为将要对应的对象提供了预键包。当使用新身份启动通信时，发起者将检索来自提要的最新更新，其中包含当前\emph{居民主要}(又称\emph{签署pre-key})和当前\emph{居住地址}，即(可能有多个)覆盖目标目标，在这些目标中，角色希望她可以接收pss消息。提要更新块中的签名同时对常驻密钥(参见签名的预密钥)和目标目标进行签名。从该签名中恢复的公钥提供了长期身份公钥，参见图\ref{fig:prekey-bundle-feed-update}。


\begin{figure}[htbp]
   \centering
   \includegraphics[width=.8\textwidth]{fig/x3dh-initial-message.pdf}
   \caption[X3DH初始消息]{X3DH初始信息。启动器检索ENS所有者以及响应器包含常驻密钥和常驻地址的预密钥包提要的最新更新。发起者使用常驻密钥将其身份密钥和临时密钥发送到应答者的常驻地址进行加密。 }
\label{fig:x3dh-initial-message}
\end{figure}


为了将响应器邀请到基于出站提要的私有通信通道，启动器首先查找响应器的公共预密钥包提要，并向响应器发送初始消息(参见图\ref{fig:x3dh-initial-message})，其中指示了通信的意图。然后，她共享启动加密对话所需的参数。这包括其长期身份的公钥，以及为该会话生成的临时密钥对的公钥。这些细节通过发送一个特洛伊pss消息到潜在的应答者的当前居住地址，这也是在他们的pre-key bundle feed中被宣传。 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=.6\textwidth]{fig/x3dh.pdf}
   \caption[X3DH密钥\statusgreen]{X3DH密钥。双方可以计算出三个Diffie-Hellmann密钥，并对其进行异或，得到作为握手后协议种子的X3DH共享密钥。}
   \label{fig:x3dh}
\end{figure}

响应方接收到此信息后，双方都拥有生成三重Diffie-Hellmann共享秘密所需的所有成分，参见图\ref{fig:x3dh}.%
%
\footnote{如果X3DH不使用一次性预键，那么从理论上讲，第三方可以重新发送初始消息，并导致应答者假设真实的重复请求。如果握手后协议添加了来自应答者的随机密钥材料，这样的协议重放攻击就可以消除。
但是最初的木马消息也可以被要求包含一个唯一的标识符，例如用于挖掘块的nonce。重用id是不可能的，因为它会导致相同的块。}
%
该共享秘密构成信号协议中使用的双棘轮连续密钥协议的种子密钥。双棘轮方案为端到端加密提供了前向保密和后折衷安全性。通过为发件箱提要的索引方案应用单独的密钥链，可以实现额外的\gloss{recover security}，即对消息插入攻击的弹性。然而，最重要的是，通过向发件箱地址添加前向和后向保密，通信通道变得模糊，这使得连续的消息拦截依赖于与加密相同的安全假设，因此消除了双棘轮加密的唯一已知攻击面。基于发件箱提要的信道的混淆性和可否认性，加上初始X3DH消息被伪装成难以分辨的块，保证将其指定为零泄漏通信。

\subsection{解决envelopes\statusgreen}\label{sec:addressed-envelopes}

\subsubsection{挖掘单个所有者块地址}

问题马上就出现了，以某种方式挖掘单个所有者的大块是否有意义。由于本例中的地址是一个32字节标识符和一个20字节帐户地址的散列，因此id提供了足够的熵来挖掘地址，即使所有者帐户是固定的。因此，对于一个特定的帐户，如果我们发现一个id，这样产生的单个所有者块地址接近目标覆盖地址，块可以作为一个消息，类似于木马块的方式。然而，重要的是，由于地址可以在块内容与之关联之前被挖掘，因此该构造可以作为\gloss{addressed envelope}。

让我们明确与这个结构相关的角色:

\begin{itemize}
\item \emph{发行人} ($I$)—通过挖掘地址来创建信封。 
\item 将内容放入信封，并将其作为有效的单个所有者块发布到Swarm。
\item \emph{老板} ($O$)—拥有地址的帐户部分的私钥，因此可以在有效负载与标识符的关联上签字。这实际上决定了信封的内容。
\item \emph{目标} ($T$)——挖掘的约束:必须形成挖掘地址前缀的位序列。它表示覆盖地址空间中的一个邻居，信封将被发送到那里。目标序列的长度对应于挖掘的难度。这个目标越长，信封能够到达的范围就越小。
\item \emph{收件人} ($R$)——其覆盖地址以目标序列作为前缀，因此是消息的目的地的一方
\end{itemize}

信封可以被认为是开放的:因为发帖者也是响应单所有者块的所有者，他们能够控制将什么内容放入块中。通过构造这样的包络，发布者有效地允许发布者向目标发送任意消息，而不需要计算挖掘数据块。参见图\ref{fig:addressed-envelope-events}。 


\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{fig/prepaid-addressed-envelopes-events.pdf}
   \caption[贴有邮票，写有地址的信封，事件的时间表]{贴有邮票的信封上写着事件的时间轴。颁发者$I$使用一个标识符为$P$创建加密的信封，这样$P$作为块的单个所有者，产生一个位于接收方$R$邻近的地址。因此(仅)$P$可以用任意内容填充信封，然后使用简单的推同步将其发布到$R$。}
   \label{fig:addressed-envelope-events}
\end{figure}

当发布者希望向接收者发送消息时，他们所需要做的就是创建一个木马消息，并使用发布者在挖掘地址时作为输入的同一个账户的私钥对标识符进行签名。如果他们这样做，数据块将是有效的。参见图\ref{fig:addressed-envelope}。


\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/addressed-envelope.pdf}
   \caption[贴有邮票和地址的信封\statusgreen]{邮寄给$P$和寄给$R$的贴上邮票的有地址的信封由一个标识符组成，当用于创建$P$拥有的单个所有者块时，它会产生一个位于$R$附近的地址。这允许$P$构造消息，根据标识符签名并使用邮票，使用网络的正常推同步功能免费将消息发送到$R$。 }
   \label{fig:addressed-envelope}
\end{figure}

\subsubsection{预付邮资}

这些块的行为方式与普通的木马消息相同，它们的隐私属性是相同的，即使不是更好，因为发布者/接收者可以将加密消息的随机公钥关联起来，甚至使用对称加密。如果预先支付了地址的邮资，然后把邮票交给某人稍后发布，他们可以使用push-sync将部分内容发送给目标用户，而不需要海报支付任何费用，因为\gloss{stamped addressed envelope}已经支付了相关费用。这种构造有效地实现了\emph{已付邮资的回邮信封}，并作为各种高级通信需求的底层解决方案:1)向订阅者推送更新通知，而不给发送者带来任何计算或财务负担;2)免费联系凭证;3)零延迟直接消息响应。  


\subsubsection{发行贴上邮票、写好地址的信封}

发行贴有邮票并写好地址的信封的程序如下:

\begin{enumerate}
\item \emph{假设}发行者$I$，潜在发帖者$P$和潜在接收者$R$，使用公钥$K_I, K_P, K_R$和覆盖地址$A_I, A_P, A_R$。
\item \emph{我的}—$I$找到一个临时的$N_R$，这样当作为一个标识符来创建\gloss{single owner chunk}时，块的地址哈希到位于$A_R$最近邻的$H_R$。
\item \emph{支付邮资}—$I$签署$H_R$以产生一个证人，以支付适当的邮资来产生$PS_R$邮票。
\item \emph{封装}——封装$N_R$和$PS_R$，代表预先地址到收件人地址的预付信封，并用$K_P$加密，然后包装成一个木马块。
\item \emph{我的}——找到一个即时$N_P$，使木马块哈希到$A_P$最近的邻居$H_P$。 
\end{enumerate}




\subsubsection{收到贴好邮票写好地址的信封}

一个潜在的海报$P$被假定收到一个由预付费信封$E$组成的木马消息。为了打开它，她执行了以下步骤:

\begin{enumerate}
    \item 带有属于$K_P$私钥的\emph{解密}消息
    \item \emph{deserialise}拆包识别$PS_R$和$N_R$，从$PS_R$中提取$H_R$
    \item \emph{验证}邮票$PS_R$，并检查$N_R$是否与$K_P$的帐户散列结果为$H_R$，以确保相关地址实际上属于$P$。
    \item \emph{商店} $N_R$和$PS_R$ 
\end{enumerate}

\subsubsection{邮寄贴好邮票、写好地址的信封}

当发帖者想要使用信封向$R$发送任意消息$M$(发送者可能不知道接收方$R$)时，他们必须遵循以下步骤:

\begin{enumerate}
\item \emph{加密}消息内容$M$与$K_R$创建有效负载，并将其包装在木马消息$T$
\item 加密木马消息导致$H_T$
\item \emph{标志} $H_T$使用属于$K_P$的私钥对标识符$N_R$生成签名$W$
\item \emph{封装}将$N_R$作为id，签名$W$和木马消息$T$作为地址为$H_R$的有效单个所有者块的有效载荷
\item \emph{帖子}具有有效戳记$PS_R$的块
\end{enumerate}

\subsubsection{收到贴好地址的信封}

当$R$接收到地址为$H_R$的块时

\begin{enumerate}
\item \emph{验证}邮票$PS_R$，并验证块作为一个单独的所有者块与有效载荷$T$。
\item \emph{解密} $T$，私钥属于$K_R$。
\item \emph{deserialise}将明文作为木马消息，识别消息有效载荷$M$并检查其完整性。
\item \emph{消费} $M$。
\end{enumerate}

\subsection{通知requests\statusgreen}\label{sec:notification-requests} 

\yellow{新}

本节详细介绍了地址信封的概念，并介绍了三种风格，每一种都实现了不同类型的通知。

\subsubsection{出版商直接通知}

如果发布者想要通知接收者关于提要上的下一个活动，她必须构造一个贴有邮票的地址的信封，嵌入到常规的木马消息中，并将其发送给发布者，见图\ref{fig:direct-notification}。如果发布者也是接收方，则请求中使用的帐户和响应信封中使用的帐户可能是同一个。


当提要所有者向其提要发布更新时，对更新块的引用将被放入信封并发送给收件人。更正式地说，发布者从表示预写地址的信封的标识符创建单个所有者块，因此，作为所有者，在与提要更新内容相关联的标识符上签字，作为单个所有者块的有效负载。在此之后，同样的发行商充当海报，向群体推送内容。这个结构称为\gloss{direct notification from publisher}。 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{fig/direct-notification.pdf}
   \caption[直接通知请求和响应\statusgreen]{直接通知请求包含对提要的引用，并包装一个为$P$(提要的发布者或已知发布者)挖掘的预付信封，并将其发送给收件人$R$。响应与一般贴有邮票、写有地址的信封所使用的流程相同，唯一不同的是消息应该是提要更新或对其内容的引用。}
   \label{fig:direct-notification}
\end{figure}

木马消息在其主题中指定它是一个通知，并使用公钥加密。当地址被挖掘到匹配一个足够长的前缀上的接收者覆盖地址时，消息最终被推同步到接收者的邻居。每当接收者上线并通过推同步接收数据块时，它就会检测到这是一条消息。它可以确定为通过解密块这样的内容与关键成功解决他们的广告,或如果收件人发出pre-addressed信封本身,只需查找记录的地址他们保存的时候发布。事件的时间轴见图\ref{fig:direct-notification-events}。


\begin{figure}[htbp]
   \centering
    \includegraphics[width=0.8\textwidth]{fig/direct-notification-events.pdf}
   \caption[直接通知从发布者的事件时间表\statusgreen]{直接通知从发布者的事件时间表。发布者$I$为feed $P/F$的发布者或已知发布者构造一个预付信封，并将地址发给接收者$R$。与提要主题$I$一起，它被封装在pss木马消息中发送到$P/F$。$P/F$接收并存储请求。当他们发布更新时，他们将其包装在信封中，即在feed更新通知消息上签名从$I$接收到的标识符，并将其作为块发布，$R$将接收到该块，从而得到feed更新的通知。 }
   \label{fig:direct-notification-events}
\end{figure}


直接来自发布者的通知使发布者能够将任意内容放入信封。海报同时也是所有者，因此在邮寄信封时，他们可以根据标识符签署任何内容。为了让发布者能够提前创建通知块地址，必须知道潜在发布者的帐户。但是，提要更新地址不需要固定，因此该方案仍然适用于(零星的)基于时点的提要。

\subsubsection{通知从附近}

假设有一个提要，其所有者没有显示其覆盖(目标目标)或拒绝处理通知。提要是使用简单的顺序索引偶尔更新的，因此在查找最新更新时轮询是不可行的，特别是在使用者随时可能离线的情况下。
消费者是否还能获得通知?

我们介绍了另一个结构，\gloss{neighbourhood notification}，它在不需要通知发布者知道潜在招贴者身份的情况下工作。但是，它预先假定内容或至少内容的散列是已知的，以便发布者自己可以对其签名。


发布者希望收到下一次更新的通知。发布者可以创建一个cdeca请求，仅仅是一个包裹消息的木马块。此消息包含一个有地址的信封(标识符、签名和邮票)，发贴者可以使用它来构造作为通知的单个所有者块。注意，通知消息不需要包含任何新信息，对接收者来说，接收消息的事实就足够了。为了指示通知内容，通知有效负载包含提要更新地址。一旦接收到通知，接收者就可以简单地发送一个常规的检索请求来获取包含或指向消息内容的实际提要更新块。邻里通知和通知请求的结构见图\ref{fig:notification-from-neighbourhood}。
                                

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/notification-from-neighbourhood.pdf}
\caption[社区通知\statusgreen]{邻居通知请求不仅包括标识符和邮票，而且还包括通知信息以及与地址相对应的签名。因此，$P$需要构造实际的通知，当发布者$F$将其更新发布到$P$的邻居时，$P$可以将通知发布到接收方$R$。}
\label{fig:notification-from-neighbourhood}
\end{figure}

如果通知只需要包含提要更新地址作为其有效负载，则颁发者可以自行签署将其与标识符关联。这个签名和标识符应该被认为是信封的必要组成部分，并且必须作为通知请求的一部分发送。
与出版商直接使用的\emph{开放}信封不同，邻里通知可以被视为\emph{关闭}信封，其内容事先得到发行人的批准。

现在，发布者而不是发布者成为数据块的所有者，并且当发布者创建和发布通知时，签名已经对其可用。因此，海报不需要公开密钥或帐户地址信息。事实上，海报的身份不需要固定，任何同行都可以作为候选海报。发布者因此可以将通知请求发送到提要更新块的邻近区域。最近的邻居将按照所附邮票的指示保持请求块，直到他们收到指示收到通知的适当feed更新块。请参见图\ref{fig:neighbourhood-notification-events}，了解使用邻居通知时的事件时间轴。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig/neighbourhood-notification-events.pdf}
\caption[事件的邻里通知时间表\statusgreen]{邻里通知事件时间表。发行者$I$挖掘一个以自己为所有者的单一所有者块的标识符，这样块地址就落在接收方$R$的邻近区域。作为所有者的发行者还必须根据预先制作的提醒符签署标识符，并记住应该通知哪个节点。当$P$同步提要更新时，通知被发送到$R$，由通常的推同步传递。}
\label{fig:neighbourhood-notification-events}
\end{figure}
  

但我们如何确保通知不会发送得太早或太晚呢?虽然通知块的完整性由发布者作为其单一所有者来保证，但还必须采取措施，防止管理通知的节点在更新实际到达之前发送它们。最理想的情况是不能在更新到来之前发布通知，否则服务该请求的恶意节点可能会产生错误警报。

一个简单的方法是用一个密钥对请求消息中的消息进行对称加密，这个密钥只有在预期的发布者收到提要更新(例如，提要更新标识符的散列)时才会显示给他们。
为了揭示通知请求需要在到达提要更新时进行匹配，主题必须不加密，因此这里我们不对称地加密pss信封，而只对称地加密消息。

请注意，如果提要是公共的，则可以知道提要更新地址和标识符，因此邻域通知将用于后续标识符不公开的提要。

\subsubsection{有针对性的一部分交付}

通常，在Swarm的DISC模型中，通过检索请求请求块，这些请求被转发到由请求块地址指定的邻居(参见\ref{sec:retrieval})。拥有数据块的路由上的第一个节点将使用它进行响应，数据块将作为反向响应沿着请求所采用的相同路径返回。然而，在某些情况下，有一种机制可以从已知存储块的任意邻域请求块，并将其发送到已知需要块的任意邻域，这可能是有用的。一个称为\gloss{targeted chunk delivery}的构造就是这样一个用例:请求是一个特洛伊pss消息，而响应，即传递，必须是包装所请求的块的单个所有者块，并挖掘一个地址以落入接收者的邻近区域。  


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/targeted-chunk-delivery.pdf}      
\caption[目标块交付\statusgreen]{有针对性的区块投递与邻里通知类似，它们不仅是预先处理和预付的，而且是预先签名的。类似地，对标识符进行挖掘，使给定的颁发者$I$作为所有者，它产生一个块地址，该地址位于接收方$R$的邻近区域。在这里，发布者根据他们希望看到发布到$R$的内容块的散列签名标识符。如果目标块交付请求落在有问题块的任何节点上，它们可以使用信封和块的内容来产生有效的响应，该响应是一个单独的所有者块包装一个内容寻址块。}
\label{fig:targeted-chunk-delivery}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.8\textwidth]{fig/targeted-chunk-delivery-events.pdf}
\caption[事件的目标块交付时间\statusgreen]{事件的目标块交付时间线。上传器$U$上传一个块到Swarm，它与存储节点$S$着陆。$P$中的节点复制(并钉住)这个块。现在，如果发布者$I$想要将该区块交付给$R$，它会将寄往$R$的预付信封不加密地发送给已知主机的邻近区域，以便拥有该区块的任何人都可以构造通知并发送或存储它以备以后使用。}
\label{fig:targeted-chunk-delivery-events}
\end{figure}



这些“chunk-in- soc”响应在结构上与邻居通知相似，因为有效负载的散列已经知道(请求的chunk的内容地址)。请求者可以在其与标识符的关联上签名，标识符连同签名一起作为请求的一部分发送，参见图\ref{fig:targeted-chunk-delivery-events}。获得请求的节点只需要存储所请求的块，它们可以将响应构造为一个有效的单个所有者块，该块地址指向接收者的邻居。
这使得请求具有普遍性，即不固定于潜在招贴者的身份。因此，它可以发送到任何需要内容的社区。甚至可以同时发送多个请求:由于有效响应的唯一性，多个响应不会损害块的完整性(参见\ref{sec:single-owner-chunks}和\ref{sec:feed-integrity})。目标交付用于缺失块恢复，请参阅\ref{sec:recovery-chunks}。

不同之处在于，邻里通知不提供任何新信息，而有针对性的块发送则提供块数据。同样，在单个所有者块中包装的块交付不使用消息包装，也没有主题。请求和响应都不使用加密。
不使用加密的结果是，如果有替代源，挖掘初始的木马请求有一个限制，即地址匹配任何目标。

表\ref{tab:notifications}总结了三个类通知结构的各种属性。

\begin{table}[htpb]
    \centering
    \begin{tabular}{c c c c c | | | | |}
    类型&所有者&海报&请求加密&通知\\\hline
直接&海报&出版商&不对称的PSS & feed更新内容\\
邻居&发行人&任何&对称的信封和feed更新到达\\
目标交付&发行人&任何&无&大块内容\\
    \end{tabular}
    \caption[提要更新通知]{对feed更新通知和目标块交付的请求和响应。}
    \label{tab:notifications}
\end{table}

\chapter{持久性\statusgreen}\label{sec:persistence}


在本章中，我们关注的是数据持久性，即确保内容在Swarm上保持可用性的方法。
我们引入了错误编码方案，它可以以存储开销为代价，提供一种确保可用性的方法。
特别是\glossplural{erasure code} (\ref{sec:repair})和\glossplural{entanglement code} %(\ref{sec:缠结})
为具有不同访问模式的文档提供优化的冗余。
% First we discuss how popular content stays alive due to opportunistic caching (\ref{sec:caching}).  
在\ref{sec:reupload}中引入了本地固定的概念，即在你的Swarm本地存储中将内容标记为粘性的能力之后，我们将介绍一些有助于实现整个网络的全局持久性的方法。我们定义了一个\gloss{missing chunk notification protocol}，它允许内容维护者在一些块被垃圾收集的事件中确保他们发布的内容被恢复，通过通过选择\glossplural{pinner}的内容进行代理检索。

最后，在\ref{sec:insurance}中，我们提出了圣杯，即去中心化文件保险:结合邮费彩票和丢失块通知的概念，Swarm提供了一种协议，允许用户支付其他节点以保持他们的内容可用。虽然普通的存储节点通过邮资抽奖来存储块，但为了获得更高的溢价，相关节点将承诺承担存储和响应块请求的责任，接受在被保险数据无法在网络上保持可用的情况下对他们施加惩罚措施的风险。


\section{冗余、延迟和修复\statusgreen}\label{sec:repair}

\green{}

\subsection{错误校正码}\label{sec:error-correcting-codes}

纠错码是一种常用的纠错码，用于在存储系统出现故障时，保证数据不丢失。特别是，它们允许我们构建比简单复制更有效地解决这个问题的存储方案(数据编码和分布)。该问题的框架是在保证给定一个表示存储子系统中预期故障条件的模型的数据可检索的一定概率的背景下构建的。

编码理论通常应用于\glossplural{RAID}和计算机硬件架构同步磁盘阵列，以提供弹性数据中心存储。
\glossupperplural{erasure code}尤其将问题视为:如何将存储的数据编码到分布在$n$磁盘上的分片中，以便在某个磁盘出现故障的特定概率下，整个数据仍然可以完全检索。
同样,在一个分布式块存储的环境中,这个问题可以作为一个问题:新配方如何编码存储数据块分布在网络中的节点,这样整体的数据仍可收回的一个特定的概率找到一大块missing. %
%
\footnote{分布式块存储模型使用固定大小的块，这些块只能完全丢失或完全无损。由于Swarm内容存储使用块的哈希作为它们的地址，由于块是由随机分布在同一地址空间的托管节点存储的，我们可以安全地假设一个特定的存储分配是独立于所有其他节点和数据的。这确保了在任何点恢复一个块实际上都可以被认为是具有相同和独立概率的潜在失败。}

有各种各样的参数可以优化，主要是:存储和带宽开销。从理论上讲，擦除码是最优的存储开销最小化，但需要检索大量的数据进行本地修复。
另一方面，纠缠代码在本地修复时需要最小的带宽开销，但存储开销是100\%的倍数。 

\subsection{通过擦除码实现冗余\statusgreen}\label{sec:erasure}


\gloss{Cauchy-Reed-Solomon erasure code}(今后\gloss{CRS} \cite{lubyetal1995CRS} \cite{plank2006optimizing})是一个\emph{系统性} \gloss{erasure code},当应用到一个blob $m$固定大小的数据块,产生额外$k$相同大小的块(所以称为\emph{奇偶校验块})这样的$m$ $n=m+k$ fix-sized块足以重建原来的团。因此存储开销是由decfa .%给出的
%
\footnote{%
有几个开源库实现了Reed-Solomon或Cauchy-Reed-Solomon编码。详细的比较请参阅\cite{plank2009performance}。}

CRS码的编码和解码都需要$O(mk)$时间，其中$m$是数据块的数量，$k$是附加块的数量，以及在不损失可解码性的情况下可以丢失的最大块数量。如果将$k$定义为$m$的给定分数，在一个固定的单个块丢失概率$p$的条件下，保证一定的可检索概率所必需的$m$，那么CRS代码的时间复杂度就变成了$O(n^2)$，这对于大文件来说是不可接受的。 

\subsection{群块树中的每级擦除编码\statusgreen}

Swarm使用分层Merkle树\cite{merkle1980protocols}将数据重新组织成固定大小的块，然后发送给Swarm节点进行存储。
让$h$是使用的散列的字节长度，让$b$是分支因子。每个顶点表示子树的根散列，或者在最后一层表示文档的$b\cdot h$长跨度(一个块)的散列。一般来说，我们可以认为每个块都由$b$散列组成。


\begin{figure}[htbp]
   \centering
   \input{fig/chunk.tex}
   \caption[群块\statusgreen]{一个Swarm块由4096个字节的文件或128个子树哈希序列组成。}
   \label{fig:chunk}
\end{figure}


\begin{figure}[htbp]
   \centering
   \input{fig/Swarm-hash-basic.tex}
   \caption[树中的一个通用节点有128个子\statusgreen]{树中的一个通用节点有128个子节点。}
   \label{fig:Swarm-hash-basic}
\end{figure}

在正常的Swarm查找期间，Swarm客户端执行一个哈希值查找并接收一个chunk作为返回。这个块又构成另一个$b$哈希，用于查找和检索另一个$b$块，以此循环，直到接收到的块属于实际的文档(参见图\ref{fig:Swarm-hash-split})。


\begin{figure}[htbp]
   \centering
   \input{fig/Swarm-hash-split.tex}
   \caption[群集哈希分裂\statusgreen]{蜂群树是一种数据结构，编码文档如何分割成块。}
   \label{fig:Swarm-hash-split}
\end{figure}

虽然现成的擦除编码可以用于上传至Swarm的文档，但这种解决方案存在直接的问题。除了编码的二次复杂度外，\gloss{chunking} crs编码的数据团与BMT块将导致某些块更容易受到攻击，因为它们的检索依赖于对块树中编码它们所有祖先节点的块的检索。

这促使我们尝试将群块的概念与CRS方案中使用的块对齐，这导致我们将冗余直接编码到群树中。这是通过将\emph{CRS方案}应用到Swarm树中节点的每一组子块来实现的。

采用CRS编码的\emph{块}算法在拆分文档时的工作方式如下:

\begin{enumerate}
\item 将输入设置为数据团。
\item 每次读取输入一个块(比如固定的4096字节)。通过增加计数器$i$来计数块。 
\item 重复步骤2直到没有更多的数据(注意:最后读取的块可能更短)或$i \equiv 0$ mod $m$。
\item 在最后一个$i \mod m$块上使用CRS方案来产生$k$奇偶校验块，从而产生总的$n \leq m+k$块。
\item 计算所有这些块的哈希值并将它们连接到下一个块(大小为下一层的$i\mod m$)。将此块记录为下一个。
\item 如果有更多的数据重复2。 
\item 如果没有更多的数据，但下一层的数据blob有一个以上的块，将输入设置为这个，并从2开始重复。
\item 否则，将blob记录为根块。
\end{enumerate}

% Fixing the branching factor of the Swarm hash as $n=128$ and $h=32$ as the size of the \emph{SHA3 Keccak hash} gives us a chunk size of $4096$ bytes.

% We start splitting the input data into chunks, and after each $m$ chunks add $k=n-m$ parity check chunks using a Reed-Solomon code so that now any $m\text{-out-of-}n$ chunks are
% sufficient to reconstruct the document. On the next level up the chunks are composed of the hashes of the $m$  data chunks and the $k$ hashes of the parity chunks. Let's take the first $m$
% of these and add an additional $k$ parity chunks to those such that any $m$ of the resulting $n$
% chunks are sufficient to reconstruct the origial $m$ chunks. And so on and on every level. In terms of
% availability, every subtree is equally important to every other subtree at this level. The resulting
% data structure is not a balanced tree since on every level $i$ the last $k$ chunks are parity leaf
% chunks while the first $m$ are branching nodes encoding a subtree of depth $i-1$ redundantly.
A typical piece of our tree would look like this (see figure \ref{fig:Swarm-hash-erasure}).


\begin{figure}[htbp]
   \centering
   \resizebox{1\textwidth}{!}{
        \input{fig/Swarm-hash-erasure.tex}
   }
   \caption[群哈希擦除\statusgreen]{基于128个CRS编码的具有额外奇偶校验块的群树。通过$p_{15}$的块$p_{0}$是每一级中间块上通过$H_{111}$的块$H_0 $的校验数据。}
   \label{fig:Swarm-hash-erasure}
\end{figure}


这种模式在整个树中重复。因此，通过$H_{127}$哈希$H_{m+1}$指向$H_0$通过$H_{m}$指向的块的校验数据。$P_i$的奇偶块没有子块，因此树状结构没有统一的深度。

\subsubsection{不完整的批次}

如果文件块的数量不能被$m$整除，我们就不能像处理其他批处理一样处理最后一批文件。我们建议用erasure代码对剩余的块进行编码，以保证至少与其他块相同的安全级别。注意，这并不像选择相同的冗余那么简单。例如，$50\text{-out-of-}100$编码比$1\text{-out-of-}2$编码更安全，即使在两种情况下冗余都是$100\%$。过度补偿，我们仍然需要相同数量的奇偶校验块，即使有少于$m$数据块。

这就只剩下一种情况:不可能在单个块($m=1$)上使用我们的$m\text{-out-of-}n$方案，因为它相当于相同块的$k+1$副本。问题是相同块的任意数量的副本都具有相同的散列，因此会自动重复数据删除。只要剩下一个块($m=1$)(这是总是如此的根块本身),我们复制数据块的有效负载更多的单一所有者与一个地址块,确定性可推论的内容所有者的公钥和原始的根散列,因此，我们可以为存储任意长度的数据提供任意级别的冗余。

\subsubsection{检索延迟的上限}

当下载带有擦除编码的文件时，包含在中间块下的数据可以从$m+k$的子块中恢复出任何$m$。下载器可以发起对所有$m+k$的请求，只需要等待第一个$m$的交付，以便继续进行。
这种技术可以有效地屏蔽由于网络争用、连接缺口和节点流失等偶然故障而导致的块不可用;价格过高的社区，甚至针对某些地区的恶意攻击。给定一个特定的故障模型的流失和吞吐量，擦除码可以被校准
\emph{保证检索延迟的上限}，一个强有力的服务质量主张。





\section{钉住、重新加载和丢失块通知\statusyellow}\label{sec:reupload}

本节介绍固定的概念，即保护本地粘性内容不受其存储节点(\ref{sec:pinning})的垃圾收集例程的影响。在\ref{sec:global-pinning}中，我们讨论了如何在全球范围内为整个网络锁定内容。\ref{sec:repair}定义了一个恢复协议，下载程序可以使用该协议来通知存储程序缺少属于它们负责全局固定的内容的块。有了这种随需应变的修复和不间断的下载体验，恢复实现了一个穷人的持久性措施，可以确保网络范围内的特定块的可用性，而不需要支付保险的财务支出。

\subsection{当地把\statusgreen}\label{sec:pinning}

本地\gloss{pinning}是使内容具有粘性并防止其被垃圾收集的机制。它只将内容固定在节点的本地存储中，以支持数据的本地持久性和快速检索。固定应用于客户端本地数据库中的块级别，并为用户公开了一个API，以便在其本地节点中固定和解固定文件和集合(参见\ref{sec:features}和\ref{spec:api:pinning})。

为了固定所有包含文件的块，客户端需要为每个块保留一个\gloss{reference count}，该\gloss{reference count}在块被固定和解除固定时分别递增和递减。只要引用计数非零，块就被认为是至少一个固定文档的一部分，因此不受垃圾收集的影响。一旦一个块被固定，只有当它的引用计数返回到零时，在它每次被固定后分别被解除固定后，这块块才再次被考虑进行垃圾收集。

本地固定可以被认为是一种功能，它允许Swarm用户将特定的文件和集合标记为重要的，因此不能删除。将文件固定在本地存储中也可以使本地节点在没有互联网连接的情况下始终可以访问该文件。因此，使用固定内容存储本地应用程序数据可以实现脱机优先应用程序范式，Swarm在重新连接时自动处理网络活动。但是，由于如果块不在节点的责任区域内，局部钉扎本身不足以保证块一般可被其他节点检索，由于pinner不在kdemlia附近，该区块是存储的，因此，当使用pull-sync协议请求该区块时，将在这里搜索它。为了提供这个功能，我们必须实现pin协议的后半部分。

\subsection{全球将}\label{sec:global-pinning}

如果一个块由于其指定邻近的存储器的垃圾收集而被删除，则在网络其他地方的本地固定节点将无法单独检索它。为了帮助全球网络的持久性，必须解决两个问题:

\begin{itemize}
    \item  通知全局锁定者他们锁定的内容的缺失部分——这样他们就可以重新上传，
    \item  维护被垃圾收集但全局固定的块的可检索性——这样下载者就不会遇到中断。 
\end{itemize}

实现此目标的一种简单方法是定期检查网络中的固定块，如果没有找到，则重新上传内容。这涉及大量多余的检索尝试，具有巨大的带宽开销，并最终不能减少延迟。

另一种可选的反应方式是向piner组织通知，当用户访问piner的内容并发现某个块不可用时，会以某种方式触发通知。理想情况下，下载器通过一条消息通知piner，该消息触发(1)重新上传丢失的块，以及(2)响应下载器的请求而交付块。  

\subsubsection{退到网关}

让我们假设一组piner节点具有本地固定的内容，我们的任务是允许回退到这些节点。在最简单的场景中，我们可以将节点设置为网关(可能对一组多个pininner节点进行负载平衡):如果该网关包含在文件或集合的清单条目中，用户就会了解该网关。如果用户无法从Swarm下载文件或集合，因为丢失了块，他们可以简单地求助于网关，在本地找到所有块。
此解决方案受益于简单性，因此很可能是要实现的第一个全局持久性里程碑。  

\subsubsection{采矿块到piners的邻居}

第二种，蛮力解决方案更复杂，因为发布者可以以一种方式构建文件的块，使它们都位于piner(或集合中的任何piner节点)附近。为了做到这一点,出版商需要找到每个块的加密密钥加密的文件块的地址匹配的平纳至少第一$d$比特,$d$在哪里选择舒适比平纳可能邻居depth. %
%
\footnote{注意，如果piner节点不共享基础设施，并且挖掘的块需要通过推同步协议发送到piner，那么使用的每个邮包批将在大多数$n$时间使用。虽然这种不一致意味着更高的单价，但如果别针是出于利他主义(即不是为了补偿)，只需要支付最低邮费。
}

这些解决方案已经能够实现持久性，但是它们重新引入了一定程度的集中化，并且还要求发布者维护和控制服务器基础设施。当然，它们也会受到服务器-客户端架构的常见缺点的影响，即容错性降低，以及由于请求更加集中而导致性能下降的可能性。这些解决方案也没有解决如何为pininner节点提供内容的问题，也没有考虑任何隐私问题。由于这些原因，尽管底层的pin API是为群用户提供的，但它的使用被认为是奖励文件保险黄金标准的不理想替代方案。因此，应该仔细考虑用例，以确保它们不会从激励系统提供的增强的隐私和弹性中受益。



\subsection{复苏\statusyellow}\label{sec:recovery-chunks}


在接下来的内容中，我们描述了一个简单的协议来通知pinners丢失的块，他们可以通过(1)将丢失的块重新上传到网络，同时(2)通过向通知者发送丢失的块来响应通知者。\ref{spec:format:recovery}中详细规定了与缺失块通知协议相关的过程，并在\ref{spec:format:recovery}中形式化了相关的数据结构。

如果块的副本分布在愿意的主机(pinners)中，那么没有找到块的下载者可以返回到\gloss{recovery}进程，使用名为\gloss{prod}的\gloss{missing chunk notification protocol}从这些主机中请求它。
通常，这个缩略词的解析捕获协议的属性:

\begin{itemize}
\item \emph{删除后恢复协议} -请求者和piner之间的协议，在垃圾收集后协调块恢复。如果下载程序检索块失败，则会触发该进程。
\item 恢复主机持续侦听来自下载程序的潜在恢复请求。
\item \emph{提供DISC维修} -
在数据丢失的情况下，Prod提供修复群集磁盘的服务。
\item \emph{Pin和重新上传数据} -
主机将数据钉住，并在提示恢复请求时将其重新上传到指定区域。 
\item \emph{按需迅速响应}—如果请求者要求一个提示的直接响应，主机将使用恢复响应信封和附带的邮票发送丢失的块。
\end{itemize}

\subsubsection{恢复主机}

\glossupperplural{recovery host}是愿意在恢复上下文中提供固定块的固定块。这些pinners应该表示他们将把这个任务交给发行商，并下载了所有相关的块，并将它们全部固定在本地实例中。 

希望将其出版物发布为全局固定或可修复的发布者将收集这些自愿恢复主机的覆盖地址。事实上，只收集长度大于Swarm深度的覆盖层前缀就足够了。我们将这些部分地址称为\gloss{recovery targets}。

发布者将通过名为\gloss{recovery feed}的提要向其数据的消费者发布其内容的恢复目标。发布者数据的使用者可以根据使用简单顺序索引方案构造主题的约定跟踪该提要(请参阅\ref{spec:format:recovery})。 

\begin{figure}[htbp]
\centering
\includegraphics[width=.8\textwidth]{fig/missing-chunk-notification.pdf} \caption[缺少块通知进程\statusgreen]{丢失的块通知过程类似于目标块交付。这里下载器挖掘标识符来匹配他们自己的地址，也就是一个自我通知。如果下载器$D$遇到丢失的块(请求超时)，它们将向有机会找到该块的几个邻居之一发送恢复请求。然后，一个成功的响应将包含一个单独的所有者块，包装发送给下载器的丢失块。数据块也被重新上传到网络中适当的位置。}
\label{fig:missing-chunk-notification}
\end{figure}

\subsubsection{恢复请求}

一旦恢复主机覆盖目标被揭示给下载节点，当遇到丢失的块时，它们应该通过发送一个名为\gloss{recovery request}的通知来“刺激”其中一个恢复主机。此目标块交付实例(参见\ref{sec:notification-requests})是一个公共的未加密木马消息，至少包含丢失的块地址，参见图\ref{fig:recovery-request}。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/recovery-request.pdf}
  \caption[恢复请求\statusgreen]{恢复请求是一个木马块，它被用作丢失块通知。它是未加密的，它的有效载荷结构为一个pss消息，其中包含要恢复的块的地址。它还可选地包括一个特殊的恢复响应信封，一个带有签名的标识符，证明标识符与丢失的块散列之间的关联。}
  \label{fig:recovery-request}
\end{figure}

为了创建一个恢复请求，下载器需要(1)创建消息的有效负载(2)找到一个nonce，当它被附加到有效负载时，结果是一个与发布者指定的\gloss{recovery targets}相匹配的内容地址。匹配目标是指通过推同步chunk，将其发送到由目标前缀表示的恢复主机的邻域。

如果目标恢复主机在线，它们将接收恢复请求，提取丢失的块地址，检索固定在其本地存储中的相应块，并使用新邮票将其重新上载到网络。

\subsubsection{恢复响应信封}

\gloss{recovery response envelope}的作用是为恢复主机提供一种方法，使其能够直接响应恢复请求的发起者，迅速且没有相关的成本或计算负担。它是目标块交付响应的一个实例(请参阅\ref{sec:notification-requests})，一个有地址的信封构造，它与海报无关，但对内容是固定的。请求消息包括潜在的发贴者需要创建有效的目标块传递响应的组件:一个标识符，该标识符具有签名，证明标识符与丢失的块散列之间的关联。选择标识符，以便单个所有者块的地址(id与所有者帐户的散列)落入请求者的邻居，因此它由网络的执行推同步协议自动传送到那里。

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig/recovery-response-2.pdf}
\caption[恢复响应\statusgreen]{恢复响应是包装丢失的块的单个所有者块。任何拥有头和块数据的人都可以构建一个有效的单个所有者块，并将其免费发送给下载器。}
\label{fig:recovery-response}
\end{figure}

如果目标恢复主机在线，它们将接收恢复请求，并从恢复响应中提取丢失的块地址以及标识符和签名。在检索他们固定在本地存储中的相应块之后，他们可以简单地创建恢复响应。标识符的哈希和有效负载哈希连接在一起形成签名的纯文本。恢复请求中接收到的签名允许她恢复请求者的公钥。从这个公钥中，他们可以计算请求者的地址，最后，将其与标识符散列得到单个所有者块的地址。如果还将邮票附加到可以与恢复响应一起发送的请求上，则该方案更有意义，因为请求者能够支付返回补偿全局绑定的块的Swap成本。通过这种方式，下载者可以智能地支付使用小额支付的节点的运营成本，从而确保整个网络的数据可用性。



\section{保险\statusorange}\label{sec:insurance}
 
\wip{still working on this}

\subsection{保险池\statusorange}
我们在\ref{sec:chunk-insurance}中看到，邮资抽奖的奖励机制也可以用来促进和加强对丢失数据的保险:其中所涉节点负责使用区块链存储与金融资产相关的特定块。

最后，我们将讨论1)如何为数据块投保2)数据块如何通过网络传递给保险公司3)之后，任何第三方如何能够审计数据块的收据，如果发现数据块丢失，则启动诉讼程序。

让我们想象一个保险池，一个注册方出资的智能合约。这个池代表的节点，为了换取更高的存储溢价，如果它们失去一块，就会失去它们的股份。 

\subsection{购买大量的保险}

\subsection{上传与保险\statusred}


\subsection{访问收据\statusred}

承保文件的清单条目包含对数据结构的引用，该数据结构将保险商地址映射到承保文件时保险商的公钥。一旦这些支点被知道，任何第三方都可以计算出哪个保险公司对每个部分负责。一旦知道了保险公司，就可以查找它们的收据存储，通过简单地查找保险公司的收据存储feed.%，就可以很容易地找到当前收据存储根
%
\footnote{事实上，没有必要有最最新的根，任何晚于保险开始时间的状态都可以工作。}
%
然后，可以使用原始块地址作为密钥遍历收据存储来检索块的实际收据。保险公司含蓄地负责对其收据存储的所有块以及收据存储feed进行保险。因此，如果在查找过程中发现任何块丢失了，可以使用与丢失块地址对应的段的默克尔证明进行诉讼。 
否则，我们可以假设查找是成功的，用户获得了收据，因此可以通过提交收据发起诉讼。 


\begin{figure}[htbp]
  \centering
  \caption[从检索到诉讼]{从检索到诉讼}
  \label{fig:flowchart-retrieval-litigation}
\end{figure}


Figure \ref{fig:flowchart-retrieval-litigation}给出了事件的完整时间轴，从第三方用户检索文件一直到文件原始保险人被惩罚。





\chapter{用户体验}\label{sec:ux}

本章从用户的角度介绍了前几章中介绍的Swarm特性。在\ref{sec:upload}中，我们讨论了与配置上传相关的用户体验，包括邮费、钉住、擦除编码等方面，以及在上传标记的帮助下跟踪块传播到网络的进程。然后我们转向用户对存储API的体验，在\ref{sec:storage-ux}中上传集合，然后转向在\ref{sec:messaging}中通信可用选项的描述。最后，在facace中给出了一个完整的web3 dapp开发框架。

\section{配置和跟踪上传\statusgreen}\label{sec:upload}

\green{}

上传是Swarm最重要的界面。Section \ref{sec:headers}提供了用于配置上传api的请求头(或者查询参数)。在\ref{sec:tags}中，我们引入了上传标签，该标签可用于跟踪整个上传的状态，并使用进度条和过程完成前的预期时间估计来显示。标签还会记录部分根哈希值，以便在上传完成前被中断的情况下继续上传。在\ref{sec:postage-ux}中，我们概述了与上传和散布到网络中的支付有关的场景，特别是用户如何购买并将戳记附加到块上。最后，\ref{sec:features}通过可选参数运行，如加密、\gloss{pinning}和\glossplural{erasure code}。

\subsection{上传选项\statusgreen}\label{sec:headers}

本地http代理提供了\lstinline{bzz} URL方案作为存储API。该API将在\ref{sec:storage-ux}中进一步讨论，并在\ref{spec:api:storage}中正式指定。请求可以指定Swarm特定的选项，如:

\begin{itemize}
\item \lstinline{tag}——使用这个上传标签——生成并在未给出的响应头中返回。 
\item \lstinline{stamp}—使用此邮资订阅上传—如果没有给出，则使用最近使用的。 
\item \lstinline{encryption}——加密内容如果设置，如果设置为一个64字节十六进制值编码一个256位整数，然后使用一个随机生成的密钥。 
\item \lstinline{pin} - pin的所有块上传，如果设置。 
\item \lstinline{parities}——使用每个子批处理的奇偶数对所有中间块应用CRS擦除编码。
\end{itemize}

这些选项可以用作URL查询参数或指定为标题。报头的名称是通过将参数名称大写并在其前面加上\lstinline{SWARM-}(即\lstinline{SWARM-PARITIES})来获得的。  


\subsection{上传标签和进度条\statusgreen}\label{sec:tags}
当上传一个文件或集合时，对于用户来说，知道上传什么时候完成是很有用的，因为所有新创建的块都被同步到网络并到达可以检索它们的邻居。此时，上传者可以“消失”，也就是可以退出他们的客户端。发布者可以传播根哈希，并确保文件或集合可以从Swarm上的每个节点检索。

由于推送同步协议提供了单个区块的托管收据声明我们只需要收集并统计一次上传。跟踪发送的数据块和返回的收据的比例将数据提供给\emph{进度条}。\gloss{upload tag}是一个表示上传并通过计算有多少块达到特定状态来跟踪进度的对象。美国是: 

\begin{itemize}
\item \emph{分裂}——分割的块数;数块实例。
\item \emph{存储}——本地存储的块数量;数块实例。
\item \emph{见过}——先前存储的块的计数(重复)。
\item \emph{发送}——使用推同步发送的不同块的数量。
\item \emph{同步}——托管声明到达的不同块的数量。
\end{itemize}

在这些计数的帮助下，人们可以监控分块存储、推同步和收据的进程。
如果上传标记没有在头文件中指定，则会随机生成一个，并在文件完全分块后作为响应头返回。为了在上传过程中监视1)和2)，需要在上传之前创建标记并在请求头中提供。因此，在处理上传的内容时，可以同时查询标记。 

\subsubsection{已知文件大小vs未知文件大小}

如果文件大小已知，则可以计算块的总数量，这样块划分和存储的进度就可以从一开始就按总数量的比例有意义。

如果在上传之前不知道分割的块的大小和总数，则分割的进度是未定义的。在分块完成拆分后，可以将总计数设置为拆分计数，从那时起，剩余计数的进度百分比和ETA可用。

注意，如果上传还包含一个清单，那么总数将仅作为一个估计，直到总数被设置为分割计数。随着文件大小的增长，这个估计收敛到正确的值。


\subsubsection{重复的块}

\glossupperplural{duplicate chunk}是在一次上传或跨上传中出现多次的块。为了有一个本地可验证的定义，当且仅当块已经在本地存储中找到时，我们将其定义为副本(或可见)。
当块通过上传进入本地存储时，它们被推送同步，因此看到的块不需要再次推送同步。

换句话说，在评估同步上传的估计时间时，只需要计算新存储的块。如果我们想要在发送和同步计数上取得进展，它们必须按照存储的不同块的比例报告完整性。

\subsubsection{标签API} 

http服务器的\lstinline{bzz} URL方案为标记API提供了\lstinline{tags}端点。它支持创建、列出和查看单个标记。最重要的是，有一个选项可以使用http流实时跟踪标记的变化。标签API在\ref{spec:api:tags}中指定。



\subsection{邮资\statusgreen}\label{sec:postage-ux}

为了对上传施加成本并有效地分配网络中的存储资源，所有的上传都必须付费。这对于网络来说有些不寻常，所以需要开发一种新颖的用户体验。最接近和最熟悉的比喻是订阅。

\subsubsection{邮资订阅}

用户为一定数量的时间和存储创建一个订阅(例如100兆字节1个月)，并根据他们从客户端软件了解到的价格支付(这与区块链的交易费用是如何确定的类似)。价格的估计可以从邮资彩票合同中读到。订阅被命名，但这些名称仅在本地有意义。API将在对数尺度上为所选择的存储周期提供一些默认选项，例如: 

\begin{itemize}
\item \emph{最少(几个小时)}——用于即时传递pss消息或单个所有者块，临时性聊天或其他临时文件的一部分。
\item \emph{临时的(周)}——文件或邮箱消息意味着不存储很长时间，而是由第三方异步提取。
\item \emph{长期(一年)}——默认的长期存储。 
\item \emph{永远(10年)}—不可丢失/遗忘的重要内容;即使上传者完全离线，也要在网络增长和后续批深度增加的情况下生存下来。
\end{itemize}

当用户上传文件时，他们还可以指示要使用哪个订阅作为\lstinline{stamp}上传参数的值。如果没有给出，则使用最近的作为默认值。如果上传的大小是已知的，如果它大于邮资容量，用户可以被警告。 

\subsubsection{邮资重用策略}

正如在\ref{sec:postage-stamps}中提到的，加密可以用于挖掘数据块，以确保它们落入邮资批次的\glossplural{collision slot}。这种批量挖掘块的策略对于只希望在特定时间段内上传特定文件/集合的用户来说是有意义的，或者希望保留更改文件/集合的存储周期的选项，而不受其他上传的影响。

另一种选择是预付大量的邮资批次，并始终保持一个固定的数量在每个时期开放。这样，我们可以确保我们有一个免费的\gloss{collision slot}在任何块的批次。邮资批次是按购买时间订购的，当将邮票附在一块时，第一批使用有一个空闲槽的块地址的问题。包括保险公司在内的大用户最有效地利用了这种更有利可图的策略，因为它们能够负担得起长期冻结流动性的费用。在创建订阅时必须指定策略的选择。

\subsubsection{邮费订阅API}

为了管理订阅，\lstinline{bzz} url模式为邮费API提供了\lstinline{stamp}端点(请参阅\ref{spec:api:postage})。通过这个API，用户可以创建邮费订阅、列出订阅、查看订阅、添加订阅、删除订阅和过期订阅。

当检查他们的订阅时，用户被告知有多少数据已经上传到该订阅，以及给定当前价格可以存储多长时间(例如$88/100$兆字节为$23$天)。如果估计的存储周期较低，使用订阅的文件有被垃圾收集的危险，因此，为防止这种情况，充值订阅具有指导意义。


\subsection{额外的上传功能\statusgreen}\label{sec:features}

其他功能，如交换成本，加密，钉住和擦除编码可以设置在上传使用请求头。 


\subsubsection{掉期成本}

上传会产生来自\gloss{SWAP}会计(\ref{sec:accounting})中显示的推同步协议的交换成本。在每一个对等连接上，如果余额超出了有效支付阈值，就会发出支票并发送给对等连接。但是，如果支票簿合同不存在或缺乏足够的资金来支付未偿债务，则对等连接将被阻塞。这可能会导致不饱和的卡德米利亚，在此期间，该节点将被算作一个光节点。下载可以继续使用少量的对等点，但是，由于一些块需要发送到比节点本身更靠近请求地址的对等点，因此检索块的平均成本将会更高。

向用户显示这个平均数字、平均交换余额和由于资金不足而不可用的对等连接数是很有用的。这是通过\ref{spec:api:swap}中指定的SWAP API完成的。

\subsubsection{加密}

通过将上传选项\lstinline{encryption}设置为非零值，可以使用加密上传。如果该值是一个32字节种子的十六进制表示，则将其用作加密的种子。由于加密和解密是由Swarm自己处理的，它只能在http客户端和Swarm代理服务器之间的传输可以保证是私有的情况下使用。因此，这不能在公共网关上使用，而只能通过本地Swarm节点或使用配置良好的TLS和自签名证书的私有节点使用。

\subsubsection{锁住}

当上传时，用户可以通过将\lstinline{pin}上传选项设置为非零值，直接指定是否希望将内容固定在本地。除此之外，本地http服务器的\lstinline{bzz} URL方案为固定API提供了bbbb端点(参见\ref{spec:api:pinning})。通过这个API，用户可以管理固定的内容。固定端点上的\lstinline{GET}请求给出固定文件或连接的列表。该API还接受散列(或解析为散列的域名)上的\lstinline{PUT}和\lstinline{DELETE}请求，分别对内容进行pin和unpin。

当固定一个文件或集合时，它应该被检索和存储。固定触发遍历哈希树，并增加每个块上的引用计数;如果在本地发现一个块丢失了，就会对它进行检索。在固定之后，根散列被保存在本地。解绑定触发器遍历哈希，并减少每个块的引用计数;如果在本地发现一个块丢失了，它将被忽略，并在响应中包含一个警告。解绑定后，该散列将从固定散列列表中删除。 



\subsubsection{擦除编码}

通过将\lstinline{parities}上传选项设置为每个中间块的子块之间的奇偶校验块的数量，可以在上传时触发擦除编码(参见\ref{sec:repair})。重要的是，擦除编码文件不能使用默认的Swarm下载器检索，因此擦除编码设置应该在封装清单条目中通过设置\lstinline{crs}属性为奇偶块的数量(参见\ref{spec:format:manifests})来指示。 

\section{存储\statusgreen}\label{sec:storage-ux}

\green{}


在本节中，我们将介绍Swarm的本地HTTP代理通过\lstinline{bzz}系列URL方案提供的存储API。

\subsection{上传文件\statusgreen}\label{sec:file-api}

\lstinline{bzz}模式允许通过\lstinline{file} API直接上传文件。该文件将以请求主体或多部分形式进行编码。在\ref{sec:headers}中引入的所有查询参数(或相应的头)都可以用于该方案。\lstinline{POST}请求块并上传文件。创建一个清单条目，其中包含对上传内容的引用，以及一些反映上传配置的属性，例如\lstinline{crs}指定每批擦除代码的对等数。
清单条目作为响应提供。我们可以用来监视上传状态的upload标记将包含对上传文件的引用以及清单条目。

\subsubsection{追加到现有文件}\label{sec:append}

\lstinline{PUT}请求实现了对集群中已存在的数据追加，并期望URL指向该文件。如果直接引用该文件，则从上传头文件中获取诸如擦除编码的校验数等设置，否则将使用外围清单条目中的设置。响应与\lstinline{POST}请求的响应相同。


\subsubsection{恢复不完整上传}\label{sec:resume}

作为一种特殊情况，append用于在崩溃或用户启动中止后恢复上传。为此，需要定期在upload标记上记录根哈希值来跟踪部分上传。当报头中指定的上传标记未完成时，我们假定请求要继续相同的上传。标记中最后记录的根哈希被用作追加目标:检索现有文件的右边缘来初始化块的状态。与请求一起发送的文件从部分上传结束的地方读取，即偏移量设置为标记上记录的根块的跨度。

\subsection{收集和清单\statusgreen}\label{sec:manifests-ux}

正如在\ref{sec:collections}中描述并在\ref{spec:format:manifests}中指定的，清单可以表示一个通用索引，将字符串路径映射到条目，因此可以作为到虚拟网站的路由表，作为文件集合的目录树或作为键值存储。 

\subsubsection{清单条目vs单例清单}

单个文件也需要清单条目，因为它们包含关于文件的关键信息，如内容类型、擦除编码(用于正确的检索)。在空路径上包含一个文件条目的清单称为\gloss{singleton manifest}。它只包含条目本身的信息。

http服务器提供实现集合存储API的\lstinline{bzz} URL方案(参见\ref{spec:api:storage})。当通过\lstinline{POST}请求\lstinline{bzz}模式上传单个文件时，清单条目将被创建并存储，响应包含对它的引用。

\subsubsection{上传和更新集合}

\lstinline{bzz} URL方案提供的API也支持上传和更新集合。\lstinline{POST}和\lstinline{PUT}请求期望具有\gloss{tar stream}的多部分。在tar流中编码的目录树被转换成清单，同时所有文件被分块并上传，它们的Swarm引用被包含在各自的清单条目中。\lstinline{POST}请求上传生成的清单，并使用它的Swarm引用进行响应。\lstinline{PUT}请求要求请求URL引用一个已经存在的清单，该清单由来自焦油流的清单更新。这里的更新意味着将所有新路径与现有清单的路径合并。在路径相同的情况下，来自上传的条目将替换旧的条目。

该API支持将路径插入到清单中、更新清单中的路径(\lstinline{PUT})和从清单中删除路径(\lstinline{DELETE})。对于\lstinline{PUT}请求，在上传的请求主体中需要一个文件，它的清单条目被插入到URL中的路径中。如果该路径已经存在于清单中，则将该条目替换为上传时生成的条目，实现更新;否则，如果路径是新的，则实现插入。

集合API支持与文件上传端点相同的头文件，即配置邮费订阅、标记、加密、擦除编码和固定的头文件。

\subsubsection{直接更新清单}

还直接支持操作清单:\lstinline{bzz} URL方案\lstinline{manifest}端点支持\lstinline{PUT}和\lstinline{DELETE}方法，其行为与集合端点类似，只是它不处理条目中引用的文件。URL路径将使用路径$p$引用清单。对于\lstinline{PUT}，请求主体需要一个清单条目，该条目将被放置在路径$p$上。创建并存储新清单所需的块，并在响应中返回新清单的根散列。\lstinline{DELETE}方法期望请求体为空，并从清单中删除路径上的条目:也就是说，它创建了一个新的清单，其中URL中的引用路径缺失。

\lstinline{POST}请求直接在清单API端点上安装一个清单条目。实际上，在文件\lstinline{POST}的输出上调用清单\lstinline{POST}等同于在通用存储端点上调用\lstinline{POST}。

给定清单引用$a$和$b$，在\lstinline{manifest/merge/<a>/<b>}上发送\lstinline{POST}请求
将$b$合并到$a$(在发生冲突时优先选择$b$进行合并)，创建并存储组成合并清单的所有块，并将其根引用作为响应返回。


如果URL路径引用了一个清单，则在请求主体中接受另一个清单，然后合并到所引用的清单中。在冲突的情况下，上传的一方获胜。 


\subsection{访问控制\statusgreen}\label{sec:access-control-ux}

\glossupper{access control}在\ref{sec:access-control}中有描述，在\ref{spec:format:access-control}中有规格。\lstinline{bzz} URL方案为访问控制提供了\lstinline{access} API端点(AC，请参阅\ref{spec:api:access-control}中的API规范)。这个API为用户提供了方便，并支持将文件/集合/站点置于访问控制之下，以及添加和删除被授予者。

如果URL路径引用了集合清单，那么带有\gloss{AC}设置的\lstinline{POST}请求将以JSON编码的请求主体发送，并将清单引用加密，并将其与提交的AC设置封装在所谓的\gloss{root access manifest}中。然后将该清单上传，并将对它的未加密引用作为响应体返回。

如果URL路径引用根访问清单，并且访问控制设置指定了一个\gloss{ACT}，那么可以使用\lstinline{POST}、\lstinline{PUT}和\lstinline{DELETE}请求创建或更新这个\gloss{ACT}。所有请求都要求在请求体中包含一个被授权公钥或url的JSON数组。如果URL引用了被授予者，则使用解析器通过ENS提取所有者公钥。

\lstinline{POST}请求将创建包含被授予者名单的ACT。\lstinline{PUT}将通过合并主体中的受让人来更新现有的ACT。\lstinline{DELETE}删除请求主体中列出的所有被授予者。然后，在上传的根访问清单中更新新的ACT根哈希，并在响应中返回其Swarm地址。更多细节请参阅\ref{spec:api:access-control}中的规范。



\subsection{下载\statusgreen}\label{sec:download}

\lstinline{bzz} URL方案支持下载。这个URL方案假设URL的域部分引用一个清单作为入口点。

虽然这一节的标题是下载，但是如果只检索部分文件，则执行相同的过程。如\ref{sec:files}和afaed所示，在最低级别上支持以任意偏移量随机访问文件。因此，指向文件的URL上的GET请求在报头中接受\gloss{range queries}。范围查询将触发对覆盖所需范围的所有文件块(除了那些块外)的检索。  

\subsubsection{检索成本}

下载涉及到通过网络检索块，这反过来需要显示为SWAP会计(\ref{sec:accounting})的成本。在每一个对等连接上，如果余额超出了有效支付阈值，就会发出支票并发送给对等连接。但是，如果支票簿合同不存在或缺乏足够的资金来支付未偿债务，则对等连接将被阻塞。这可能会导致不饱和的卡德米利亚，在此期间，该节点将被算作一个光节点。下载可以继续使用少量的对等点，但是由于有些块需要发送到比节点本身更靠近请求地址的对等点，因此检索块的平均成本将会更高。

向用户显示这个平均数字、平均交换余额和由于资金不足而无法接收检索请求的对等连接数是很有用的。这是通过在defaf URL方案的\lstinline{swap}端点上提供的\ref{spec:api:swap}中指定的SWAP API来实现的。


\subsubsection{域名解析}

URL的域部分可以是人类可读的域或带有\gloss{TLD}扩展的子域。根据TLD，可以调用各种名称解析器。TLD \lstinline{eth}链接到以太坊主链上的以太坊名称服务合同。如果你注册了一个Swarm哈希到\gloss{ENS}域，Swarm可以像命名服务器一样调用ENS合同来解决这个问题。 

\subsubsection{访问控制认证}

如果解析的域引用了\gloss{root access manifest}，则检索到的URL位于\gloss{access control}(参见\ref{sec:access-control})之下。
根据所使用的凭据，会提示用户输入密码，可能还有密钥对。
Diffie—Hellmann共享密钥使用一个常量进行哈希，以获得查找密钥，并使用另一个常量获得访问密钥解密密钥。ACT清单根块的Swarm地址取自根访问清单。
接下来，将查找键附加到ACT地址，并使用生成的URL检索清单条目。然后使用访问密钥解密密钥对该条目的引用进行解密，生成的访问密钥用于解密根访问清单中找到的原始加密引用。

接下来，将检索与URL路径匹配的清单条目。考虑了以下属性:

\begin{itemize}
    \item \lstinline{crs}——{
    结构的属性需要使用CRS擦除编码检索，例如奇偶校验块的数量}。
    \item \lstinline{sw3}——{ 具有诉讼所需属性的结构，例如就缺失的部分向保险公司提出挑战}。 
\end{itemize}


\subsubsection{擦除编码的文件}

如果给定了\lstinline{crs}属性，可以采用两种策略: 

\begin{itemize}
\item \emph{回退}——对于所有中间块，CRS奇偶校验块首先被忽略，只有在缺少非奇偶校验块时才会使用它们。这节省了一些带宽和相应的速度成本:如果一个块丢失，回退到CRS将被延迟。
\item \emph{比赛}——对于所有中间块，CRS对等立即与其他子块一起检索。第一个$n$(假设$k$为\lstinline{crs}的值，即来自$n+k$编码方案的$n$)块将能够重建所有$n$真实的子块。这相当于说可以忽略$k$最慢的块检索。  
\end{itemize}

默认的策略选择是\lstinline{race}，如果用户想在下载时保存，那么可以通过设置报头\lstinline{SWARM-CRS-STRATEGY=fallback}强制执行回退策略，或者通过设置becee完全禁用回退策略。擦除码批处理的校验数取自外围清单的\lstinline{crs}属性，但可以用报头\lstinline{SWARM-CRS-PARITIES}重写。

\subsubsection{失踪的块}

如果发现一个块丢失了，我们可以回到丢失块通知协议(见\ref{sec:reupload})。在恢复提要的最新更新时，可以找到表示\gloss{recovery targets}集合的数据结构的根的引用。

当块请求超时时，客户端可以开始使用piner主机集创建恢复消息(请参阅\ref{spec:format:recovery})。一旦创建，它就被发送到主机。如果超时，则使用不同的pininner主机节点尝试下一个恢复块。这一过程一直重复，直到恢复部分到来，或者所有的固定钉和保险公司都筋疲力尽。

\subsubsection{诉讼}

如果丢失的块通知没有返回块，但是文件被保险了，作为最后的手段，客户端可以提起诉讼(请参阅\ref{sec:chunk-insurance})。为此需要收据。为了获得收据，我们首先确定哪个保险公司对问题部分负责(见\ref{sec:insurance})。使用它们的公钥，我们可以构造指向当前收据清单根的提要地址。将块地址附加到这个引用后，客户端就可以检索收据了。一旦获得收据，客户就可以通过提交对\emph{发誓}合同的挑战来开始诉讼。由于持有收据的数据结构是由保险人隐式投保的，如果需要获取收据的任何块丢失了，可以将挑战作为该块的引用提交。这个挑战将包含包含在更新中找到的根哈希中包含引用的段的包含证明，以及提要块中的标识符和签名，而不是签名的收据。 

\section{沟通\statusred}\label{sec:messaging}

\red{没有覆盖}

令人惊讶的是，Swarm的网络层可以作为一个高效的通信平台，并且具有极强的隐私属性。本章试图定义一套完整的原语集合，这些原语作为基础层通信基础设施的构建块，覆盖了所有的通信方式，包括实时匿名聊天、从以前未连接的地方发送和接收消息、潜在的匿名发送者、用于异步传递、长期通知和发布/订阅接口的邮件装箱。

蜂群核心提供了最低水平的入门点的功能相关的通信。

\begin{itemize}
    \item pss提供了一个API来发送和接收木马块
    \item BZZ提供了一种上传单个所有者块的方法。除了存储api提供的内容外，单所有者块检索不需要其他任何东西
\end{itemize}



从用户体验的角度来看，这些pss和feed的原始界面太低级了。然而，重要的是，任何更高层次的解决方案都可以安全地构建在蜂群核心基础设施之上，理想情况下是作为养蜂场中的软件包。

\subsection{提要\statusorange}\label{sec:feeds-ux}


\subsection{Pss \statusorange}\label{sec:pss-ux}

木马消息发送和接收的功能与存储完全不同，因此应该有自己的url方案\lstinline{pss}。pss方案提供了一个用于发送消息的API。当发送\lstinline{POST}请求时，URL被解释为引用X3DH预键包提要更新块。它包含需要加密的公钥以及目标目标，其中一个木马消息地址应该被挖掘来匹配(参见\ref{sec:trojan})。

目标目标被表示为目标前缀的嗡嗡声序列化文件。URL路径指向这个文件，或者是顶级域。主题作为查询参数给出，而消息作为请求体。

仅通过在内部注册主题处理程序来支持接收消息。在API上下文中，这意味着通过web套接字推送通知。



\section{Swarm作为web3的后端 \statusred}\label{sec:buzz-apiary}

\subsection{原语\statusred}\label{sec:primitives}


\begin{figure}[htbp]
   \centering
   \includegraphics[width=1\textwidth]{fig/buzz-apiary.pdf}
   \caption[buzz养蜂场\statusgreen]{buzz养蜂场。 }
   \label{fig:buzz-apiary}
\end{figure}

\subsection{脚本\statusred}
\label{sec:buzz}

\subsection{内置复合api \statusred}
\label{sec:lego}

\subsection{标准库\statusred}
\label{sec:stdlib}